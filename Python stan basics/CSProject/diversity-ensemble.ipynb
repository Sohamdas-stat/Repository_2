{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28fc02d8",
   "metadata": {
    "papermill": {
     "duration": 0.013834,
     "end_time": "2024-03-15T23:17:32.077945",
     "exception": false,
     "start_time": "2024-03-15T23:17:32.064111",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Notes - This notebook is an extension of the discussion forund here: https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/484124\n",
    "\n",
    "##### This aids to show th benefits of diversity of different modeling. In this notebook we see LB of 0.41, 0.37, and 0.36 yet when we average them we see far better scores of 0.31. However this does come with its warnings. This notebook uses a combonation of 2 stage and 1 stage which \"could\" be dramatically overfitting the LB depending on the outcome of the distribution of voters in the test set. I would personally suggest a deep review of the methods used in this notebook before you opt to use any strategies from it. Please reference the many warnings about this in the discussions for more details.\n",
    "\n",
    "#### Lastly, please do check out the hard work of those who have created these datasets and notebooks in the first place! Or who combined them in @Majiaqi111 . A high LB score does not always mean a good solution!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4d66fe",
   "metadata": {
    "papermill": {
     "duration": 0.012944,
     "end_time": "2024-03-15T23:17:32.104637",
     "exception": false,
     "start_time": "2024-03-15T23:17:32.091693",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model 1 - @andreasbis 0.41 \n",
    "https://www.kaggle.com/code/andreasbis/hms-inference-lb-0-41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7025a629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting timm\n",
      "  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors\n",
      "  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from timm) (6.0)\n",
      "Requirement already satisfied: huggingface_hub in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from timm) (0.10.1)\n",
      "Requirement already satisfied: torchvision in /home/sohamdas/.local/lib/python3.10/site-packages (from timm) (0.17.1)\n",
      "Requirement already satisfied: torch in /home/sohamdas/.local/lib/python3.10/site-packages (from timm) (2.2.1)\n",
      "Requirement already satisfied: filelock in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from huggingface_hub->timm) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/sohamdas/.local/lib/python3.10/site-packages (from huggingface_hub->timm) (4.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from huggingface_hub->timm) (22.0)\n",
      "Requirement already satisfied: tqdm in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from huggingface_hub->timm) (4.64.1)\n",
      "Requirement already satisfied: requests in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from huggingface_hub->timm) (2.28.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/sohamdas/.local/lib/python3.10/site-packages (from torch->timm) (2.19.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/sohamdas/.local/lib/python3.10/site-packages (from torch->timm) (10.3.2.106)\n",
      "Requirement already satisfied: fsspec in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from torch->timm) (2022.11.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/sohamdas/.local/lib/python3.10/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/sohamdas/.local/lib/python3.10/site-packages (from torch->timm) (8.9.2.26)\n",
      "Requirement already satisfied: jinja2 in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from torch->timm) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/sohamdas/.local/lib/python3.10/site-packages (from torch->timm) (12.1.3.1)\n",
      "Requirement already satisfied: sympy in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from torch->timm) (1.11.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/sohamdas/.local/lib/python3.10/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/sohamdas/.local/lib/python3.10/site-packages (from torch->timm) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/sohamdas/.local/lib/python3.10/site-packages (from torch->timm) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/sohamdas/.local/lib/python3.10/site-packages (from torch->timm) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/sohamdas/.local/lib/python3.10/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/sohamdas/.local/lib/python3.10/site-packages (from torch->timm) (2.2.0)\n",
      "Requirement already satisfied: networkx in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from torch->timm) (2.8.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/sohamdas/.local/lib/python3.10/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/sohamdas/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm) (12.4.99)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from torchvision->timm) (9.4.0)\n",
      "Requirement already satisfied: numpy in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from torchvision->timm) (1.23.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from jinja2->torch->timm) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2.0.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->torch->timm) (1.2.1)\n",
      "Installing collected packages: safetensors, timm\n",
      "Successfully installed safetensors-0.4.2 timm-0.9.16\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a523678",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:17:32.132174Z",
     "iopub.status.busy": "2024-03-15T23:17:32.131353Z",
     "iopub.status.idle": "2024-03-15T23:17:38.069059Z",
     "shell.execute_reply": "2024-03-15T23:17:38.068057Z"
    },
    "papermill": {
     "duration": 5.953689,
     "end_time": "2024-03-15T23:17:38.071168",
     "exception": false,
     "start_time": "2024-03-15T23:17:32.117479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing essential libraries\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# PyTorch for deep learning\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# torchvision for image processing and augmentation\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Suppressing minor warnings to keep the output clean\n",
    "warnings.filterwarnings('ignore', category=Warning)\n",
    "\n",
    "# Reclaim memory no longer in use.\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce4e8af4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:17:38.100284Z",
     "iopub.status.busy": "2024-03-15T23:17:38.099971Z",
     "iopub.status.idle": "2024-03-15T23:17:38.109216Z",
     "shell.execute_reply": "2024-03-15T23:17:38.108363Z"
    },
    "papermill": {
     "duration": 0.02622,
     "end_time": "2024-03-15T23:17:38.111214",
     "exception": false,
     "start_time": "2024-03-15T23:17:38.084994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed=42\n",
    "    image_transform=transforms.Resize((512, 512))\n",
    "    num_folds=5\n",
    "    \n",
    "# Set the seed for reproducibility across multiple libraries\n",
    "def set_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "set_seed(Config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eae4a1fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:17:38.138414Z",
     "iopub.status.busy": "2024-03-15T23:17:38.138135Z",
     "iopub.status.idle": "2024-03-15T23:17:48.704403Z",
     "shell.execute_reply": "2024-03-15T23:17:48.703455Z"
    },
    "papermill": {
     "duration": 10.582314,
     "end_time": "2024-03-15T23:17:48.706519",
     "exception": false,
     "start_time": "2024-03-15T23:17:38.124205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/hms-train-resnet34d/resnet34d_fold0.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m model_resnet \u001b[38;5;241m=\u001b[39m timm\u001b[38;5;241m.\u001b[39mcreate_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresnet34d\u001b[39m\u001b[38;5;124m'\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, in_chans\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Load the trained weights from the corresponding file\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m model_resnet\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/hms-train-resnet34d/resnet34d_fold\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Append the loaded model to the models list\u001b[39;00m\n\u001b[1;32m     13\u001b[0m models\u001b[38;5;241m.\u001b[39mappend(model_resnet)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/hms-train-resnet34d/resnet34d_fold0.pth'"
     ]
    }
   ],
   "source": [
    "# Load and store the trained models for each fold into a list\n",
    "models = []\n",
    "\n",
    "# Load ResNet34d\n",
    "for i in range(Config.num_folds):\n",
    "    # Create the same model architecture as during training\n",
    "    model_resnet = timm.create_model('resnet34d', pretrained=False, num_classes=6, in_chans=1)\n",
    "    \n",
    "    # Load the trained weights from the corresponding file\n",
    "    model_resnet.load_state_dict(torch.load(f'/kaggle/input/hms-train-resnet34d/resnet34d_fold{i}.pth', map_location=torch.device('cpu')))\n",
    "    \n",
    "    # Append the loaded model to the models list\n",
    "    models.append(model_resnet)\n",
    "\n",
    "# Reclaim memory no longer in use.\n",
    "gc.collect()\n",
    "\n",
    "# Load EfficientNetB0\n",
    "for j in range(Config.num_folds):\n",
    "    # Create the same model architecture as during training\n",
    "    model_effnet_b0 = timm.create_model('efficientnet_b0', pretrained=False, num_classes=6, in_chans=1)\n",
    "    \n",
    "    # Load the trained weights from the corresponding file\n",
    "    model_effnet_b0.load_state_dict(torch.load(f'/kaggle/input/hms-train-efficientnetb0/efficientnet_b0_fold{j}.pth', map_location=torch.device('cpu')))\n",
    "    \n",
    "    # Append the loaded model to the models list\n",
    "    models.append(model_effnet_b0)\n",
    "    \n",
    "# Reclaim memory no longer in use.\n",
    "gc.collect()\n",
    "    \n",
    "# Load EfficientNetB1\n",
    "for k in range(Config.num_folds):\n",
    "    # Create the same model architecture as during training\n",
    "    model_effnet_b1 = timm.create_model('efficientnet_b1', pretrained=False, num_classes=6, in_chans=1)\n",
    "    \n",
    "    # Load the trained weights from the corresponding file\n",
    "    model_effnet_b1.load_state_dict(torch.load(f'/kaggle/input/hms-train-efficientnetb1/efficientnet_b1_fold{k}.pth', map_location=torch.device('cpu')))\n",
    "    \n",
    "    # Append the loaded model to the models list\n",
    "    models.append(model_effnet_b1)\n",
    "\n",
    "# Reclaim memory no longer in use.\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28e1bed6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:17:48.735862Z",
     "iopub.status.busy": "2024-03-15T23:17:48.735494Z",
     "iopub.status.idle": "2024-03-15T23:17:48.928550Z",
     "shell.execute_reply": "2024-03-15T23:17:48.927611Z"
    },
    "papermill": {
     "duration": 0.20983,
     "end_time": "2024-03-15T23:17:48.930455",
     "exception": false,
     "start_time": "2024-03-15T23:17:48.720625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3911565283</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>853520</td>\n",
       "      <td>6885</td>\n",
       "      <td>/kaggle/input/hms-harmful-brain-activity-class...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
       "0  3911565283      0.166667  0.166667  0.166667   0.166667   0.166667   \n",
       "\n",
       "   other_vote  spectrogram_id  patient_id  \\\n",
       "0    0.166667          853520        6885   \n",
       "\n",
       "                                                path  \n",
       "0  /kaggle/input/hms-harmful-brain-activity-class...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test data and sample submission dataframe\n",
    "test_df = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/test.csv\")\n",
    "submission = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/sample_submission.csv\")\n",
    "\n",
    "# Merge the submission dataframe with the test data on EEG IDs\n",
    "submission = submission.merge(test_df, on='eeg_id', how='left')\n",
    "\n",
    "# Generate file paths for each spectrogram based on the EEG data in the submission dataframe\n",
    "submission['path'] = submission['spectrogram_id'].apply(lambda x: f\"/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms/{x}.parquet\")\n",
    "\n",
    "# Display the first few rows of the submission dataframe\n",
    "display(submission.head())\n",
    "\n",
    "# Reclaim memory no longer in use\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "271e6044",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:17:48.957782Z",
     "iopub.status.busy": "2024-03-15T23:17:48.957440Z",
     "iopub.status.idle": "2024-03-15T23:17:52.322296Z",
     "shell.execute_reply": "2024-03-15T23:17:52.321322Z"
    },
    "papermill": {
     "duration": 3.380803,
     "end_time": "2024-03-15T23:17:52.324404",
     "exception": false,
     "start_time": "2024-03-15T23:17:48.943601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the weights for each model\n",
    "weight_resnet34d = 0.26\n",
    "weight_effnetb0 = 0.48\n",
    "weight_effnetb1 = 0.26\n",
    "\n",
    "# Get file paths for test spectrograms\n",
    "paths = submission['path'].values\n",
    "test_preds = []\n",
    "\n",
    "# Generate predictions for each spectrogram using all models\n",
    "for path in paths:\n",
    "    eps = 1e-6\n",
    "    # Read and preprocess spectrogram data\n",
    "    data = pd.read_parquet(path)\n",
    "    data = data.fillna(-1).values[:, 1:].T\n",
    "    data = np.clip(data, np.exp(-6), np.exp(10))\n",
    "    data = np.log(data)\n",
    "    \n",
    "    # Normalize the data\n",
    "    data_mean = data.mean(axis=(0, 1))\n",
    "    data_std = data.std(axis=(0, 1))\n",
    "    data = (data - data_mean) / (data_std + eps)\n",
    "    data_tensor = torch.unsqueeze(torch.Tensor(data), dim=0)\n",
    "    data = Config.image_transform(data_tensor)\n",
    "\n",
    "    test_pred = []\n",
    "    \n",
    "    # Generate predictions using all models\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred = F.softmax(model(data.unsqueeze(0)))[0]\n",
    "            pred = pred.detach().cpu().numpy()\n",
    "        test_pred.append(pred)\n",
    "        \n",
    "    # Combine predictions from all models using weighted voting\n",
    "    weighted_pred = weight_resnet34d * np.mean(test_pred[:Config.num_folds], axis=0) + \\\n",
    "                     weight_effnetb0 * np.mean(test_pred[Config.num_folds:2*Config.num_folds], axis=0) + \\\n",
    "                     weight_effnetb1 * np.mean(test_pred[2*Config.num_folds:], axis=0)\n",
    "    \n",
    "    test_preds.append(weighted_pred)\n",
    "\n",
    "# Convert the list of predictions to a NumPy array for further processing\n",
    "test_preds = np.array(test_preds)\n",
    "\n",
    "# Reclaim memory no longer in use\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93b07d50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:17:52.354897Z",
     "iopub.status.busy": "2024-03-15T23:17:52.354228Z",
     "iopub.status.idle": "2024-03-15T23:17:52.510583Z",
     "shell.execute_reply": "2024-03-15T23:17:52.509542Z"
    },
    "papermill": {
     "duration": 0.173796,
     "end_time": "2024-03-15T23:17:52.512883",
     "exception": false,
     "start_time": "2024-03-15T23:17:52.339087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3911565283</td>\n",
       "      <td>0.034403</td>\n",
       "      <td>0.103879</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.371507</td>\n",
       "      <td>0.010815</td>\n",
       "      <td>0.478578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
       "0  3911565283      0.034403  0.103879  0.000818   0.371507   0.010815   \n",
       "\n",
       "   other_vote  \n",
       "0    0.478578  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the sample submission file and update it with model predictions for each label\n",
    "sub1 = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/sample_submission.csv\")\n",
    "labels = ['seizure', 'lpd', 'gpd', 'lrda', 'grda', 'other']\n",
    "\n",
    "# Assign model predictions to respective columns in the submission DataFrame\n",
    "for i in range(len(labels)):\n",
    "    sub1[f'{labels[i]}_vote'] = test_preds[:, i]\n",
    "\n",
    "display(sub1.head())\n",
    "\n",
    "# Reclaim memory no longer in use.\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "825f8904",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:17:52.542976Z",
     "iopub.status.busy": "2024-03-15T23:17:52.542661Z",
     "iopub.status.idle": "2024-03-15T23:17:52.549729Z",
     "shell.execute_reply": "2024-03-15T23:17:52.548784Z"
    },
    "papermill": {
     "duration": 0.024209,
     "end_time": "2024-03-15T23:17:52.551766",
     "exception": false,
     "start_time": "2024-03-15T23:17:52.527557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n"
     ]
    }
   ],
   "source": [
    "print(sub1.iloc[:,-6:].sum(axis=1).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0395246",
   "metadata": {
    "papermill": {
     "duration": 0.013915,
     "end_time": "2024-03-15T23:17:52.580005",
     "exception": false,
     "start_time": "2024-03-15T23:17:52.566090",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model 2 - @minhsienweng 0.37\n",
    "https://www.kaggle.com/code/minhsienweng/infer-features-head-starter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a1e6ced",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:17:52.652776Z",
     "iopub.status.busy": "2024-03-15T23:17:52.652392Z",
     "iopub.status.idle": "2024-03-15T23:18:05.445478Z",
     "shell.execute_reply": "2024-03-15T23:18:05.444677Z"
    },
    "papermill": {
     "duration": 12.811054,
     "end_time": "2024-03-15T23:18:05.447983",
     "exception": false,
     "start_time": "2024-03-15T23:17:52.636929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, random, sys\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "import tensorflow.keras.backend as K\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "import albumentations as albu\n",
    "from scipy.signal import butter, lfilter\n",
    "import librosa\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "import tensorflow.keras.backend as K, gc\n",
    "from tensorflow.keras.layers import Input, Dense, Multiply, Add, Conv1D, Concatenate, LayerNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf61d9cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:18:05.478344Z",
     "iopub.status.busy": "2024-03-15T23:18:05.477753Z",
     "iopub.status.idle": "2024-03-15T23:18:05.482588Z",
     "shell.execute_reply": "2024-03-15T23:18:05.481737Z"
    },
    "papermill": {
     "duration": 0.022254,
     "end_time": "2024-03-15T23:18:05.484544",
     "exception": false,
     "start_time": "2024-03-15T23:18:05.462290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOAD_MODELS_FROM = '/kaggle/input/features-head-starter-models'\n",
    "TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b8f4b55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:18:05.513897Z",
     "iopub.status.busy": "2024-03-15T23:18:05.513615Z",
     "iopub.status.idle": "2024-03-15T23:18:05.518435Z",
     "shell.execute_reply": "2024-03-15T23:18:05.517569Z"
    },
    "papermill": {
     "duration": 0.021693,
     "end_time": "2024-03-15T23:18:05.520369",
     "exception": false,
     "start_time": "2024-03-15T23:18:05.498676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Seed the same seed to all \n",
    "def seed_everything(seed=42):\n",
    "    np.random.seed(42)\n",
    "    random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ece4a68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:18:05.549751Z",
     "iopub.status.busy": "2024-03-15T23:18:05.549454Z",
     "iopub.status.idle": "2024-03-15T23:18:05.553980Z",
     "shell.execute_reply": "2024-03-15T23:18:05.553014Z"
    },
    "papermill": {
     "duration": 0.021212,
     "end_time": "2024-03-15T23:18:05.555883",
     "exception": false,
     "start_time": "2024-03-15T23:18:05.534671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ctypes\n",
    "libc = ctypes.CDLL(\"libc.so.6\")\n",
    "def clear_memory():\n",
    "    libc.malloc_trim(0)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92cf0ffb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:18:05.586248Z",
     "iopub.status.busy": "2024-03-15T23:18:05.585937Z",
     "iopub.status.idle": "2024-03-15T23:18:06.570714Z",
     "shell.execute_reply": "2024-03-15T23:18:06.569758Z"
    },
    "papermill": {
     "duration": 1.002675,
     "end_time": "2024-03-15T23:18:06.573030",
     "exception": false,
     "start_time": "2024-03-15T23:18:05.570355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs\n"
     ]
    }
   ],
   "source": [
    "# USE SINGLE GPU, MULTIPLE GPUS \n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "# WE USE MIXED PRECISION\n",
    "tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n",
    "if len(gpus)>1:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    print(f'Using {len(gpus)} GPUs')\n",
    "else:\n",
    "    strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
    "    print(f'Using {len(gpus)} GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfea5f26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:18:06.604098Z",
     "iopub.status.busy": "2024-03-15T23:18:06.603794Z",
     "iopub.status.idle": "2024-03-15T23:18:06.618064Z",
     "shell.execute_reply": "2024-03-15T23:18:06.617370Z"
    },
    "papermill": {
     "duration": 0.031981,
     "end_time": "2024-03-15T23:18:06.620101",
     "exception": false,
     "start_time": "2024-03-15T23:18:06.588120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod \n",
    "  \n",
    "FEATS2 = ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']\n",
    "FEAT2IDX = {x:y for x,y in zip(FEATS2,range(len(FEATS2)))}\n",
    "FEATS = [['Fp1','F7','T3','T5','O1'],\n",
    "         ['Fp1','F3','C3','P3','O1'],\n",
    "         ['Fp2','F8','T4','T6','O2'],\n",
    "         ['Fp2','F4','C4','P4','O2']]\n",
    "USE_PROCESSED = True # Use processed downsampled Raw EEG \n",
    "    \n",
    "class BaseDataGenerator():\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, data, specs, eeg_specs, raw_eegs, augment, mode, data_type): \n",
    "        self.data = data\n",
    "        self.augment = augment\n",
    "        self.mode = mode\n",
    "        self.data_type = data_type\n",
    "        self.specs = specs\n",
    "        self.eeg_specs = eeg_specs\n",
    "        self.raw_eegs = raw_eegs\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.data_generation(index)\n",
    "        if self.augment: X = self.augmentation(X)\n",
    "        return X, y\n",
    "    \n",
    "    def __call__(self):\n",
    "        for i in range(self.__len__()):\n",
    "            yield self.__getitem__(i)\n",
    "            \n",
    "            if i == self.__len__()-1:\n",
    "                self.on_epoch_end()\n",
    "                \n",
    "    def on_epoch_end(self):\n",
    "        if self.mode=='train': \n",
    "            self.data = self.data.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # Abstract method generate data based on the trained data type\n",
    "    @abstractmethod\n",
    "    def data_generation(self, index):\n",
    "        pass\n",
    "        \n",
    "    def butter_lowpass_filter(self, data, cutoff_freq=20, sampling_rate=200, order=4):\n",
    "        nyquist = 0.5 * sampling_rate\n",
    "        normal_cutoff = cutoff_freq / nyquist\n",
    "        b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "        filtered_data = lfilter(b, a, data, axis=0)\n",
    "        return filtered_data\n",
    "    \n",
    "    def resize(self, img,size):\n",
    "        composition = albu.Compose([\n",
    "                albu.Resize(size[0],size[1])\n",
    "            ])\n",
    "        return composition(image=img)['image']\n",
    "            \n",
    "    def augmentation(self, img):\n",
    "        composition = albu.Compose([\n",
    "                albu.HorizontalFlip(p=0.4)\n",
    "            ])\n",
    "        return composition(image=img)['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8ba5f77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:18:06.650724Z",
     "iopub.status.busy": "2024-03-15T23:18:06.650404Z",
     "iopub.status.idle": "2024-03-15T23:18:06.699577Z",
     "shell.execute_reply": "2024-03-15T23:18:06.698678Z"
    },
    "papermill": {
     "duration": 0.066997,
     "end_time": "2024-03-15T23:18:06.701655",
     "exception": false,
     "start_time": "2024-03-15T23:18:06.634658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Implementation class generates the data based on the data_type \n",
    "class DataGenerator(BaseDataGenerator):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, data, specs, eeg_specs, raw_eegs, augment, \n",
    "                 mode, data_type): \n",
    "        super().__init__(data, specs, eeg_specs, raw_eegs, augment, mode, data_type)\n",
    "    \n",
    "    def data_generation(self, index):\n",
    "        if self.data_type == 'KE':\n",
    "            X,y = self.generate_all_specs(index)\n",
    "        elif self.data_type == 'E' or self.data_type == 'K':\n",
    "            X,y = self.generate_specs(index)\n",
    "        elif self.data_type == 'R':\n",
    "            X,y = self.generate_raw(index)\n",
    "        elif self.data_type in ['ER','KR']:\n",
    "            X1,y = self.generate_specs(index)\n",
    "            X2,y = self.generate_raw(index)\n",
    "            X = (X1,X2)\n",
    "        elif self.data_type == 'KER':\n",
    "            X1,y = self.generate_all_specs(index)\n",
    "            X2,y = self.generate_raw(index)\n",
    "            X = (X1,X2)\n",
    "        return X,y\n",
    "    \n",
    "    def generate_all_specs(self, index):\n",
    "        X = np.zeros((512,512,3),dtype='float32')\n",
    "        y = np.zeros((6,),dtype='float32')\n",
    "        \n",
    "        row = self.data.iloc[index]\n",
    "        if self.mode=='test': \n",
    "            offset = 0\n",
    "        else:\n",
    "            offset = int(row.offset/2)\n",
    "        \n",
    "        eeg = self.eeg_specs[row.eeg_id]\n",
    "        spec = self.specs[row.spec_id]\n",
    "        \n",
    "        imgs = [spec[offset:offset+300,k*100:(k+1)*100].T for k in [0,2,1,3]] # to match kaggle with eeg\n",
    "        img = np.stack(imgs,axis=-1)\n",
    "        # LOG TRANSFORM SPECTROGRAM\n",
    "        img = np.clip(img,np.exp(-4),np.exp(8))\n",
    "        img = np.log(img)\n",
    "            \n",
    "        # STANDARDIZE PER IMAGE\n",
    "        img = np.nan_to_num(img, nan=0.0)    \n",
    "            \n",
    "        mn = img.flatten().min()\n",
    "        mx = img.flatten().max()\n",
    "        ep = 1e-5\n",
    "        img = 255 * (img - mn) / (mx - mn + ep)\n",
    "        \n",
    "        X[0_0+56:100+56,:256,0] = img[:,22:-22,0] # LL_k\n",
    "        X[100+56:200+56,:256,0] = img[:,22:-22,2] # RL_k\n",
    "        X[0_0+56:100+56,:256,1] = img[:,22:-22,1] # LP_k\n",
    "        X[100+56:200+56,:256,1] = img[:,22:-22,3] # RP_k\n",
    "        X[0_0+56:100+56,:256,2] = img[:,22:-22,2] # RL_k\n",
    "        X[100+56:200+56,:256,2] = img[:,22:-22,1] # LP_k\n",
    "        \n",
    "        X[0_0+56:100+56,256:,0] = img[:,22:-22,0] # LL_k\n",
    "        X[100+56:200+56,256:,0] = img[:,22:-22,2] # RL_k\n",
    "        X[0_0+56:100+56,256:,1] = img[:,22:-22,1] # LP_k\n",
    "        X[100+56:200+56,256:,1] = img[:,22:-22,3] # RP_K\n",
    "        \n",
    "        # EEG\n",
    "        img = eeg\n",
    "        mn = img.flatten().min()\n",
    "        mx = img.flatten().max()\n",
    "        ep = 1e-5\n",
    "        img = 255 * (img - mn) / (mx - mn + ep)\n",
    "        X[200+56:300+56,:256,0] = img[:,22:-22,0] # LL_e\n",
    "        X[300+56:400+56,:256,0] = img[:,22:-22,2] # RL_e\n",
    "        X[200+56:300+56,:256,1] = img[:,22:-22,1] # LP_e\n",
    "        X[300+56:400+56,:256,1] = img[:,22:-22,3] # RP_e\n",
    "        X[200+56:300+56,:256,2] = img[:,22:-22,2] # RL_e\n",
    "        X[300+56:400+56,:256,2] = img[:,22:-22,1] # LP_e\n",
    "        \n",
    "        X[200+56:300+56,256:,0] = img[:,22:-22,0] # LL_e\n",
    "        X[300+56:400+56,256:,0] = img[:,22:-22,2] # RL_e\n",
    "        X[200+56:300+56,256:,1] = img[:,22:-22,1] # LP_e\n",
    "        X[300+56:400+56,256:,1] = img[:,22:-22,3] # RP_e\n",
    "\n",
    "        if self.mode!='test':\n",
    "            y[:] = row[TARGETS]\n",
    "        \n",
    "        return X,y\n",
    "    \n",
    "    def generate_specs(self, index):\n",
    "        X = np.zeros((512,512,3),dtype='float32')\n",
    "        y = np.zeros((6,),dtype='float32')\n",
    "        \n",
    "        row = self.data.iloc[index]\n",
    "        if self.mode=='test': \n",
    "            offset = 0\n",
    "        else:\n",
    "            offset = int(row.offset/2)\n",
    "            \n",
    "        if self.data_type in ['E','ER']:\n",
    "            img = self.eeg_specs[row.eeg_id]\n",
    "        elif self.data_type in ['K','KR']:\n",
    "            spec = self.specs[row.spec_id]\n",
    "            imgs = [spec[offset:offset+300,k*100:(k+1)*100].T for k in [0,2,1,3]] # to match kaggle with eeg\n",
    "            img = np.stack(imgs,axis=-1)\n",
    "            # LOG TRANSFORM SPECTROGRAM\n",
    "            img = np.clip(img,np.exp(-4),np.exp(8))\n",
    "            img = np.log(img)\n",
    "            \n",
    "            # STANDARDIZE PER IMAGE\n",
    "            img = np.nan_to_num(img, nan=0.0)    \n",
    "            \n",
    "        mn = img.flatten().min()\n",
    "        mx = img.flatten().max()\n",
    "        ep = 1e-5\n",
    "        img = 255 * (img - mn) / (mx - mn + ep)\n",
    "        \n",
    "        X[0_0+56:100+56,:256,0] = img[:,22:-22,0]\n",
    "        X[100+56:200+56,:256,0] = img[:,22:-22,2]\n",
    "        X[0_0+56:100+56,:256,1] = img[:,22:-22,1]\n",
    "        X[100+56:200+56,:256,1] = img[:,22:-22,3]\n",
    "        X[0_0+56:100+56,:256,2] = img[:,22:-22,2]\n",
    "        X[100+56:200+56,:256,2] = img[:,22:-22,1]\n",
    "        \n",
    "        X[0_0+56:100+56,256:,0] = img[:,22:-22,0]\n",
    "        X[100+56:200+56,256:,0] = img[:,22:-22,1]\n",
    "        X[0_0+56:100+56,256:,1] = img[:,22:-22,2]\n",
    "        X[100+56:200+56,256:,1] = img[:,22:-22,3]\n",
    "        \n",
    "        X[200+56:300+56,:256,0] = img[:,22:-22,0]\n",
    "        X[300+56:400+56,:256,0] = img[:,22:-22,1]\n",
    "        X[200+56:300+56,:256,1] = img[:,22:-22,2]\n",
    "        X[300+56:400+56,:256,1] = img[:,22:-22,3]\n",
    "        X[200+56:300+56,:256,2] = img[:,22:-22,3]\n",
    "        X[300+56:400+56,:256,2] = img[:,22:-22,2]\n",
    "        \n",
    "        X[200+56:300+56,256:,0] = img[:,22:-22,0]\n",
    "        X[300+56:400+56,256:,0] = img[:,22:-22,2]\n",
    "        X[200+56:300+56,256:,1] = img[:,22:-22,1]\n",
    "        X[300+56:400+56,256:,1] = img[:,22:-22,3]\n",
    "        \n",
    "        if self.mode!='test':\n",
    "            y[:] = row[TARGETS]\n",
    "        \n",
    "        return X,y\n",
    "    \n",
    "    def generate_raw(self,index):\n",
    "        if USE_PROCESSED and self.mode!='test':\n",
    "            X = np.zeros((2_000,8),dtype='float32')\n",
    "            y = np.zeros((6,),dtype='float32')\n",
    "            row = self.data.iloc[index]\n",
    "            X = self.raw_eegs[row.eeg_id]\n",
    "            y[:] = row[TARGETS]\n",
    "            return X,y\n",
    "        \n",
    "        X = np.zeros((10_000,8),dtype='float32')\n",
    "        y = np.zeros((6,),dtype='float32')\n",
    "        \n",
    "        row = self.data.iloc[index]\n",
    "        eeg = self.raw_eegs[row.eeg_id]\n",
    "            \n",
    "        # FEATURE ENGINEER\n",
    "        X[:,0] = eeg[:,FEAT2IDX['Fp1']] - eeg[:,FEAT2IDX['T3']]\n",
    "        X[:,1] = eeg[:,FEAT2IDX['T3']] - eeg[:,FEAT2IDX['O1']]\n",
    "            \n",
    "        X[:,2] = eeg[:,FEAT2IDX['Fp1']] - eeg[:,FEAT2IDX['C3']]\n",
    "        X[:,3] = eeg[:,FEAT2IDX['C3']] - eeg[:,FEAT2IDX['O1']]\n",
    "            \n",
    "        X[:,4] = eeg[:,FEAT2IDX['Fp2']] - eeg[:,FEAT2IDX['C4']]\n",
    "        X[:,5] = eeg[:,FEAT2IDX['C4']] - eeg[:,FEAT2IDX['O2']]\n",
    "            \n",
    "        X[:,6] = eeg[:,FEAT2IDX['Fp2']] - eeg[:,FEAT2IDX['T4']]\n",
    "        X[:,7] = eeg[:,FEAT2IDX['T4']] - eeg[:,FEAT2IDX['O2']]\n",
    "            \n",
    "        # STANDARDIZE\n",
    "        X = np.clip(X,-1024,1024)\n",
    "        X = np.nan_to_num(X, nan=0) / 32.0\n",
    "            \n",
    "        # BUTTER LOW-PASS FILTER\n",
    "        X = self.butter_lowpass_filter(X)\n",
    "        # Downsample\n",
    "        X = X[::5,:]\n",
    "        \n",
    "        if self.mode!='test':\n",
    "            y[:] = row[TARGETS]\n",
    "                \n",
    "        return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e599e4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:18:06.734946Z",
     "iopub.status.busy": "2024-03-15T23:18:06.734640Z",
     "iopub.status.idle": "2024-03-15T23:18:06.743284Z",
     "shell.execute_reply": "2024-03-15T23:18:06.742351Z"
    },
    "papermill": {
     "duration": 0.027469,
     "end_time": "2024-03-15T23:18:06.745328",
     "exception": false,
     "start_time": "2024-03-15T23:18:06.717859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset(data, mode, data_type, specs, eeg_specs, raw_eegs, augment=False,\n",
    "                   batch_size=8):    \n",
    "    if data_type in ['K','E','KE', 'K+E']: \n",
    "        inp = tf.TensorSpec(shape=(512,512,3), dtype=tf.float32)\n",
    "    elif data_type in ['KR','ER','KER']:\n",
    "        inp = (tf.TensorSpec(shape=(512,512,3), dtype=tf.float32), \n",
    "               tf.TensorSpec(shape=(2000,8), dtype=tf.float32))\n",
    "    elif data_type in ['R']:\n",
    "        inp = tf.TensorSpec(shape=(2000,8), dtype=tf.float32)\n",
    "\n",
    "    output_signature = (inp, tf.TensorSpec(shape=(6,), dtype=tf.float32))\n",
    "    \n",
    "    \n",
    "    # Create the data generator\n",
    "    gen = DataGenerator(data, specs, eeg_specs, raw_eegs, augment, mode, data_type)\n",
    "    # Create the dataset from data generator\n",
    "    dataset = tf.data.Dataset.from_generator(generator=gen,\n",
    "                                             output_signature=output_signature).batch(batch_size * strategy.num_replicas_in_sync)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95743a30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:18:06.777628Z",
     "iopub.status.busy": "2024-03-15T23:18:06.777304Z",
     "iopub.status.idle": "2024-03-15T23:18:06.790570Z",
     "shell.execute_reply": "2024-03-15T23:18:06.789775Z"
    },
    "papermill": {
     "duration": 0.031088,
     "end_time": "2024-03-15T23:18:06.792371",
     "exception": false,
     "start_time": "2024-03-15T23:18:06.761283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def spectrogram_from_eeg(parquet_path):    \n",
    "    # LOAD MIDDLE 50 SECONDS OF EEG SERIES\n",
    "    eeg = pd.read_parquet(parquet_path)\n",
    "    middle = (len(eeg)-10_000)//2\n",
    "    eeg = eeg.iloc[middle:middle+10_000]\n",
    "    \n",
    "    # VARIABLE TO HOLD SPECTROGRAM\n",
    "    img = np.zeros((100,300,4) ,dtype='float32')\n",
    "\n",
    "    for k in range(4):\n",
    "        COLS = FEATS[k]\n",
    "        \n",
    "        for kk in range(4):\n",
    "            # FILL NANS\n",
    "            x1 = eeg[COLS[kk]].values\n",
    "            x2 = eeg[COLS[kk+1]].values\n",
    "            m = np.nanmean(x1)\n",
    "            if np.isnan(x1).mean()<1: \n",
    "                x1 = np.nan_to_num(x1,nan=m)\n",
    "            else: \n",
    "                x1[:] = 0\n",
    "            m = np.nanmean(x2)\n",
    "            if np.isnan(x2).mean()<1: \n",
    "                x2 = np.nan_to_num(x2,nan=m)\n",
    "            else: \n",
    "                x2[:] = 0\n",
    "                \n",
    "            # COMPUTE PAIR DIFFERENCES\n",
    "            x = x1 - x2\n",
    "\n",
    "            # RAW SPECTROGRAM\n",
    "            mel_spec = librosa.feature.melspectrogram(y=x, sr=200, hop_length=len(x)//300, \n",
    "                                  n_fft=1024, n_mels=100, fmin=0, fmax=20, win_length=128)\n",
    "            \n",
    "            # LOG TRANSFORM\n",
    "            width = (mel_spec.shape[1]//30)*30\n",
    "            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).astype(np.float32)[:,:width]\n",
    "            img[:,:,k] += mel_spec_db\n",
    "                \n",
    "        # AVERAGE THE 4 MONTAGE DIFFERENCES\n",
    "        img[:,:,k] /= 4.0\n",
    "    return img\n",
    "# Read EEG from par files\n",
    "def eeg_from_parquet(parquet_path):\n",
    "    eeg = pd.read_parquet(parquet_path, columns=FEATS2)\n",
    "    rows = len(eeg)\n",
    "    offset = (rows-10_000)//2\n",
    "    eeg = eeg.iloc[offset:offset+10_000]\n",
    "    data = np.zeros((10_000,len(FEATS2)))\n",
    "    for j,col in enumerate(FEATS2):\n",
    "        \n",
    "        # FILL NAN\n",
    "        x = eeg[col].values.astype('float32')\n",
    "        m = np.nanmean(x)\n",
    "        if np.isnan(x).mean()<1: x = np.nan_to_num(x,nan=m)\n",
    "        else: x[:] = 0\n",
    "        \n",
    "        data[:,j] = x\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "039b2865",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:18:06.823610Z",
     "iopub.status.busy": "2024-03-15T23:18:06.823293Z",
     "iopub.status.idle": "2024-03-15T23:18:06.830139Z",
     "shell.execute_reply": "2024-03-15T23:18:06.829438Z"
    },
    "papermill": {
     "duration": 0.024408,
     "end_time": "2024-03-15T23:18:06.832162",
     "exception": false,
     "start_time": "2024-03-15T23:18:06.807754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_spec_model(hybrid=False):\n",
    "    LOAD_BACKBONE_FROM = '/kaggle/input/efficientnetb-tf-keras/EfficientNetB2.h5'\n",
    "    base_model = load_model(f'{LOAD_BACKBONE_FROM}')\n",
    "    \n",
    "    inp = tf.keras.layers.Input((512,512,3))        \n",
    "    x = base_model(inp)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    if not hybrid:\n",
    "        x = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(x)\n",
    "    # Create the model\n",
    "    model_spec = tf.keras.Model(inputs=inp, outputs=x)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "    loss = tf.keras.losses.KLDivergence()\n",
    "    model_spec.compile(loss=loss, optimizer=opt)\n",
    "    return model_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e30e34e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:18:06.864806Z",
     "iopub.status.busy": "2024-03-15T23:18:06.864507Z",
     "iopub.status.idle": "2024-03-15T23:18:06.882233Z",
     "shell.execute_reply": "2024-03-15T23:18:06.881481Z"
    },
    "papermill": {
     "duration": 0.037076,
     "end_time": "2024-03-15T23:18:06.884160",
     "exception": false,
     "start_time": "2024-03-15T23:18:06.847084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wave_block(x, filters, kernel_size, n):\n",
    "    dilation_rates = [2**i for i in range(n)]\n",
    "    x = Conv1D(filters = filters,\n",
    "               kernel_size = 1,\n",
    "               padding = 'same')(x)\n",
    "    res_x = x\n",
    "    for dilation_rate in dilation_rates:\n",
    "        tanh_out = Conv1D(filters = filters,\n",
    "                          kernel_size = kernel_size,\n",
    "                          padding = 'same', \n",
    "                          activation = 'tanh', \n",
    "                          dilation_rate = dilation_rate)(x)\n",
    "        sigm_out = Conv1D(filters = filters,\n",
    "                          kernel_size = kernel_size,\n",
    "                          padding = 'same',\n",
    "                          activation = 'sigmoid', \n",
    "                          dilation_rate = dilation_rate)(x)\n",
    "        x = Multiply()([tanh_out, sigm_out])\n",
    "        x = Conv1D(filters = filters,\n",
    "                   kernel_size = 1,\n",
    "                   padding = 'same')(x)\n",
    "        res_x = Add()([res_x, x])\n",
    "    return res_x\n",
    "        \n",
    "def build_wave_model(hybrid=False):\n",
    "    # INPUT \n",
    "    inp = tf.keras.Input(shape=(2_000,8))\n",
    "\n",
    "    ############\n",
    "    # FEATURE EXTRACTION SUB MODEL\n",
    "    inp2 = tf.keras.Input(shape=(2_000,1))\n",
    "    x = wave_block(inp2, 8, 4, 6)\n",
    "    x = wave_block(x, 16, 4, 6)\n",
    "    x = wave_block(x, 32, 4, 6)\n",
    "    x = wave_block(x, 64, 4, 6)\n",
    "    base_model = tf.keras.Model(inputs=inp2, outputs=x)\n",
    "    ###########\n",
    "\n",
    "    # LEFT TEMPORAL CHAIN\n",
    "    x1 = base_model(inp[:,:,0:1])\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "    x2 = base_model(inp[:,:,1:2])\n",
    "    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n",
    "    z1 = tf.keras.layers.Average()([x1,x2])\n",
    "\n",
    "    # LEFT PARASAGITTAL CHAIN\n",
    "    x1 = base_model(inp[:,:,2:3])\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "    x2 = base_model(inp[:,:,3:4])\n",
    "    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n",
    "    z2 = tf.keras.layers.Average()([x1,x2])\n",
    "\n",
    "    # RIGHT PARASAGITTAL CHAIN\n",
    "    x1 = base_model(inp[:,:,4:5])\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "    x2 = base_model(inp[:,:,5:6])\n",
    "    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n",
    "    z3 = tf.keras.layers.Average()([x1,x2])\n",
    "\n",
    "    # RIGHT TEMPORAL CHAIN\n",
    "    x1 = base_model(inp[:,:,6:7])\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "    x2 = base_model(inp[:,:,7:8])\n",
    "    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n",
    "    z4 = tf.keras.layers.Average()([x1,x2])\n",
    "\n",
    "    # COMBINE CHAINS\n",
    "    y = tf.keras.layers.Concatenate()([z1,z2,z3,z4])\n",
    "    if not hybrid:\n",
    "        y = tf.keras.layers.Dense(64, activation='relu')(y)\n",
    "        y = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(y)\n",
    "\n",
    "    # COMPILE MODEL\n",
    "    model_wave = tf.keras.Model(inputs=inp, outputs=y)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "    loss = tf.keras.losses.KLDivergence()\n",
    "    model_wave.compile(loss=loss, optimizer = opt)\n",
    "    return model_wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9cab1d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:18:06.916275Z",
     "iopub.status.busy": "2024-03-15T23:18:06.915966Z",
     "iopub.status.idle": "2024-03-15T23:18:06.922765Z",
     "shell.execute_reply": "2024-03-15T23:18:06.921822Z"
    },
    "papermill": {
     "duration": 0.025183,
     "end_time": "2024-03-15T23:18:06.924738",
     "exception": false,
     "start_time": "2024-03-15T23:18:06.899555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_hyrbid_model():\n",
    "    model_spec = build_spec_model(hybrid=True)\n",
    "    model_wave = build_wave_model(hybrid=True)\n",
    "    inputs = [model_spec.input, model_wave.input]\n",
    "    x = [model_spec.output, model_wave.output]\n",
    "    x = tf.keras.layers.Concatenate()(x)\n",
    "    x = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(x)\n",
    "\n",
    "    # COMPILE MODEL\n",
    "    model_hybrid = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "    loss = tf.keras.losses.KLDivergence()\n",
    "    model_hybrid.compile(loss=loss, optimizer = opt)\n",
    "    return model_hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e146d3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:18:06.955142Z",
     "iopub.status.busy": "2024-03-15T23:18:06.954873Z",
     "iopub.status.idle": "2024-03-15T23:18:34.537248Z",
     "shell.execute_reply": "2024-03-15T23:18:34.536336Z"
    },
    "papermill": {
     "duration": 27.599962,
     "end_time": "2024-03-15T23:18:34.539787",
     "exception": false,
     "start_time": "2024-03-15T23:18:06.939825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_spec = build_spec_model(hybrid=False)\n",
    "model_wave = build_wave_model(hybrid=False)\n",
    "model_hybrid = build_hyrbid_model()\n",
    "# print(model_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3fc2002b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:18:34.573364Z",
     "iopub.status.busy": "2024-03-15T23:18:34.572786Z",
     "iopub.status.idle": "2024-03-15T23:18:34.578012Z",
     "shell.execute_reply": "2024-03-15T23:18:34.576993Z"
    },
    "papermill": {
     "duration": 0.024057,
     "end_time": "2024-03-15T23:18:34.580115",
     "exception": false,
     "start_time": "2024-03-15T23:18:34.556058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "VERS ={\n",
    "    'K': 43, # Kaggle spectrogram\n",
    "    'E': 42, # EEG spectrogram \n",
    "    'R': 37, # Raw EEG \n",
    "    'KE': 47, # Kaggle + EEG spectrogram\n",
    "    'KR': 48, # Kaggle spectrogram + Raw EEG \n",
    "    'ER': 49, # EEG spectrogram + Raw EEG  \n",
    "    'KER': 50, # Kaggle + EGG spectrogram + Raw EEG \n",
    "    'K+E': 51, # Kaggle + EEG spectrogram + Data augumentation\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "962b79f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:18:34.611772Z",
     "iopub.status.busy": "2024-03-15T23:18:34.611474Z",
     "iopub.status.idle": "2024-03-15T23:18:34.628378Z",
     "shell.execute_reply": "2024-03-15T23:18:34.627435Z"
    },
    "papermill": {
     "duration": 0.034948,
     "end_time": "2024-03-15T23:18:34.630321",
     "exception": false,
     "start_time": "2024-03-15T23:18:34.595373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "import tensorflow.keras.backend as K, gc\n",
    "\n",
    "# Load training data\n",
    "def add_kl(data):\n",
    "    labels = data[TARGETS].values + 1e-5 \n",
    "    data['kl'] = tf.keras.losses.KLDivergence(reduction='none')(np.array([[1/6]*6]*len(data)), labels)\n",
    "    return data\n",
    "    \n",
    "def load_train_data():\n",
    "    # Load training features\n",
    "    train = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/train.csv')\n",
    "    META = ['spectrogram_id','spectrogram_label_offset_seconds','patient_id','expert_consensus']\n",
    "    train = train.groupby('eeg_id')[META+TARGETS].agg({**{m:'first' for m in META},**{t:'sum' for t in TARGETS}}).reset_index() \n",
    "    train[TARGETS] = train[TARGETS]/train[TARGETS].values.sum(axis=1,keepdims=True)\n",
    "    train.columns = ['eeg_id','spec_id','offset','patient_id','target'] + TARGETS\n",
    "    train = add_kl(train)\n",
    "    # display(train.head(3))\n",
    "    # Read all spectrograms\n",
    "    train_specs = np.load('/kaggle/input/brain-spectrograms/specs.npy',allow_pickle=True).item()\n",
    "    # Read all EEG Spectrograms\n",
    "    train_eegs = np.load('/kaggle/input/eeg-spectrograms/eeg_specs.npy',allow_pickle=True).item()\n",
    "    # Read all raw EGG signals\n",
    "    train_raw_eegs = np.load('/kaggle/input/hms-eeg/eegs_processed.npy',allow_pickle=True).item()\n",
    "    return train, train_specs, train_eegs, train_raw_eegs\n",
    "\n",
    "# Compute the score using KLDivergence \n",
    "# KL measures how much prediction prob distribution differs from actual prob distribution\n",
    "def compute_score(y_true, y_pred):\n",
    "    kl = tf.keras.metrics.KLDivergence()\n",
    "    return kl(y_true, y_pred)\n",
    "\n",
    "# Submission ON TEST with an individual\n",
    "def preds_with_a_model(data_type):\n",
    "    VER=VERS[data_type]\n",
    "    train, train_specs, train_eegs, train_raw_eegs = load_train_data()\n",
    "    # Make the predictions with 5 fold models\n",
    "    all_oof = []\n",
    "    all_true = []\n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "    for i, (_, valid_index) in enumerate(gkf.split(train, train.target, train.patient_id)):   \n",
    "        print(f'### Fold {i+1}')\n",
    "        true_values = train.iloc[valid_index][TARGETS].values  \n",
    "        all_true.append(true_values)\n",
    "        # Valid dataset\n",
    "        val_df = train.iloc[valid_index]\n",
    "        val_dataset = create_dataset(val_df, mode='train', data_type=data_type,\n",
    "                                     specs=train_specs, eeg_specs=train_eegs, \n",
    "                                     raw_eegs=train_raw_eegs)\n",
    "        print(f'valid size {len(valid_index)}')\n",
    "        model = None\n",
    "        if data_type in ['K','E','KE']:\n",
    "            model = model_spec\n",
    "        elif data_type in ['R']:\n",
    "            model = model_wave\n",
    "        elif data_type in ['KR','ER','KER']:\n",
    "            model = model_hybrid\n",
    "        # EEG's, Kaggle's spectrograms and Raw model\n",
    "        model.load_weights(f'{LOAD_MODELS_FROM}/model_{data_type}_{VER}_{i}.weights.h5')\n",
    "        oof = model.predict(val_dataset, verbose=1)\n",
    "        print(f\"oof shape = {np.array(oof).shape}\")\n",
    "        all_oof.append(oof)           \n",
    "        del val_df, val_dataset\n",
    "        clear_memory()\n",
    "\n",
    "    # Compute the score with predictions and actual labels\n",
    "    all_oof = np.concatenate(all_oof)\n",
    "    all_true = np.concatenate(all_true)\n",
    "    print(f\"all_oof shape = {all_oof.shape} and all_true shape = {all_true.shape}\")\n",
    "    print(f'CV KL SCORE of {data_type} model: {compute_score(all_true,all_oof)}')\n",
    "    del train, train_specs, train_eegs, train_raw_eegs\n",
    "    clear_memory()\n",
    "    \n",
    "# # Compute the cross validation score for a model\n",
    "# preds_with_a_model(data_type='KE')\n",
    "# sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abbc4d5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:18:34.661329Z",
     "iopub.status.busy": "2024-03-15T23:18:34.661046Z",
     "iopub.status.idle": "2024-03-15T23:18:34.674579Z",
     "shell.execute_reply": "2024-03-15T23:18:34.673673Z"
    },
    "papermill": {
     "duration": 0.031672,
     "end_time": "2024-03-15T23:18:34.676684",
     "exception": false,
     "start_time": "2024-03-15T23:18:34.645012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape (1, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spec_id</th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>853520</td>\n",
       "      <td>3911565283</td>\n",
       "      <td>6885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spec_id      eeg_id  patient_id\n",
       "0   853520  3911565283        6885"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load testing features\n",
    "test = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/test.csv')\n",
    "# Rename\n",
    "test = test.rename({'spectrogram_id':'spec_id'},axis=1)\n",
    "print('Test shape',test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "437c18b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:18:34.709446Z",
     "iopub.status.busy": "2024-03-15T23:18:34.709178Z",
     "iopub.status.idle": "2024-03-15T23:18:34.745957Z",
     "shell.execute_reply": "2024-03-15T23:18:34.744929Z"
    },
    "papermill": {
     "duration": 0.055725,
     "end_time": "2024-03-15T23:18:34.748070",
     "exception": false,
     "start_time": "2024-03-15T23:18:34.692345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 test spectrogram parquets\n"
     ]
    }
   ],
   "source": [
    "# Read all spectrograms\n",
    "PATH = '/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms'\n",
    "files = os.listdir(PATH)\n",
    "print(f'There are {len(files)} test spectrogram parquets')\n",
    "test_specs = {}\n",
    "for i,f in enumerate(files):\n",
    "    tmp = pd.read_parquet(f'{PATH}/{f}')\n",
    "    name = int(f.split('.')[0])\n",
    "    test_specs[name] = tmp.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdd60e79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:18:34.780873Z",
     "iopub.status.busy": "2024-03-15T23:18:34.780598Z",
     "iopub.status.idle": "2024-03-15T23:18:45.020324Z",
     "shell.execute_reply": "2024-03-15T23:18:45.018967Z"
    },
    "papermill": {
     "duration": 10.259572,
     "end_time": "2024-03-15T23:18:45.024027",
     "exception": false,
     "start_time": "2024-03-15T23:18:34.764455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Test EEG to Spectrograms...\n"
     ]
    }
   ],
   "source": [
    "# Read all EEG Spectrograms\n",
    "PATH = '/kaggle/input/hms-harmful-brain-activity-classification/test_eegs'\n",
    "DISPLAY = 0\n",
    "EEG_IDS = test.eeg_id.unique()\n",
    "test_eeg_specs = {}\n",
    "print('Converting Test EEG to Spectrograms...')\n",
    "for i,eeg_id in enumerate(EEG_IDS):\n",
    "    # CREATE SPECTROGRAM FROM EEG PARQUET\n",
    "    test_eeg_specs[eeg_id] = spectrogram_from_eeg(f'{PATH}/{eeg_id}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "861ba0eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:18:45.097347Z",
     "iopub.status.busy": "2024-03-15T23:18:45.095607Z",
     "iopub.status.idle": "2024-03-15T23:18:45.130452Z",
     "shell.execute_reply": "2024-03-15T23:18:45.129326Z"
    },
    "papermill": {
     "duration": 0.075601,
     "end_time": "2024-03-15T23:18:45.134178",
     "exception": false,
     "start_time": "2024-03-15T23:18:45.058577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Test EEG parquets...\n"
     ]
    }
   ],
   "source": [
    "# Read all RAW EEG Signals\n",
    "test_raw_eegs = {}\n",
    "EEG_IDS = test.eeg_id.unique()\n",
    "PATH = '/kaggle/input/hms-harmful-brain-activity-classification/test_eegs'\n",
    "print('Processing Test EEG parquets...')\n",
    "for i,eeg_id in enumerate(EEG_IDS):\n",
    "    # SAVE EEG TO PYTHON DICTIONARY OF NUMPY ARRAYS\n",
    "    test_raw_eegs[eeg_id] = eeg_from_parquet(f'{PATH}/{eeg_id}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4e68c41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:18:45.178768Z",
     "iopub.status.busy": "2024-03-15T23:18:45.178410Z",
     "iopub.status.idle": "2024-03-15T23:18:45.374113Z",
     "shell.execute_reply": "2024-03-15T23:18:45.373256Z"
    },
    "papermill": {
     "duration": 0.215426,
     "end_time": "2024-03-15T23:18:45.376655",
     "exception": false,
     "start_time": "2024-03-15T23:18:45.161229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {'specs':test_specs, 'eeg_specs':test_eeg_specs, 'raw_eegs':test_raw_eegs}\n",
    "test_datasets ={\n",
    "    'K': create_dataset(test, data_type='K', mode='test', **params),\n",
    "    'E': create_dataset(test, data_type='E', mode='test', **params),\n",
    "    'R': create_dataset(test, data_type='R', mode='test', **params),\n",
    "    'KE': create_dataset(test, data_type='KE', mode='test', **params),\n",
    "    'KR': create_dataset(test, data_type='KR', mode='test', **params),\n",
    "    'ER': create_dataset(test, data_type='ER', mode='test', **params),\n",
    "    'KER': create_dataset(test, data_type='KER', mode='test', **params),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6e2c5ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:18:45.414943Z",
     "iopub.status.busy": "2024-03-15T23:18:45.414643Z",
     "iopub.status.idle": "2024-03-15T23:19:03.518753Z",
     "shell.execute_reply": "2024-03-15T23:19:03.517737Z"
    },
    "papermill": {
     "duration": 18.124738,
     "end_time": "2024-03-15T23:19:03.521096",
     "exception": false,
     "start_time": "2024-03-15T23:18:45.396358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "Fold 2\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "Fold 3\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "Fold 4\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "Fold 5\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "Test preds shape (1, 6)\n"
     ]
    }
   ],
   "source": [
    "LBs = [0.41,0.39,0.41,0.37,0.39,0.38,0.36] # K|E|R|KE|KR|ER|KER for weighted ensemble we use LBs of each model\n",
    "\n",
    "def make_preds(i, data_type):\n",
    "    VER = VERS[data_type]\n",
    "    test_dataset = test_datasets[data_type]\n",
    "    model_preds = None\n",
    "    if data_type in ['K','E','KE']:\n",
    "        model_spec.load_weights(f'{LOAD_MODELS_FROM}/model_{data_type}_{VER}_{i}.weights.h5')\n",
    "        model_preds = model_spec.predict(test_dataset, verbose=1)\n",
    "    elif data_type in ['R']:\n",
    "        model_wave.load_weights(f'{LOAD_MODELS_FROM}/model_{data_type}_{VER}_{i}.weights.h5')\n",
    "        model_preds = model_wave.predict(test_dataset, verbose=1)\n",
    "    elif data_type in ['KR','ER','KER']:\n",
    "        model_hybrid.load_weights(f'{LOAD_MODELS_FROM}/model_{data_type}_{VER}_{i}.weights.h5')\n",
    "        model_preds = model_hybrid.predict(test_dataset, verbose=1)\n",
    "    clear_memory()\n",
    "    return model_preds\n",
    "\n",
    "# Submission ON TEST with ensemble\n",
    "def preds_with_ensemble():\n",
    "    preds = []\n",
    "    # LB SCORE WEIGHTS FOR EACH MODEL\n",
    "    lbs = 1 - np.array(LBs)\n",
    "    weights = lbs/lbs.sum()\n",
    "    for i in range(5):\n",
    "        print(f'Fold {i+1}')\n",
    "        # 'KE' model (Kaggle and EEG spectrogram)\n",
    "        preds.append(make_preds(i, data_type='KE'))\n",
    "        \n",
    "        ## 'K' model (Kaggle spectrograms)\n",
    "#         model_spec.load_weights(f'{LOAD_MODELS_FROM}/model_K_{VER_K}_{i}.weights.h5')\n",
    "#         pred_K = model_spec.predict(test_dataset_K, verbose=1)\n",
    "        ## EEG's spectrogram model\n",
    "#         model_spec.load_weights(f'{LOAD_MODELS_FROM}/model_E_{VER_E}_{i}.weights.h5')\n",
    "#         pred_E = model_spec.predict(test_dataset_E, verbose=1)\n",
    "        # EEG Raw wavenet model\n",
    "#         model_wave.load_weights(f'{LOAD_MODELS_FROM}/model_R_{VER_R}_{i}.weights.h5')\n",
    "#         pred_R = model_wave.predict(test_dataset_R, verbose=1)\n",
    "       \n",
    "#         # Kaggle's spectrogram and Raw model\n",
    "#         model_hybrid.load_weights(f'{LOAD_MODELS_FROM}/model_KR_{VER_KR}_{i}.weights.h5')\n",
    "#         pred_KR = model_hybrid.predict(test_dataset_KR, verbose=1)\n",
    "#         # EEG's spectrogram and Raw model\n",
    "#         model_hybrid.load_weights(f'{LOAD_MODELS_FROM}/model_ER_{VER_ER}_{i}.weights.h5')\n",
    "#         pred_ER = model_hybrid.predict(test_dataset_ER, verbose=1)\n",
    "#         # EEG's, Kaggle's spectrograms and Raw model\n",
    "#         model_hybrid.load_weights(f'{LOAD_MODELS_FROM}/model_KER_{VER_KER}_{i}.weights.h5')\n",
    "#         pred_KER = model_hybrid.predict(test_dataset_KER, verbose=1)\n",
    "        # Combine the predictions from all the model with different weights \n",
    "#         pred = np.array([pred_K,pred_E,pred_R,pred_KE,pred_KR,pred_ER,pred_KER])\n",
    "#         pred = np.average(pred,axis=0,weights=weights)\n",
    "        \n",
    "#         preds.append(pred)\n",
    "    # Average the prediction of all five fold models\n",
    "    avg_pred = np.mean(preds, axis=0)\n",
    "    clear_memory()\n",
    "    return avg_pred\n",
    "# Prediction with \n",
    "pred_final = preds_with_ensemble()\n",
    "print('Test preds shape', pred_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7528b8ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:19:03.556860Z",
     "iopub.status.busy": "2024-03-15T23:19:03.556196Z",
     "iopub.status.idle": "2024-03-15T23:19:03.572593Z",
     "shell.execute_reply": "2024-03-15T23:19:03.571570Z"
    },
    "papermill": {
     "duration": 0.036652,
     "end_time": "2024-03-15T23:19:03.574936",
     "exception": false,
     "start_time": "2024-03-15T23:19:03.538284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submissionn shape (1, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3911565283</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.073478</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.527459</td>\n",
       "      <td>0.011426</td>\n",
       "      <td>0.298592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
       "0  3911565283        0.0887  0.073478  0.000345   0.527459   0.011426   \n",
       "\n",
       "   other_vote  \n",
       "0    0.298592  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub2 = pd.DataFrame({'eeg_id':test.eeg_id.values})\n",
    "sub2[TARGETS] = pred_final\n",
    "print('Submissionn shape',sub2.shape)\n",
    "display(sub2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43a1cfe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:19:03.613080Z",
     "iopub.status.busy": "2024-03-15T23:19:03.612305Z",
     "iopub.status.idle": "2024-03-15T23:19:03.618739Z",
     "shell.execute_reply": "2024-03-15T23:19:03.617803Z"
    },
    "papermill": {
     "duration": 0.026984,
     "end_time": "2024-03-15T23:19:03.620828",
     "exception": false,
     "start_time": "2024-03-15T23:19:03.593844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n"
     ]
    }
   ],
   "source": [
    "print(sub2.iloc[:,-6:].sum(axis=1).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bbc3d1",
   "metadata": {
    "papermill": {
     "duration": 0.016934,
     "end_time": "2024-03-15T23:19:03.654461",
     "exception": false,
     "start_time": "2024-03-15T23:19:03.637527",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model 3 @konstantinboyko   0.36\n",
    "https://www.kaggle.com/code/konstantinboyko/hms-full-validation-2-stage-s-train-infer/notebook?scriptVersionId=166580594"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c707301",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:19:03.689974Z",
     "iopub.status.busy": "2024-03-15T23:19:03.689242Z",
     "iopub.status.idle": "2024-03-15T23:19:04.775205Z",
     "shell.execute_reply": "2024-03-15T23:19:04.773984Z"
    },
    "papermill": {
     "duration": 1.106003,
     "end_time": "2024-03-15T23:19:04.777286",
     "exception": false,
     "start_time": "2024-03-15T23:19:03.671283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ubuntu 22.04.3 LTS\r\n",
      "BUILD_DATE=20240109-221321, CONTAINER_NAME=tf2-gpu/2-13+gpu\n",
      "PyTorch Version:2.0.0, CUDA is available:True, Version CUDA:11.8\n",
      "Device Capability:(7, 5), ['sm_37', 'sm_60', 'sm_70', 'sm_75', 'compute_70', 'compute_75']\n",
      "CuDNN Enabled:True, Version:8900\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Union\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "sys.path.append(\"/kaggle/input/kaggle-kl-div\")\n",
    "from kaggle_kl_div import score\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "!cat /etc/os-release | grep -oP \"PRETTY_NAME=\\\"\\K([^\\\"]*)\"\n",
    "print(f\"BUILD_DATE={os.environ['BUILD_DATE']}, CONTAINER_NAME={os.environ['CONTAINER_NAME']}\")\n",
    "\n",
    "try:\n",
    "    print(\n",
    "        f\"PyTorch Version:{torch.__version__}, CUDA is available:{torch.cuda.is_available()}, Version CUDA:{torch.version.cuda}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Device Capability:{torch.cuda.get_device_capability()}, {torch.cuda.get_arch_list()}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"CuDNN Enabled:{torch.backends.cudnn.enabled}, Version:{torch.backends.cudnn.version()}\"\n",
    "    )\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7d15686",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:19:04.814383Z",
     "iopub.status.busy": "2024-03-15T23:19:04.813434Z",
     "iopub.status.idle": "2024-03-15T23:19:04.824127Z",
     "shell.execute_reply": "2024-03-15T23:19:04.823226Z"
    },
    "papermill": {
     "duration": 0.031315,
     "end_time": "2024-03-15T23:19:04.826111",
     "exception": false,
     "start_time": "2024-03-15T23:19:04.794796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jupyter:True, kaggle:True, local:False\n",
      ".\n",
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "class APP:\n",
    "    jupyter = \"ipykernel\" in globals()\n",
    "    if not jupyter:\n",
    "        try:\n",
    "            if \"IPython\" in globals().get(\"__doc__\", \"\"):\n",
    "                jupyter = True\n",
    "        except Exception as inst:\n",
    "            print(inst)\n",
    "\n",
    "    kaggle = os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\", \"\") != \"\"\n",
    "    local = os.environ.get(\"DOCKER_USING\", \"\") == \"LOCAL\"\n",
    "    date_time_start = dt.datetime.now()\n",
    "    dt_start_ymd_hms = date_time_start.strftime(\"%Y.%m.%d_%H-%M-%S\")\n",
    "\n",
    "    file_run_path = \"\"\n",
    "    if jupyter:\n",
    "        try:\n",
    "            file_run_path = Path(globals().get(\"__vsc_ipynb_file__\", \"\"))\n",
    "        except Exception as inst:\n",
    "            print(inst)\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            file_run_path = Path(__file__)\n",
    "        except Exception as inst:\n",
    "            print(inst)\n",
    "\n",
    "    file_run_name = file_run_path.stem\n",
    "    path_app = file_run_path.parent\n",
    "    path_run = Path(os.getcwd())\n",
    "    path_out = (\n",
    "        Path(\"/kaggle/working\")\n",
    "        if kaggle\n",
    "        else file_run_path / f\"{file_run_name}_{dt_start_ymd_hms}\"\n",
    "    )\n",
    "\n",
    "\n",
    "print(f\"jupyter:{APP.jupyter}, kaggle:{APP.kaggle}, local:{APP.local}\")\n",
    "print(APP.file_run_path)\n",
    "print(APP.path_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4bba10e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:19:04.862449Z",
     "iopub.status.busy": "2024-03-15T23:19:04.862187Z",
     "iopub.status.idle": "2024-03-15T23:19:04.872227Z",
     "shell.execute_reply": "2024-03-15T23:19:04.871390Z"
    },
    "papermill": {
     "duration": 0.030546,
     "end_time": "2024-03-15T23:19:04.874110",
     "exception": false,
     "start_time": "2024-03-15T23:19:04.843564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    VERSION = 93\n",
    "\n",
    "    model_name = \"resnet1d_gru\"\n",
    "\n",
    "    seed = 2024\n",
    "    batch_size = 32\n",
    "    num_workers = 0\n",
    "\n",
    "    fixed_kernel_size = 5\n",
    "    # kernels = [3, 5, 7, 9]\n",
    "    # linear_layer_features = 424\n",
    "    kernels = [3, 5, 7, 9, 11]\n",
    "    #linear_layer_features = 448  # Full Signal = 10_000\n",
    "    #linear_layer_features = 352  # Half Signal = 5_000\n",
    "    linear_layer_features = 304   # 1/5  Signal = 2_000\n",
    "\n",
    "    seq_length = 50  # Second's\n",
    "    sampling_rate = 200  # Hz\n",
    "    nsamples = seq_length * sampling_rate  # Число семплов\n",
    "    out_samples = nsamples // 5\n",
    "\n",
    "    # bandpass_filter = {\"low\": 0.5, \"high\": 20, \"order\": 2}\n",
    "    # rand_filter = {\"probab\": 0.1, \"low\": 10, \"high\": 20, \"band\": 1.0, \"order\": 2}\n",
    "    freq_channels = []  # [(8.0, 12.0)]; [(0.5, 4.5)]\n",
    "    filter_order = 2\n",
    "    random_close_zone = 0.0  # 0.2\n",
    "        \n",
    "    target_cols = [\n",
    "        \"seizure_vote\",\n",
    "        \"lpd_vote\",\n",
    "        \"gpd_vote\",\n",
    "        \"lrda_vote\",\n",
    "        \"grda_vote\",\n",
    "        \"other_vote\",\n",
    "    ]\n",
    "\n",
    "    # target_preds = [x + \"_pred\" for x in target_cols]\n",
    "    # label_to_num = {\"Seizure\": 0, \"LPD\": 1, \"GPD\": 2, \"LRDA\": 3, \"GRDA\": 4, \"Other\": 5}\n",
    "    # num_to_label = {v: k for k, v in label_to_num.items()}\n",
    "\n",
    "    map_features = [\n",
    "        (\"Fp1\", \"T3\"),\n",
    "        (\"T3\", \"O1\"),\n",
    "        (\"Fp1\", \"C3\"),\n",
    "        (\"C3\", \"O1\"),\n",
    "        (\"Fp2\", \"C4\"),\n",
    "        (\"C4\", \"O2\"),\n",
    "        (\"Fp2\", \"T4\"),\n",
    "        (\"T4\", \"O2\"),\n",
    "        #('Fz', 'Cz'), ('Cz', 'Pz'),        \n",
    "    ]\n",
    "\n",
    "    eeg_features = [\"Fp1\", \"T3\", \"C3\", \"O1\", \"Fp2\", \"C4\", \"T4\", \"O2\"]  # 'Fz', 'Cz', 'Pz']\n",
    "        # 'F3', 'P3', 'F7', 'T5', 'Fz', 'Cz', 'Pz', 'F4', 'P4', 'F8', 'T6', 'EKG']                    \n",
    "    feature_to_index = {x: y for x, y in zip(eeg_features, range(len(eeg_features)))}\n",
    "    simple_features = []  # 'Fz', 'Cz', 'Pz', 'EKG'\n",
    "\n",
    "    # eeg_features = [row for row in feature_to_index]\n",
    "    # eeg_feat_size = len(eeg_features)\n",
    "    \n",
    "    n_map_features = len(map_features)\n",
    "    in_channels = n_map_features + n_map_features * len(freq_channels) + len(simple_features)\n",
    "    target_size = len(target_cols)\n",
    "    \n",
    "    PATH = \"/kaggle/input/hms-harmful-brain-activity-classification/\"\n",
    "    test_eeg = \"/kaggle/input/hms-harmful-brain-activity-classification/test_eegs/\"\n",
    "    test_csv = \"/kaggle/input/hms-harmful-brain-activity-classification/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e714c1c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:19:04.911283Z",
     "iopub.status.busy": "2024-03-15T23:19:04.911031Z",
     "iopub.status.idle": "2024-03-15T23:19:04.915762Z",
     "shell.execute_reply": "2024-03-15T23:19:04.914930Z"
    },
    "papermill": {
     "duration": 0.026218,
     "end_time": "2024-03-15T23:19:04.917653",
     "exception": false,
     "start_time": "2024-03-15T23:19:04.891435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "koef_1 = 1.0\n",
    "model_weights = [\n",
    "    {\n",
    "        'bandpass_filter':{'low':0.5, 'high':20, 'order':2}, \n",
    "        'file_data': \n",
    "        [\n",
    "            #{'koef':koef_1, 'file_mask':\"/kaggle/input/hms-resnet1d-gru-weights-v98/pop_1_weight_oof/*_full.pth\"},\n",
    "            #{'koef':koef_1, 'file_mask':\"/kaggle/input/hms-resnet1d-gru-weights-v98/*_full.pth\"},\n",
    "            {'koef':koef_1, 'file_mask':\"/kaggle/input/hms-resnet1d-gru-weights-v98/pop_2_weight_oof/*_full.pth\"},\n",
    "            #{'koef':koef_1, 'file_mask':\"/kaggle/input/hms-resnet1d-gru-weights-v98/pop_3_weight_oof/*_full.pth\"},\n",
    "        ]\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "946b84f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:19:04.953849Z",
     "iopub.status.busy": "2024-03-15T23:19:04.953356Z",
     "iopub.status.idle": "2024-03-15T23:19:04.968187Z",
     "shell.execute_reply": "2024-03-15T23:19:04.967369Z"
    },
    "papermill": {
     "duration": 0.035063,
     "end_time": "2024-03-15T23:19:04.970002",
     "exception": false,
     "start_time": "2024-03-15T23:19:04.934939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_logger(log_file=\"./test.log\"):\n",
    "    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def quantize_data(data, classes):\n",
    "    mu_x = mu_law_encoding(data, classes)\n",
    "    return mu_x  # quantized\n",
    "\n",
    "\n",
    "def mu_law_encoding(data, mu):\n",
    "    mu_x = np.sign(data) * np.log(1 + mu * np.abs(data)) / np.log(mu + 1)\n",
    "    return mu_x\n",
    "\n",
    "\n",
    "def mu_law_expansion(data, mu):\n",
    "    s = np.sign(data) * (np.exp(np.abs(data) * np.log(mu + 1)) - 1) / mu\n",
    "    return s\n",
    "\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    return butter(order, [lowcut, highcut], fs=fs, btype=\"band\")\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "def butter_lowpass_filter(\n",
    "    data, cutoff_freq=20, sampling_rate=CFG.sampling_rate, order=4\n",
    "):\n",
    "    nyquist = 0.5 * sampling_rate\n",
    "    normal_cutoff = cutoff_freq / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype=\"low\", analog=False)\n",
    "    filtered_data = lfilter(b, a, data, axis=0)\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "def denoise_filter(x):\n",
    "    # Частота дискретизации и желаемые частоты среза (в Гц).\n",
    "    # Отфильтруйте шумный сигнал\n",
    "    y = butter_bandpass_filter(x, CFG.lowcut, CFG.highcut, CFG.sampling_rate, order=6)\n",
    "    y = (y + np.roll(y, -1) + np.roll(y, -2) + np.roll(y, -3)) / 4\n",
    "    y = y[0:-1:4]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dcb429d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:19:05.006872Z",
     "iopub.status.busy": "2024-03-15T23:19:05.006623Z",
     "iopub.status.idle": "2024-03-15T23:19:05.017638Z",
     "shell.execute_reply": "2024-03-15T23:19:05.016854Z"
    },
    "papermill": {
     "duration": 0.031653,
     "end_time": "2024-03-15T23:19:05.019546",
     "exception": false,
     "start_time": "2024-03-15T23:19:04.987893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eeg_from_parquet(\n",
    "    parquet_path: str, display: bool = False, seq_length=CFG.seq_length\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Эта функция читает файл паркета и извлекает средние 50 секунд показаний. Затем он заполняет значения NaN\n",
    "    со средним значением (игнорируя NaN).\n",
    "        :param parquet_path: путь к файлу паркета.\n",
    "        :param display: отображать графики ЭЭГ или нет.\n",
    "        :return data: np.array формы (time_steps, eeg_features) -> (10_000, 8)\n",
    "    \"\"\"\n",
    "\n",
    "    # Вырезаем среднюю 50 секундную часть\n",
    "    eeg = pd.read_parquet(parquet_path, columns=CFG.eeg_features)\n",
    "    rows = len(eeg)\n",
    "\n",
    "    # начало смещения данных, чтобы забрать середину\n",
    "    offset = (rows - CFG.nsamples) // 2\n",
    "\n",
    "    # средние 50 секунд, имеет одинаковое количество показаний слева и справа\n",
    "    eeg = eeg.iloc[offset : offset + CFG.nsamples]\n",
    "\n",
    "    if display:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        offset = 0\n",
    "\n",
    "    # Конвертировать в numpy\n",
    "\n",
    "    # создать заполнитель той же формы с нулями\n",
    "    data = np.zeros((CFG.nsamples, len(CFG.eeg_features)))\n",
    "\n",
    "    for index, feature in enumerate(CFG.eeg_features):\n",
    "        x = eeg[feature].values.astype(\"float32\")  # конвертировать в float32\n",
    "\n",
    "        # Вычисляет среднее арифметическое вдоль указанной оси, игнорируя NaN.\n",
    "        mean = np.nanmean(x)\n",
    "        nan_percentage = np.isnan(x).mean()  # percentage of NaN values in feature\n",
    "\n",
    "        # Заполнение значения Nan\n",
    "        # Поэлементная проверка на NaN и возврат результата в виде логического массива.\n",
    "        if nan_percentage < 1:  # если некоторые значения равны Nan, но не все\n",
    "            x = np.nan_to_num(x, nan=mean)\n",
    "        else:  # если все значения — Nan\n",
    "            x[:] = 0\n",
    "        data[:, index] = x\n",
    "\n",
    "        if display:\n",
    "            if index != 0:\n",
    "                offset += x.max()\n",
    "            plt.plot(range(CFG.nsamples), x - offset, label=feature)\n",
    "            offset -= x.min()\n",
    "\n",
    "    if display:\n",
    "        plt.legend()\n",
    "        name = parquet_path.split(\"/\")[-1].split(\".\")[0]\n",
    "        plt.yticks([])\n",
    "        plt.title(f\"EEG {name}\", size=16)\n",
    "        plt.show()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64155131",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:19:05.056893Z",
     "iopub.status.busy": "2024-03-15T23:19:05.056535Z",
     "iopub.status.idle": "2024-03-15T23:19:05.081876Z",
     "shell.execute_reply": "2024-03-15T23:19:05.081016Z"
    },
    "papermill": {
     "duration": 0.04698,
     "end_time": "2024-03-15T23:19:05.083904",
     "exception": false,
     "start_time": "2024-03-15T23:19:05.036924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        batch_size: int,\n",
    "        eegs: Dict[int, np.ndarray],\n",
    "        mode: str = \"train\",\n",
    "        downsample: int = None,\n",
    "        bandpass_filter: Dict[str, Union[int, float]] = None,\n",
    "        rand_filter: Dict[str, Union[int, float]] = None,\n",
    "    ):\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.mode = mode\n",
    "        self.eegs = eegs\n",
    "        self.downsample = downsample\n",
    "        self.bandpass_filter = bandpass_filter\n",
    "        self.rand_filter = rand_filter\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Length of dataset.\n",
    "        \"\"\"\n",
    "        # Обозначает количество пакетов за эпоху\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Get one item.\n",
    "        \"\"\"\n",
    "        # Сгенерировать один пакет данных\n",
    "        X, y_prob = self.__data_generation(index)\n",
    "        if self.downsample is not None:\n",
    "            X = X[:: self.downsample, :]\n",
    "        output = {\n",
    "            \"eeg\": torch.tensor(X, dtype=torch.float32),\n",
    "            \"labels\": torch.tensor(y_prob, dtype=torch.float32),\n",
    "        }\n",
    "        return output\n",
    "\n",
    "    def __data_generation(self, index):\n",
    "        # Генерирует данные, содержащие образцы размера партии\n",
    "        X = np.zeros(\n",
    "            (CFG.out_samples, CFG.in_channels), dtype=\"float32\"\n",
    "        )  # Size=(10000, 14)\n",
    "\n",
    "        row = self.df.iloc[index]  # Строка Pandas\n",
    "        data = self.eegs[row.eeg_id]  # Size=(10000, 8)\n",
    "        if CFG.nsamples != CFG.out_samples:\n",
    "            if self.mode != \"train\":\n",
    "                offset = (CFG.nsamples - CFG.out_samples) // 2\n",
    "            else:\n",
    "                #offset = random.randint(0, CFG.nsamples - CFG.out_samples)                \n",
    "                offset = ((CFG.nsamples - CFG.out_samples) * random.randint(0, 1000)) // 1000\n",
    "            data = data[offset:offset+CFG.out_samples,:]\n",
    "\n",
    "        for i, (feat_a, feat_b) in enumerate(CFG.map_features):\n",
    "            if self.mode == \"train\" and CFG.random_close_zone > 0 and random.uniform(0.0, 1.0) <= CFG.random_close_zone:\n",
    "                continue\n",
    "                \n",
    "            diff_feat = (\n",
    "                data[:, CFG.feature_to_index[feat_a]]\n",
    "                - data[:, CFG.feature_to_index[feat_b]]\n",
    "            )  # Size=(10000,)\n",
    "\n",
    "            if not self.bandpass_filter is None:\n",
    "                diff_feat = butter_bandpass_filter(\n",
    "                    diff_feat,\n",
    "                    self.bandpass_filter[\"low\"],\n",
    "                    self.bandpass_filter[\"high\"],\n",
    "                    CFG.sampling_rate,\n",
    "                    order=self.bandpass_filter[\"order\"],\n",
    "                )\n",
    "                    \n",
    "            if (\n",
    "                self.mode == \"train\"\n",
    "                and not self.rand_filter is None\n",
    "                and random.uniform(0.0, 1.0) <= self.rand_filter[\"probab\"]\n",
    "            ):\n",
    "                lowcut = random.randint(\n",
    "                    self.rand_filter[\"low\"], self.rand_filter[\"high\"]\n",
    "                )\n",
    "                highcut = lowcut + self.rand_filter[\"band\"]\n",
    "                diff_feat = butter_bandpass_filter(\n",
    "                    diff_feat,\n",
    "                    lowcut,\n",
    "                    highcut,\n",
    "                    CFG.sampling_rate,\n",
    "                    order=self.rand_filter[\"order\"],\n",
    "                )\n",
    "\n",
    "            X[:, i] = diff_feat\n",
    "\n",
    "        n = CFG.n_map_features\n",
    "        if len(CFG.freq_channels) > 0:\n",
    "            for i in range(CFG.n_map_features):\n",
    "                diff_feat = X[:, i]\n",
    "                for j, (lowcut, highcut) in enumerate(CFG.freq_channels):\n",
    "                    band_feat = butter_bandpass_filter(\n",
    "                        diff_feat, lowcut, highcut, CFG.sampling_rate, order=CFG.filter_order,  # 6\n",
    "                    )\n",
    "                    X[:, n] = band_feat\n",
    "                    n += 1\n",
    "\n",
    "        for spml_feat in CFG.simple_features:\n",
    "            feat_val = data[:, CFG.feature_to_index[spml_feat]]\n",
    "            \n",
    "            if not self.bandpass_filter is None:\n",
    "                feat_val = butter_bandpass_filter(\n",
    "                    feat_val,\n",
    "                    self.bandpass_filter[\"low\"],\n",
    "                    self.bandpass_filter[\"high\"],\n",
    "                    CFG.sampling_rate,\n",
    "                    order=self.bandpass_filter[\"order\"],\n",
    "                )\n",
    "\n",
    "            if (\n",
    "                self.mode == \"train\"\n",
    "                and not self.rand_filter is None\n",
    "                and random.uniform(0.0, 1.0) <= self.rand_filter[\"probab\"]\n",
    "            ):\n",
    "                lowcut = random.randint(\n",
    "                    self.rand_filter[\"low\"], self.rand_filter[\"high\"]\n",
    "                )\n",
    "                highcut = lowcut + self.rand_filter[\"band\"]\n",
    "                feat_val = butter_bandpass_filter(\n",
    "                    feat_val,\n",
    "                    lowcut,\n",
    "                    highcut,\n",
    "                    CFG.sampling_rate,\n",
    "                    order=self.rand_filter[\"order\"],\n",
    "                )\n",
    "\n",
    "            X[:, n] = feat_val\n",
    "            n += 1\n",
    "            \n",
    "        # Обрезать края превышающие значения [-1024, 1024]\n",
    "        X = np.clip(X, -1024, 1024)\n",
    "\n",
    "        # Замените NaN нулем и разделить все на 32\n",
    "        X = np.nan_to_num(X, nan=0) / 32.0\n",
    "\n",
    "        # обрезать полосовым фильтром верхнюю границу в 20 Hz.\n",
    "        X = butter_lowpass_filter(X, order=CFG.filter_order)  # 4\n",
    "\n",
    "        y_prob = np.zeros(CFG.target_size, dtype=\"float32\")  # Size=(6,)\n",
    "        if self.mode != \"test\":\n",
    "            y_prob = row[CFG.target_cols].values.astype(np.float32)\n",
    "\n",
    "        return X, y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a104d32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:19:05.122548Z",
     "iopub.status.busy": "2024-03-15T23:19:05.122232Z",
     "iopub.status.idle": "2024-03-15T23:19:05.149462Z",
     "shell.execute_reply": "2024-03-15T23:19:05.148698Z"
    },
    "papermill": {
     "duration": 0.04878,
     "end_time": "2024-03-15T23:19:05.151416",
     "exception": false,
     "start_time": "2024-03-15T23:19:05.102636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResNet_1D_Block(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        padding,\n",
    "        downsampling,\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "        dropout=0.0,\n",
    "    ):\n",
    "        super(ResNet_1D_Block, self).__init__()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=in_channels)\n",
    "        # self.relu = nn.ReLU(inplace=False)\n",
    "        # self.relu_1 = nn.PReLU()\n",
    "        # self.relu_2 = nn.PReLU()\n",
    "        self.relu_1 = nn.Hardswish()\n",
    "        self.relu_2 = nn.Hardswish()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout, inplace=False)\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=out_channels)\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        self.maxpool = nn.MaxPool1d(\n",
    "            kernel_size=2,\n",
    "            stride=2,\n",
    "            padding=0,\n",
    "            dilation=dilation,\n",
    "        )\n",
    "        self.downsampling = downsampling\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu_1(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu_2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out = self.maxpool(out)\n",
    "        identity = self.downsampling(x)\n",
    "\n",
    "        out += identity\n",
    "        return out\n",
    "\n",
    "\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        kernels,\n",
    "        in_channels,\n",
    "        fixed_kernel_size,\n",
    "        num_classes,\n",
    "        linear_layer_features,\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "    ):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.kernels = kernels\n",
    "        self.planes = 24\n",
    "        self.parallel_conv = nn.ModuleList()\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        for i, kernel_size in enumerate(list(self.kernels)):\n",
    "            sep_conv = nn.Conv1d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=self.planes,\n",
    "                kernel_size=(kernel_size),\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                dilation=dilation,\n",
    "                groups=groups,\n",
    "                bias=False,\n",
    "            )\n",
    "            self.parallel_conv.append(sep_conv)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=self.planes)\n",
    "        # self.relu = nn.ReLU(inplace=False)\n",
    "        # self.relu_1 = nn.ReLU()\n",
    "        # self.relu_2 = nn.ReLU()\n",
    "        self.relu_1 = nn.SiLU()\n",
    "        self.relu_2 = nn.SiLU()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=self.planes,\n",
    "            out_channels=self.planes,\n",
    "            kernel_size=fixed_kernel_size,\n",
    "            stride=2,\n",
    "            padding=2,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        self.block = self._make_resnet_layer(\n",
    "            kernel_size=fixed_kernel_size,\n",
    "            stride=1,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            padding=fixed_kernel_size // 2,\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=self.planes)\n",
    "        self.avgpool = nn.AvgPool1d(kernel_size=6, stride=6, padding=2)\n",
    "\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=self.in_channels,\n",
    "            hidden_size=128,\n",
    "            num_layers=1,\n",
    "            bidirectional=True,\n",
    "            # dropout=0.2,\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(in_features=linear_layer_features, out_features=num_classes)\n",
    "\n",
    "    def _make_resnet_layer(\n",
    "        self,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "        blocks=9,\n",
    "        padding=0,\n",
    "        dropout=0.0,\n",
    "    ):\n",
    "        layers = []\n",
    "        downsample = None\n",
    "        base_width = self.planes\n",
    "\n",
    "        for i in range(blocks):\n",
    "            downsampling = nn.Sequential(\n",
    "                nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "            )\n",
    "            layers.append(\n",
    "                ResNet_1D_Block(\n",
    "                    in_channels=self.planes,\n",
    "                    out_channels=self.planes,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=stride,\n",
    "                    padding=padding,\n",
    "                    downsampling=downsampling,\n",
    "                    dilation=dilation,\n",
    "                    groups=groups,\n",
    "                    dropout=dropout,\n",
    "                )\n",
    "            )\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        out_sep = []\n",
    "\n",
    "        for i in range(len(self.kernels)):\n",
    "            sep = self.parallel_conv[i](x)\n",
    "            out_sep.append(sep)\n",
    "\n",
    "        out = torch.cat(out_sep, dim=2)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu_1(out)\n",
    "        out = self.conv1(out)\n",
    "\n",
    "        out = self.block(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu_2(out)\n",
    "        out = self.avgpool(out)\n",
    "\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        rnn_out, _ = self.rnn(x.permute(0, 2, 1))\n",
    "        new_rnn_h = rnn_out[:, -1, :]  # <~~\n",
    "\n",
    "        new_out = torch.cat([out, new_rnn_h], dim=1)\n",
    "        return new_out\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_out = self.extract_features(x)\n",
    "        result = self.fc(new_out)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4056570",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:19:05.189344Z",
     "iopub.status.busy": "2024-03-15T23:19:05.189095Z",
     "iopub.status.idle": "2024-03-15T23:19:05.195845Z",
     "shell.execute_reply": "2024-03-15T23:19:05.195012Z"
    },
    "papermill": {
     "duration": 0.02803,
     "end_time": "2024-03-15T23:19:05.197849",
     "exception": false,
     "start_time": "2024-03-15T23:19:05.169819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference_function(test_loader, model, device):\n",
    "    model.eval()  # set model in evaluation mode\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    prediction_dict = {}\n",
    "    preds = []\n",
    "    with tqdm(test_loader, unit=\"test_batch\", desc=\"Inference\") as tqdm_test_loader:\n",
    "        for step, batch in enumerate(tqdm_test_loader):\n",
    "            X = batch.pop(\"eeg\").to(device)  # send inputs to `device`\n",
    "            batch_size = X.size(0)\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(X)  # forward propagation pass\n",
    "            y_preds = softmax(y_preds)\n",
    "            preds.append(y_preds.to(\"cpu\").numpy())  # save predictions\n",
    "\n",
    "    prediction_dict[\"predictions\"] = np.concatenate(\n",
    "        preds\n",
    "    )  # np.array() of shape (fold_size, target_cols)\n",
    "    return prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4d2a641",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:19:05.235630Z",
     "iopub.status.busy": "2024-03-15T23:19:05.235338Z",
     "iopub.status.idle": "2024-03-15T23:19:05.248177Z",
     "shell.execute_reply": "2024-03-15T23:19:05.247337Z"
    },
    "papermill": {
     "duration": 0.034171,
     "end_time": "2024-03-15T23:19:05.250055",
     "exception": false,
     "start_time": "2024-03-15T23:19:05.215884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataframe shape is: (1, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>853520</td>\n",
       "      <td>3911565283</td>\n",
       "      <td>6885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spectrogram_id      eeg_id  patient_id\n",
       "0          853520  3911565283        6885"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(CFG.test_csv)\n",
    "print(f\"Test dataframe shape is: {test_df.shape}\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5fde04fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:19:05.287392Z",
     "iopub.status.busy": "2024-03-15T23:19:05.287128Z",
     "iopub.status.idle": "2024-03-15T23:19:05.857831Z",
     "shell.execute_reply": "2024-03-15T23:19:05.856571Z"
    },
    "papermill": {
     "duration": 0.592215,
     "end_time": "2024-03-15T23:19:05.860407",
     "exception": false,
     "start_time": "2024-03-15T23:19:05.268192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 20 raw eeg features\n",
      "['Fp1', 'F3', 'C3', 'P3', 'F7', 'T3', 'T5', 'O1', 'Fz', 'Cz', 'Pz', 'Fp2', 'F4', 'C4', 'P4', 'F8', 'T4', 'T6', 'O2', 'EKG']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f82e1a07ade4b478675f772e14a96e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_eeg_parquet_paths = glob(CFG.test_eeg + \"*.parquet\")\n",
    "test_eeg_df = pd.read_parquet(test_eeg_parquet_paths[0])\n",
    "test_eeg_features = test_eeg_df.columns\n",
    "print(f\"There are {len(test_eeg_features)} raw eeg features\")\n",
    "print(list(test_eeg_features))\n",
    "del test_eeg_df\n",
    "_ = gc.collect()\n",
    "\n",
    "# %%time\n",
    "all_eegs = {}\n",
    "eeg_ids = test_df.eeg_id.unique()\n",
    "for i, eeg_id in tqdm(enumerate(eeg_ids)):\n",
    "    # Save EEG to Python dictionary of numpy arrays\n",
    "    eeg_path = CFG.test_eeg + str(eeg_id) + \".parquet\"\n",
    "    data = eeg_from_parquet(eeg_path)\n",
    "    all_eegs[eeg_id] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8de49585",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:19:05.915497Z",
     "iopub.status.busy": "2024-03-15T23:19:05.915088Z",
     "iopub.status.idle": "2024-03-15T23:19:08.884146Z",
     "shell.execute_reply": "2024-03-15T23:19:08.883018Z"
    },
    "papermill": {
     "duration": 2.998879,
     "end_time": "2024-03-15T23:19:08.886183",
     "exception": false,
     "start_time": "2024-03-15T23:19:05.887304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([2000, 8])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b53f3ba74054492a9c998ef6221b33e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?test_batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d98043872a448c8f6bccb14ff3070f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?test_batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36121c53547542fc9498742349a3ac26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?test_batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df013ac9b5f4f5e80a0780045846bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?test_batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b956e98277403082de0220333e0359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?test_batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "koef_sum = 0\n",
    "koef_count = 0\n",
    "predictions = []\n",
    "files = []\n",
    "    \n",
    "for model_block in model_weights:\n",
    "    test_dataset = EEGDataset(\n",
    "        df=test_df,\n",
    "        batch_size=CFG.batch_size,\n",
    "        mode=\"test\",\n",
    "        eegs=all_eegs,\n",
    "        bandpass_filter=model_block['bandpass_filter']\n",
    "    )\n",
    "\n",
    "    if len(predictions) == 0:\n",
    "        output = test_dataset[0]\n",
    "        X = output[\"eeg\"]\n",
    "        print(f\"X shape: {X.shape}\")\n",
    "                \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    model = EEGNet(\n",
    "        kernels=CFG.kernels,\n",
    "        in_channels=CFG.in_channels,\n",
    "        fixed_kernel_size=CFG.fixed_kernel_size,\n",
    "        num_classes=CFG.target_size,\n",
    "        linear_layer_features=CFG.linear_layer_features,\n",
    "    )\n",
    "\n",
    "    for file_line in model_block['file_data']:\n",
    "        koef = file_line['koef']\n",
    "        for weight_model_file in glob(file_line['file_mask']):\n",
    "            files.append(weight_model_file)\n",
    "            checkpoint = torch.load(weight_model_file, map_location=device)\n",
    "            model.load_state_dict(checkpoint[\"model\"])\n",
    "            model.to(device)\n",
    "            prediction_dict = inference_function(test_loader, model, device)\n",
    "            predict = prediction_dict[\"predictions\"]\n",
    "            predict *= koef\n",
    "            koef_sum += koef\n",
    "            koef_count += 1\n",
    "            predictions.append(predict)\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "koef_sum /= koef_count\n",
    "predictions /= koef_sum\n",
    "predictions = np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2ac1620",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:19:08.929480Z",
     "iopub.status.busy": "2024-03-15T23:19:08.929155Z",
     "iopub.status.idle": "2024-03-15T23:19:08.935752Z",
     "shell.execute_reply": "2024-03-15T23:19:08.934875Z"
    },
    "papermill": {
     "duration": 0.030095,
     "end_time": "2024-03-15T23:19:08.937712",
     "exception": false,
     "start_time": "2024-03-15T23:19:08.907617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/kaggle/input/hms-resnet1d-gru-weights-v98/pop_2_weight_oof/resnet1d_gru_ver-64_stage-2_fold-1_full.pth',\n",
       " '/kaggle/input/hms-resnet1d-gru-weights-v98/pop_2_weight_oof/resnet1d_gru_ver-64_stage-2_fold-4_full.pth',\n",
       " '/kaggle/input/hms-resnet1d-gru-weights-v98/pop_2_weight_oof/resnet1d_gru_ver-64_stage-2_fold-2_full.pth',\n",
       " '/kaggle/input/hms-resnet1d-gru-weights-v98/pop_2_weight_oof/resnet1d_gru_ver-64_stage-2_fold-0_full.pth',\n",
       " '/kaggle/input/hms-resnet1d-gru-weights-v98/pop_2_weight_oof/resnet1d_gru_ver-64_stage-2_fold-3_full.pth']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(koef_count, koef_sum)\n",
    "display(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c4dd1bba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:19:08.977832Z",
     "iopub.status.busy": "2024-03-15T23:19:08.977581Z",
     "iopub.status.idle": "2024-03-15T23:19:08.995515Z",
     "shell.execute_reply": "2024-03-15T23:19:08.994546Z"
    },
    "papermill": {
     "duration": 0.039796,
     "end_time": "2024-03-15T23:19:08.997422",
     "exception": false,
     "start_time": "2024-03-15T23:19:08.957626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission shape: (1, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3911565283</td>\n",
       "      <td>0.016862</td>\n",
       "      <td>0.026578</td>\n",
       "      <td>0.009426</td>\n",
       "      <td>0.093476</td>\n",
       "      <td>0.089352</td>\n",
       "      <td>0.764305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
       "0  3911565283      0.016862  0.026578  0.009426   0.093476   0.089352   \n",
       "\n",
       "   other_vote  \n",
       "0    0.764305  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub3 = pd.DataFrame({\"eeg_id\": test_df.eeg_id.values})\n",
    "sub3[CFG.target_cols] = predictions\n",
    "\n",
    "sub3.to_csv(f\"submission.csv\", index=False)\n",
    "print(f\"Submission shape: {sub3.shape}\")\n",
    "display(sub3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "87e57253",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:19:09.038184Z",
     "iopub.status.busy": "2024-03-15T23:19:09.037911Z",
     "iopub.status.idle": "2024-03-15T23:19:09.043994Z",
     "shell.execute_reply": "2024-03-15T23:19:09.043116Z"
    },
    "papermill": {
     "duration": 0.028674,
     "end_time": "2024-03-15T23:19:09.046281",
     "exception": false,
     "start_time": "2024-03-15T23:19:09.017607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n"
     ]
    }
   ],
   "source": [
    "print(sub3.iloc[:,-6:].sum(axis=1).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d31a012",
   "metadata": {
    "papermill": {
     "duration": 0.022083,
     "end_time": "2024-03-15T23:19:09.090375",
     "exception": false,
     "start_time": "2024-03-15T23:19:09.068292",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "24f15f89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:19:09.133564Z",
     "iopub.status.busy": "2024-03-15T23:19:09.133191Z",
     "iopub.status.idle": "2024-03-15T23:19:09.159630Z",
     "shell.execute_reply": "2024-03-15T23:19:09.158560Z"
    },
    "papermill": {
     "duration": 0.050649,
     "end_time": "2024-03-15T23:19:09.161937",
     "exception": false,
     "start_time": "2024-03-15T23:19:09.111288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission shape: (1, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3911565283</td>\n",
       "      <td>0.046655</td>\n",
       "      <td>0.067978</td>\n",
       "      <td>0.00353</td>\n",
       "      <td>0.330814</td>\n",
       "      <td>0.037198</td>\n",
       "      <td>0.513825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
       "0  3911565283      0.046655  0.067978   0.00353   0.330814   0.037198   \n",
       "\n",
       "   other_vote  \n",
       "0    0.513825  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_final = pd.DataFrame({\"eeg_id\": test_df.eeg_id.values})\n",
    "labels = ['seizure', 'lpd', 'gpd', 'lrda', 'grda', 'other']\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    sub1[f'{labels[i]}_vote'] = test_preds[:, i]\n",
    "sub2[TARGETS] = pred_final\n",
    "sub3[CFG.target_cols] = predictions\n",
    "    \n",
    "for label in labels:\n",
    "    sub_final[f'{label}_vote'] = (sub1[f'{label}_vote'] + sub2[f'{label}_vote'] + sub3[f'{label}_vote']) / 3.0 \n",
    "\n",
    "sub_final.to_csv(f\"submission.csv\", index=False)\n",
    "print(f\"Submission shape: {sub_final.shape}\")\n",
    "display(sub_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "827e711a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T23:19:09.208778Z",
     "iopub.status.busy": "2024-03-15T23:19:09.208442Z",
     "iopub.status.idle": "2024-03-15T23:19:09.215483Z",
     "shell.execute_reply": "2024-03-15T23:19:09.214374Z"
    },
    "papermill": {
     "duration": 0.032612,
     "end_time": "2024-03-15T23:19:09.217493",
     "exception": false,
     "start_time": "2024-03-15T23:19:09.184881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n"
     ]
    }
   ],
   "source": [
    "print(sub_final.iloc[:,-6:].sum(axis=1).to_string())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7469972,
     "sourceId": 59093,
     "sourceType": "competition"
    },
    {
     "datasetId": 4297749,
     "sourceId": 7392733,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4297782,
     "sourceId": 7392775,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4317718,
     "sourceId": 7465251,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4378712,
     "sourceId": 7517324,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4407194,
     "sourceId": 7570342,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4382744,
     "sourceId": 7752462,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4550181,
     "sourceId": 7776446,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4417235,
     "sourceId": 7818976,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4581021,
     "sourceId": 7819029,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 160674831,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 160700706,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 161586765,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 103.604986,
   "end_time": "2024-03-15T23:19:12.241417",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-15T23:17:28.636431",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0194fd4e4ac844839f63ca908f56fe95": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "026f68631b464733adfd2ef5b6766443": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4c3f4bfba9e347998bc4c191e10a1c59",
       "placeholder": "​",
       "style": "IPY_MODEL_f030fb0494374330986b4576c77690df",
       "value": "Inference: 100%"
      }
     },
     "0ddbf22311104d5ebe0a493ea9a73296": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0f2f3b0706df48c8b02850d40e56d538": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0fb045dde6ed49abad48feb5f786f61b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2d4988d400014691b87e176d241fd1ff",
       "placeholder": "​",
       "style": "IPY_MODEL_f0a0803cf7d34d619881fa1b2ee2af9a",
       "value": " 1/1 [00:00&lt;00:00,  3.10test_batch/s]"
      }
     },
     "1223330796654c109e276fdb2f0fa6be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3875e16aeae9411583e48dfa59660489",
       "placeholder": "​",
       "style": "IPY_MODEL_c090679a2c454121aaac98a3a14ef092",
       "value": "Inference: 100%"
      }
     },
     "12e58c056fde4dcfac377bb742c36d62": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1c2d216ac0bc476898f72bce1741e981": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2d9d185cb0ae485f878c53aca3b9bb69",
       "placeholder": "​",
       "style": "IPY_MODEL_c09a66899c454c58907d00975da90b16",
       "value": " 1/1 [00:00&lt;00:00, 24.57test_batch/s]"
      }
     },
     "1d22cc80f4354d15bfeab21a52c3feb2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1e071bbcc35f4009bf0a86e01a110474": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "21153e563fd84dacaed5cf0354029350": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "274702afe6734c6b983952804d1c4780": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2a591b77175f46d6bd44c79d1063ba18": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2b53f3ba74054492a9c998ef6221b33e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e949a20f0ef047aaa719df7787d7ab7e",
        "IPY_MODEL_d30e36e7cfc541c4a9d44439545fce11",
        "IPY_MODEL_0fb045dde6ed49abad48feb5f786f61b"
       ],
       "layout": "IPY_MODEL_f8d29e708c1d4ee290ba0782bd7ef021"
      }
     },
     "2d4988d400014691b87e176d241fd1ff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2d9d185cb0ae485f878c53aca3b9bb69": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2fcec690aead4bcabf4ca0256aeb4b81": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "33b956e98277403082de0220333e0359": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1223330796654c109e276fdb2f0fa6be",
        "IPY_MODEL_8fa871da91f7470b92076cfa55273679",
        "IPY_MODEL_53700e3916e14349a94706703005a994"
       ],
       "layout": "IPY_MODEL_12e58c056fde4dcfac377bb742c36d62"
      }
     },
     "36121c53547542fc9498742349a3ac26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_026f68631b464733adfd2ef5b6766443",
        "IPY_MODEL_c526fc07805d4362a6e93aab51b18b33",
        "IPY_MODEL_d77f5f7907f94a7ea9e3273283f4137f"
       ],
       "layout": "IPY_MODEL_2fcec690aead4bcabf4ca0256aeb4b81"
      }
     },
     "3875e16aeae9411583e48dfa59660489": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "39ca9ed502c64b32a20ad54767fecd8f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4c3f4bfba9e347998bc4c191e10a1c59": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4ec91c36754248498609fa952f653cf3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5199b7f8e28b43cc86c632f7e1618c41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "53700e3916e14349a94706703005a994": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_965a2a42dfd74ee9ae70a45349b32819",
       "placeholder": "​",
       "style": "IPY_MODEL_1e071bbcc35f4009bf0a86e01a110474",
       "value": " 1/1 [00:00&lt;00:00, 24.96test_batch/s]"
      }
     },
     "54d98043872a448c8f6bccb14ff3070f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_97ec6842c6c8416c9ae79365b68f2944",
        "IPY_MODEL_9dfa3538ecc6484daf98ec51e8a2289d",
        "IPY_MODEL_1c2d216ac0bc476898f72bce1741e981"
       ],
       "layout": "IPY_MODEL_b54fb8ff24c342db9d50aae739d27f1f"
      }
     },
     "5d3d298d46ec44629804087c5a798b03": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5df013ac9b5f4f5e80a0780045846bb6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5e07fb357da94c7eb07b5c006bdb2957",
        "IPY_MODEL_82a1cb238b9f4484922bd62af61f6c26",
        "IPY_MODEL_cfeb35df0414411fad5448347d09f618"
       ],
       "layout": "IPY_MODEL_f68b98c9e6d541fe8a29686a5d3f9929"
      }
     },
     "5e07fb357da94c7eb07b5c006bdb2957": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_39ca9ed502c64b32a20ad54767fecd8f",
       "placeholder": "​",
       "style": "IPY_MODEL_91c316a3f31942d4b774d226589381da",
       "value": "Inference: 100%"
      }
     },
     "5e7791069a1f4c20b8981d337bb79fab": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5f82e1a07ade4b478675f772e14a96e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b26c1ce59c45432c8f61ef1fe91a0564",
        "IPY_MODEL_f99641435ba844fc8909371f0d7b564a",
        "IPY_MODEL_ef6559f5fa384bcb808a9c630422d2e9"
       ],
       "layout": "IPY_MODEL_274702afe6734c6b983952804d1c4780"
      }
     },
     "61af74382b6c46ae8cca92850be87419": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6bede690e4b5465c904b1a3aa24fff08": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "713a148e35d9489f9134b0b9512fa62e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "73c90f0c62164dcb9e820c581eb8e469": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "762a0f7adafd47b980353ba62531f6d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "82a1cb238b9f4484922bd62af61f6c26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0ddbf22311104d5ebe0a493ea9a73296",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0f2f3b0706df48c8b02850d40e56d538",
       "value": 1
      }
     },
     "8a38badb493344ccba26fedb4e3e6c33": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8dd1d39e68b2438da230b7f6666d22d5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8e8294ad7fac40d58b76f559e2f32dfa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8fa871da91f7470b92076cfa55273679": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_61af74382b6c46ae8cca92850be87419",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8a38badb493344ccba26fedb4e3e6c33",
       "value": 1
      }
     },
     "91c316a3f31942d4b774d226589381da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "965a2a42dfd74ee9ae70a45349b32819": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "97ec6842c6c8416c9ae79365b68f2944": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5d3d298d46ec44629804087c5a798b03",
       "placeholder": "​",
       "style": "IPY_MODEL_6bede690e4b5465c904b1a3aa24fff08",
       "value": "Inference: 100%"
      }
     },
     "98a13942876c4795982ef8c0365f937c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9dfa3538ecc6484daf98ec51e8a2289d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_21153e563fd84dacaed5cf0354029350",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_762a0f7adafd47b980353ba62531f6d9",
       "value": 1
      }
     },
     "a6bbee87df3c462fbb97ce747e8fcb5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b26c1ce59c45432c8f61ef1fe91a0564": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4ec91c36754248498609fa952f653cf3",
       "placeholder": "​",
       "style": "IPY_MODEL_d66bd48595514d1bab4231785bbe3157",
       "value": ""
      }
     },
     "b54fb8ff24c342db9d50aae739d27f1f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c090679a2c454121aaac98a3a14ef092": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c09a66899c454c58907d00975da90b16": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c526fc07805d4362a6e93aab51b18b33": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5199b7f8e28b43cc86c632f7e1618c41",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_73c90f0c62164dcb9e820c581eb8e469",
       "value": 1
      }
     },
     "cfeb35df0414411fad5448347d09f618": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0194fd4e4ac844839f63ca908f56fe95",
       "placeholder": "​",
       "style": "IPY_MODEL_8e8294ad7fac40d58b76f559e2f32dfa",
       "value": " 1/1 [00:00&lt;00:00, 22.69test_batch/s]"
      }
     },
     "d30e36e7cfc541c4a9d44439545fce11": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2a591b77175f46d6bd44c79d1063ba18",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a6bbee87df3c462fbb97ce747e8fcb5b",
       "value": 1
      }
     },
     "d429edc21daf4454872e42743e02d1db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "d66bd48595514d1bab4231785bbe3157": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d77f5f7907f94a7ea9e3273283f4137f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1d22cc80f4354d15bfeab21a52c3feb2",
       "placeholder": "​",
       "style": "IPY_MODEL_de35c937a4184557af45a07d0fc24ddd",
       "value": " 1/1 [00:00&lt;00:00, 25.48test_batch/s]"
      }
     },
     "de35c937a4184557af45a07d0fc24ddd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e8e428d9937648349af8421e6d226c2f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e949a20f0ef047aaa719df7787d7ab7e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_713a148e35d9489f9134b0b9512fa62e",
       "placeholder": "​",
       "style": "IPY_MODEL_8dd1d39e68b2438da230b7f6666d22d5",
       "value": "Inference: 100%"
      }
     },
     "ef6559f5fa384bcb808a9c630422d2e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5e7791069a1f4c20b8981d337bb79fab",
       "placeholder": "​",
       "style": "IPY_MODEL_98a13942876c4795982ef8c0365f937c",
       "value": " 1/? [00:00&lt;00:00, 33.53it/s]"
      }
     },
     "f030fb0494374330986b4576c77690df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f0a0803cf7d34d619881fa1b2ee2af9a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f68b98c9e6d541fe8a29686a5d3f9929": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f8d29e708c1d4ee290ba0782bd7ef021": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f99641435ba844fc8909371f0d7b564a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d429edc21daf4454872e42743e02d1db",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e8e428d9937648349af8421e6d226c2f",
       "value": 1
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
