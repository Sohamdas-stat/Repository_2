{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf30469f",
   "metadata": {},
   "source": [
    "# HMS-PySpark-exercise\n",
    "### by Iulian Cozma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012a57f5",
   "metadata": {},
   "source": [
    "## Toools and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b8a24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with experiment params: {'sample_frac': 0.1, 'seed': 42, 'flags': {'eval', 'kaggle'}, 'spectogram_freq_sparse_N': 10, 'eeg_freq_sparse_N': 20}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "root = \"/scratch/eecs545w24_class_root/eecs545w24_class/shared_data/hms_data/raw_data/\" \n",
    "#root = \"/kaggle/input/hms-harmful-brain-activity-classification\" \n",
    "ENVIRONMENT = 'kaggle'\n",
    "\n",
    "experiment_params = {\n",
    "    # \"N\": 1_000,\n",
    "    \"sample_frac\": .10,     # fraction of the dataset to be used, -1 to use 'all' data\n",
    "    \"seed\": 42,\n",
    "    \"flags\": { \"eval\", ENVIRONMENT},\n",
    "    \"spectogram_freq_sparse_N\": 10,\n",
    "    \"eeg_freq_sparse_N\": 20\n",
    "}\n",
    "FLAGS = experiment_params[\"flags\"] \n",
    "\n",
    "print(f\"Running with experiment params: {experiment_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2e0841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eafa59",
   "metadata": {},
   "source": [
    "### Install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b56226dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "#src_path = r\"/kaggle/input/pyspark-package/pyspark-3.5.0.tar.gz.mp4\"\n",
    "#dst_path = r\"/kaggle/working/pyspark-3.5.0.tar.gz\"\n",
    "#src_path = r\"/Users/sohamdas/Desktop/EECS 545/Project\"\n",
    "#dst_path = r\"/Users/sohamdas/Desktop/EECS 545/Project\"\n",
    "#shutil.copy(src_path, dst_path)\n",
    "#!pip install pyspark\n",
    "#!pip install /kaggle/working/pyspark-3.5.0.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f289738",
   "metadata": {},
   "source": [
    "### ML Flow - setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22645ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if \"eval\" in FLAGS:\n",
    "#    import os\n",
    "#    # Set the environment variable\n",
    "#    os.environ[\"PYSPARK_PIN_THREAD\"] = \"False\"\n",
    "#    spark.builder.config(\"spark.jars.packages\", \"org.mlflow.mlflow-spark\")\n",
    "#    import mlflow\n",
    "#\n",
    "#     # mlflow.set_tracking_uri(\"http://127.0.0.0:5000\")\n",
    "#    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "#    mlflow.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5ff2a3",
   "metadata": {},
   "source": [
    "### PySpark app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ee70695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark as ps\n",
    "from pyspark.sql import SparkSession\n",
    "import faulthandler\n",
    "\n",
    "faulthandler.enable()\n",
    "ps.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c936fb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/28 09:37:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark UI:  http://gl3205.arc-ts.umich.edu:4040\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.master(\"local[*]\")\n",
    "    # .config(\"spark.jars.packages\", \"org.mlflow.mlflow-spark\")\n",
    "    .config(\"spark.driver.memory\", \"15g\")\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\")  # Enable adaptive query execution\n",
    "    .config(\n",
    "        \"spark.debug.maxToStringFields\", 20_000\n",
    "    )  # For msg: truncated the string representation of a plan since it was too large.\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", -1)\n",
    "    .appName(\"brain-spark-1\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "# Access the Spark UI URL\n",
    "print(\"Spark UI: \", spark.sparkContext.uiWebUrl)\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    IntegerType,\n",
    "    FloatType,\n",
    "    LongType,\n",
    "    DoubleType,\n",
    "    ArrayType,\n",
    ")\n",
    "\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "\n",
    "from pyspark.sql.functions import (\n",
    "    input_file_name as input_file_name,\n",
    "    regexp_extract as regexp_extract,\n",
    "    collect_list as collect_list,\n",
    "    col,\n",
    "    lit,\n",
    "    expr,\n",
    "    slice,\n",
    "    udf,\n",
    ")\n",
    "from pyspark.sql.functions import array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1131789",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8526c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7cc7d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train & Test columns and schema\n",
    "train_columns = eval(\n",
    "    \"\"\"['eeg_id', 'eeg_sub_id', 'eeg_label_offset_seconds', 'spectrogram_id', 'spectrogram_sub_id', 'spectrogram_label_offset_seconds', 'label_id', 'patient_id', 'expert_consensus', 'seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\"\"\"\n",
    ")\n",
    "train_schema = StructType(\n",
    "    [\n",
    "        StructField(\"eeg_id\", LongType(), True),\n",
    "        StructField(\"eeg_sub_id\", IntegerType(), True),\n",
    "        StructField(\"eeg_label_offset_seconds\", DoubleType(), True),\n",
    "        StructField(\"spectrogram_id\", IntegerType(), True),\n",
    "        StructField(\"spectrogram_sub_id\", IntegerType(), True),\n",
    "        StructField(\"spectrogram_label_offset_seconds\", DoubleType(), True),\n",
    "        StructField(\"label_id\", LongType(), True),\n",
    "        StructField(\"patient_id\", IntegerType(), True),\n",
    "        StructField(\"expert_consensus\", StringType(), True),\n",
    "        StructField(\"seizure_vote\", IntegerType(), True),\n",
    "        StructField(\"lpd_vote\", IntegerType(), True),\n",
    "        StructField(\"gpd_vote\", IntegerType(), True),\n",
    "        StructField(\"lrda_vote\", IntegerType(), True),\n",
    "        StructField(\"grda_vote\", IntegerType(), True),\n",
    "        StructField(\"other_vote\", IntegerType(), True),\n",
    "    ]\n",
    ")\n",
    "test_schema = StructType(\n",
    "    [\n",
    "        StructField(\"spectrogram_id\", IntegerType(), True),\n",
    "        StructField(\"eeg_id\", LongType(), True),\n",
    "        StructField(\"patient_id\", IntegerType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# EEG columns and schema\n",
    "eeg_columns = eval(\n",
    "    \"\"\"[\n",
    "        'Fp1', 'F3', 'C3', 'P3', 'F7', 'T3', 'T5', 'O1', 'Fz', 'Cz', 'Pz', 'Fp2', 'F4', 'C4', 'P4', 'F8', 'T4', 'T6', 'O2', 'EKG', 'eeg_id']\"\"\"\n",
    ")\n",
    "eeg_columns_data = eeg_columns[:-1]  # eeg columns containing data only (no eeg_id)\n",
    "eeg_schema = StructType(\n",
    "    [\n",
    "        StructField(\"Fp1\", FloatType(), True),\n",
    "        StructField(\"F3\", FloatType(), True),\n",
    "        StructField(\"C3\", FloatType(), True),\n",
    "        StructField(\"P3\", FloatType(), True),\n",
    "        StructField(\"F7\", FloatType(), True),\n",
    "        StructField(\"T3\", FloatType(), True),\n",
    "        StructField(\"T5\", FloatType(), True),\n",
    "        StructField(\"O1\", FloatType(), True),\n",
    "        StructField(\"Fz\", FloatType(), True),\n",
    "        StructField(\"Cz\", FloatType(), True),\n",
    "        StructField(\"Pz\", FloatType(), True),\n",
    "        StructField(\"Fp2\", FloatType(), True),\n",
    "        StructField(\"F4\", FloatType(), True),\n",
    "        StructField(\"C4\", FloatType(), True),\n",
    "        StructField(\"P4\", FloatType(), True),\n",
    "        StructField(\"F8\", FloatType(), True),\n",
    "        StructField(\"T4\", FloatType(), True),\n",
    "        StructField(\"T6\", FloatType(), True),\n",
    "        StructField(\"O2\", FloatType(), True),\n",
    "        StructField(\"EKG\", FloatType(), True),\n",
    "        StructField(\"eeg_id\", IntegerType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Spectrogram columns and schema\n",
    "spectrogram_columns_prefix = eval(\"\"\"['LL', 'RL', 'RP', 'LP']\"\"\")\n",
    "spectrogram_columns_sufix = eval(\n",
    "    \"\"\"['0.59', '0.78', '0.98', '1.17', '1.37', '1.56', '1.76', '1.95', '2.15', '2.34', '2.54', '2.73', '2.93', '3.13', '3.32', '3.52', '3.71', '3.91', '4.1', '4.3', '4.49', '4.69', '4.88', '5.08', '5.27', '5.47', '5.66', '5.86', '6.05', '6.25', '6.45', '6.64', '6.84', '7.03', '7.23', '7.42', '7.62', '7.81', '8.01', '8.2', '8.4', '8.59', '8.79', '8.98', '9.18', '9.38', '9.57', '9.77', '9.96', '10.16', '10.35', '10.55', '10.74', '10.94', '11.13', '11.33', '11.52', '11.72', '11.91', '12.11', '12.3', '12.5', '12.7', '12.89', '13.09', '13.28', '13.48', '13.67', '13.87', '14.06', '14.26', '14.45', '14.65', '14.84', '15.04', '15.23', '15.43', '15.63', '15.82', '16.02', '16.21', '16.41', '16.6', '16.8', '16.99', '17.19', '17.38', '17.58', '17.77', '17.97', '18.16', '18.36', '18.55', '18.75', '18.95', '19.14', '19.34', '19.53', '19.73', '19.92']\"\"\"\n",
    ")\n",
    "spectrogram_columns_data = [\n",
    "    f\"{prefix}_{suffix}\"\n",
    "    for prefix in spectrogram_columns_prefix\n",
    "    for suffix in spectrogram_columns_sufix\n",
    "]\n",
    "\n",
    "\n",
    "# Create a StructType for the schema from a list of StructFields\n",
    "spectrogram_schema = StructType(\n",
    "    [StructField(\"time\", IntegerType())]\n",
    "    + [\n",
    "        StructField(prefix + \"_\" + suffix, FloatType(), True)\n",
    "        for prefix in spectrogram_columns_prefix\n",
    "        for suffix in spectrogram_columns_sufix\n",
    "    ]\n",
    ")\n",
    "\n",
    "NFreq = experiment_params.get(\"spectogram_freq_sparse_N\", 10)\n",
    "spectrogram_columns_data = (\n",
    "    [x for x in spectrogram_columns_data if x.startswith(\"LL\")][::NFreq]\n",
    "    + [x for x in spectrogram_columns_data if x.startswith(\"RL\")][::NFreq]\n",
    "    + [x for x in spectrogram_columns_data if x.startswith(\"RP\")][::NFreq]\n",
    "    + [x for x in spectrogram_columns_data if x.startswith(\"LP\")][::NFreq]\n",
    ")\n",
    "\n",
    "spectrogram_columns_data_dot = [\n",
    "    col.replace(\".\", \"__\") for col in spectrogram_columns_data\n",
    "]\n",
    "\n",
    "\n",
    "votes_columns = eval(\n",
    "    \"\"\"[  'seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa8da371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 40, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eeg_columns_data), len(spectrogram_columns_data), len(votes_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13b8be1",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "817749ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = experiment_params.get(\"N\", -1)\n",
    "sample_frac = experiment_params.get(\"sample_frac\", -1)\n",
    "seed = experiment_params.get(\"seed\", 42)\n",
    "\n",
    "sum_of_votes_expr = \"(\" + \"+\".join(votes_columns) + \")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01899c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = (\n",
    "    spark.read.csv(root + \"train.csv\", header=True, schema=train_schema)\n",
    "    # .alias(\"train\")\n",
    "    # .groupBy(\"train.eeg_id\")\n",
    "    # .agg(*[first(col(column)).alias(column) for column in train_columns])\n",
    "    .filter(\"eeg_sub_id=0\")\n",
    "    # cast offest to integer\n",
    "    .withColumn(\n",
    "        \"eeg_label_offset_seconds\",\n",
    "        col(\"eeg_label_offset_seconds\").cast(\"integer\"),\n",
    "    ).withColumn(\n",
    "        \"spectrogram_label_offset_seconds\",\n",
    "        col(\"spectrogram_label_offset_seconds\").cast(\"integer\"),\n",
    "    )\n",
    "    # label\n",
    "    .withColumn(\"label\", col(\"expert_consensus\"))\n",
    "    # percent of votes for each label for model evaluation,necesary on 'eval' flag\n",
    "    .withColumns(\n",
    "        {\n",
    "            f\"{column}_actual\": expr(f\"{column} / {sum_of_votes_expr}\")\n",
    "            for column in votes_columns\n",
    "        },\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67f194cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting a fraction of the data: 0.1\n"
     ]
    }
   ],
   "source": [
    "if N > 0:\n",
    "    df_train = df_train.limit(N)\n",
    "if sample_frac > 0:\n",
    "    df_train = df_train.sample(\n",
    "        fraction=sample_frac,\n",
    "        withReplacement=False,\n",
    "        seed=experiment_params.get(\"seed\", 42),\n",
    "    )\n",
    "    print(f\"getting a fraction of the data: {sample_frac}\")\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "train_df, eval_df = df_train.randomSplit([0.7, 0.3], seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdddf4a1",
   "metadata": {},
   "source": [
    "### EEGs and Spectrograms parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5f8c87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parquet_files(df, folder, root=root):\n",
    "    \"\"\"\n",
    "    Returns a list of file paths for EEG and Spectrograns, based on the given ids.\n",
    "    Function is needed because multiple EEGs & Spectrogram are stored into single parquet file.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The DataFrame containing the EEG/Spectrogram id as a column named 'id'.\n",
    "        folder (str): The folder where the EEG/Spectrogram files are stored. Defaults to \"train_eegs\".\n",
    "        root (str, optional): The root directory where the folder is located. Defaults to root.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of parquet file paths\n",
    "    \"\"\"\n",
    "\n",
    "    paths = [\n",
    "        os.path.join(root, folder, f\"{x.id}.parquet\")\n",
    "        for x in df.select(\"id\").distinct().collect()\n",
    "    ]\n",
    "    print(f\"Found {len(paths)} files\")\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17a93401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1277 files\n",
      "Found 1157 files\n",
      "Found 500 files\n",
      "Found 474 files\n"
     ]
    }
   ],
   "source": [
    "train_eeg_files_paths = get_parquet_files(\n",
    "    train_df.select(col(\"eeg_id\").alias(\"id\")), folder=\"train_eegs\", root=root\n",
    ")\n",
    "train_spectro_files_paths = get_parquet_files(\n",
    "    train_df.select(col(\"spectrogram_id\").alias(\"id\")),\n",
    "    folder=\"train_spectrograms\",\n",
    "    root=root,\n",
    ")\n",
    "\n",
    "\n",
    "if \"eval\" in FLAGS:\n",
    "    eval_eeg_files_paths = get_parquet_files(\n",
    "        eval_df.select(col(\"eeg_id\").alias(\"id\")), folder=\"train_eegs\", root=root\n",
    "    )\n",
    "\n",
    "    eval_spectro_files_paths = get_parquet_files(\n",
    "        eval_df.select(col(\"spectrogram_id\").alias(\"id\")),\n",
    "        folder=\"train_spectrograms\",\n",
    "        root=root,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de493cc",
   "metadata": {},
   "source": [
    "### UDF for Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e538cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "\n",
    "# Convert array columns to vectors\n",
    "to_vector_udf = udf(lambda arr: Vectors.dense(arr), VectorUDT())\n",
    "\n",
    "from scipy.stats import skew, kurtosis\n",
    "from pyspark.sql.functions import udf\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the UDF for stats summary\n",
    "@udf(ArrayType(DoubleType()))\n",
    "def stats_summary_udf(arr):\n",
    "    \"\"\"\n",
    "    It splits the array in 3 parts and calculate some stats for each segment:\n",
    "    - mean\n",
    "    - std\n",
    "    - variance ...\n",
    "    \"\"\"\n",
    "\n",
    "    def stats_sub_array(x):\n",
    "        if len(x) == 0:\n",
    "            return [0] * 7\n",
    "\n",
    "        return [\n",
    "            float(np.mean(x)),\n",
    "            float(np.std(x)),\n",
    "            float(np.var(x)),\n",
    "            float(np.median(x)),\n",
    "            float(np.max(x)),\n",
    "            float(np.min(x)),\n",
    "            float(np.max(x) - np.min(x)),\n",
    "        ]\n",
    "\n",
    "    if not arr or len(arr) == 0:\n",
    "        return [0] * 7 * 3\n",
    "    else:\n",
    "        arr = np.array(arr)\n",
    "        split_point1 = len(arr) // 3\n",
    "        split_point2 = 2 * (len(arr) // 3)\n",
    "        ret = (\n",
    "            stats_sub_array(arr[:split_point1])\n",
    "            + stats_sub_array(arr[split_point1:split_point2])\n",
    "            + stats_sub_array(arr[split_point2:])\n",
    "        )\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3f4ae0",
   "metadata": {},
   "source": [
    "### EEGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdd35986",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_freq_sparse_N = experiment_params.get(\"eeg_freq_sparse_N\", 20)\n",
    "\n",
    "\n",
    "def load_eegs(df, eeg_files_paths, eeg_schema, cols_to_array):\n",
    "    \"\"\"\n",
    "    Load EEG data from parquet files and join it with the train/test data.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The train/test data DataFrame.\n",
    "        eeg_files_paths (list): List of file paths for the EEG parquet files.\n",
    "        schema (StructType): The schema of the EEG data.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The DataFrame with the EEG data joined with the train/test data.\n",
    "    \"\"\"\n",
    "    initial_columns = df.columns\n",
    "    return (\n",
    "        df.alias(\"train\")\n",
    "        .join(\n",
    "            # read the eeg data from parquet files\n",
    "            spark.read.parquet(*eeg_files_paths, schema=eeg_schema)\n",
    "            .withColumn(\n",
    "                \"eeg_id\", regexp_extract(input_file_name(), r\"(\\d+).parquet\", 1)\n",
    "            )\n",
    "            .groupBy(\"eeg_id\")\n",
    "            # collect all eeg data into a single row / array\n",
    "            .agg(\n",
    "                # i.e. collect_list(\"Fp1\").alias(\"Fp1\")\n",
    "                *([collect_list(column).alias(column) for column in cols_to_array])\n",
    "            )\n",
    "            # join the eeg data with the train/test data\n",
    "            .alias(\"eegs\"),  # join alias is needed to avoid ambiguous column names\n",
    "            \"eeg_id\",\n",
    "            \"inner\",\n",
    "        )\n",
    "        .withColumns(  # slice the eeg data to 50 seconds, starting from eeg_label_offset_seconds, data recording frequency is 200Hz\n",
    "            {\n",
    "                column: expr(f\"slice({column}, 200*eeg_label_offset_seconds+1, 200*50)\")\n",
    "                for column in cols_to_array\n",
    "                if \"eeg_label_offset_seconds\" in initial_columns\n",
    "            }\n",
    "        )\n",
    "        .withColumns(  # decrease frequency to ...Hz\n",
    "            {\n",
    "                column: expr(\n",
    "                    f\"FILTER({column}, (element, index) -> index % {eeg_freq_sparse_N} = 0)\"\n",
    "                )\n",
    "                for column in cols_to_array\n",
    "            }\n",
    "        )\n",
    "        .withColumns(  # apply tranformation to the eeg data\n",
    "            {\n",
    "                column: to_vector_udf(stats_summary_udf(f\"{column}\"))\n",
    "                for column in cols_to_array\n",
    "            }\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bab3768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_train_eegs = load_eegs(train_df, train_eeg_files_paths, eeg_schema, eeg_columns_data)\n",
    "\n",
    "if \"eval\" in FLAGS:\n",
    "    df_eval_eegs = load_eegs(\n",
    "        eval_df, eval_eeg_files_paths, eeg_schema, eeg_columns_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27737845",
   "metadata": {},
   "source": [
    "### Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcda6cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spectrograms(df, files_paths, schema, cols_to_array):\n",
    "    \"\"\" \"\"\"\n",
    "    initial_columns = df.columns\n",
    "    return (\n",
    "        df.alias(\"train\")\n",
    "        .join(\n",
    "            # read the eeg data from parquet files\n",
    "            spark.read.parquet(*files_paths, schema=schema)\n",
    "            .withColumn(\n",
    "                \"spectrogram_id\", regexp_extract(input_file_name(), r\"(\\d+).parquet\", 1)\n",
    "            )\n",
    "            .selectExpr(\n",
    "                # \".\" in column name does not help, \".\" will be replaced with \"__\"\n",
    "                *(\n",
    "                    [\"spectrogram_id\", \"time\"]\n",
    "                    + [\n",
    "                        f\"`{column.replace('__', '.')}` as {column}\"\n",
    "                        for column in cols_to_array\n",
    "                    ]\n",
    "                ),\n",
    "            )\n",
    "            .na.fill(0, subset=cols_to_array)\n",
    "            .groupBy(\"spectrogram_id\")\n",
    "            # collect all eeg data into a single array\n",
    "            .agg(\n",
    "                *(\n",
    "                    [\n",
    "                        collect_list(f\"`{column}`\").alias(f\"{column}\")\n",
    "                        for column in cols_to_array\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "            # join the spectrogram to the train/test data\n",
    "            .alias(\"spectrograms\"),\n",
    "            \"spectrogram_id\",\n",
    "            \"inner\",\n",
    "        )\n",
    "        .withColumns(  # slice the eeg data to 600 seconds, starting from ..._offset_seconds\n",
    "            {\n",
    "                f\"{column.replace('.', '__')}\": slice(\n",
    "                    col(f\"`{column.replace('.', '__')}`\"),\n",
    "                    col(\"spectrogram_label_offset_seconds\") + 1,\n",
    "                    600,\n",
    "                )\n",
    "                for column in cols_to_array\n",
    "                if \"spectrogram_label_offset_seconds\" in initial_columns\n",
    "            }\n",
    "        )\n",
    "        .withColumns(  # apply tranformation to the spectrogram data\n",
    "            {\n",
    "                column: to_vector_udf(stats_summary_udf(f\"{column}\"))\n",
    "                for column in cols_to_array\n",
    "            }\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "266d6691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_train_spectrograms = load_spectrograms(\n",
    "    df_train_eegs,\n",
    "    train_spectro_files_paths,\n",
    "    schema=spectrogram_schema,\n",
    "    cols_to_array=spectrogram_columns_data_dot,\n",
    ")\n",
    "\n",
    "if \"eval\" in FLAGS:\n",
    "    df_eval_spectrograms = load_spectrograms(\n",
    "        df_eval_eegs,\n",
    "        eval_spectro_files_paths,\n",
    "        schema=spectrogram_schema,\n",
    "        cols_to_array=spectrogram_columns_data_dot,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6932fa3f",
   "metadata": {},
   "source": [
    "### Execution plan - new the query makes sense :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc5fb4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (35)\n",
      "+- Project (34)\n",
      "   +- BatchEvalPython (33)\n",
      "      +- Project (32)\n",
      "         +- SortMergeJoin Inner (31)\n",
      "            :- Sort (22)\n",
      "            :  +- Exchange (21)\n",
      "            :     +- Project (20)\n",
      "            :        +- BatchEvalPython (19)\n",
      "            :           +- Project (18)\n",
      "            :              +- SortMergeJoin Inner (17)\n",
      "            :                 :- Sort (9)\n",
      "            :                 :  +- Exchange (8)\n",
      "            :                 :     +- Filter (7)\n",
      "            :                 :        +- Sample (6)\n",
      "            :                 :           +- Sort (5)\n",
      "            :                 :              +- Sample (4)\n",
      "            :                 :                 +- Project (3)\n",
      "            :                 :                    +- Filter (2)\n",
      "            :                 :                       +- Scan csv  (1)\n",
      "            :                 +- Sort (16)\n",
      "            :                    +- Exchange (15)\n",
      "            :                       +- ObjectHashAggregate (14)\n",
      "            :                          +- Exchange (13)\n",
      "            :                             +- ObjectHashAggregate (12)\n",
      "            :                                +- Project (11)\n",
      "            :                                   +- Scan parquet  (10)\n",
      "            +- Sort (30)\n",
      "               +- Exchange (29)\n",
      "                  +- ObjectHashAggregate (28)\n",
      "                     +- Exchange (27)\n",
      "                        +- ObjectHashAggregate (26)\n",
      "                           +- Project (25)\n",
      "                              +- Project (24)\n",
      "                                 +- Scan parquet  (23)\n",
      "\n",
      "\n",
      "(1) Scan csv \n",
      "Output [15]: [eeg_id#0L, eeg_sub_id#1, eeg_label_offset_seconds#2, spectrogram_id#3, spectrogram_sub_id#4, spectrogram_label_offset_seconds#5, label_id#6L, patient_id#7, expert_consensus#8, seizure_vote#9, lpd_vote#10, gpd_vote#11, lrda_vote#12, grda_vote#13, other_vote#14]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [file:/scratch/eecs545w24_class_root/eecs545w24_class/shared_data/hms_data/raw_data/train.csv]\n",
      "PushedFilters: [IsNotNull(eeg_sub_id), EqualTo(eeg_sub_id,0)]\n",
      "ReadSchema: struct<eeg_id:bigint,eeg_sub_id:int,eeg_label_offset_seconds:double,spectrogram_id:int,spectrogram_sub_id:int,spectrogram_label_offset_seconds:double,label_id:bigint,patient_id:int,expert_consensus:string,seizure_vote:int,lpd_vote:int,gpd_vote:int,lrda_vote:int,grda_vote:int,other_vote:int>\n",
      "\n",
      "(2) Filter\n",
      "Input [15]: [eeg_id#0L, eeg_sub_id#1, eeg_label_offset_seconds#2, spectrogram_id#3, spectrogram_sub_id#4, spectrogram_label_offset_seconds#5, label_id#6L, patient_id#7, expert_consensus#8, seizure_vote#9, lpd_vote#10, gpd_vote#11, lrda_vote#12, grda_vote#13, other_vote#14]\n",
      "Condition : (isnotnull(eeg_sub_id#1) AND (eeg_sub_id#1 = 0))\n",
      "\n",
      "(3) Project\n",
      "Output [22]: [eeg_id#0L, eeg_sub_id#1, cast(eeg_label_offset_seconds#2 as int) AS eeg_label_offset_seconds#31, spectrogram_id#3, spectrogram_sub_id#4, cast(spectrogram_label_offset_seconds#5 as int) AS spectrogram_label_offset_seconds#47, label_id#6L, patient_id#7, expert_consensus#8, seizure_vote#9, lpd_vote#10, gpd_vote#11, lrda_vote#12, grda_vote#13, other_vote#14, expert_consensus#8 AS label#63, (cast(seizure_vote#9 as double) / cast((((((seizure_vote#9 + lpd_vote#10) + gpd_vote#11) + lrda_vote#12) + grda_vote#13) + other_vote#14) as double)) AS seizure_vote_actual#80, (cast(lpd_vote#10 as double) / cast((((((seizure_vote#9 + lpd_vote#10) + gpd_vote#11) + lrda_vote#12) + grda_vote#13) + other_vote#14) as double)) AS lpd_vote_actual#81, (cast(gpd_vote#11 as double) / cast((((((seizure_vote#9 + lpd_vote#10) + gpd_vote#11) + lrda_vote#12) + grda_vote#13) + other_vote#14) as double)) AS gpd_vote_actual#82, (cast(lrda_vote#12 as double) / cast((((((seizure_vote#9 + lpd_vote#10) + gpd_vote#11) + lrda_vote#12) + grda_vote#13) + other_vote#14) as double)) AS lrda_vote_actual#83, (cast(grda_vote#13 as double) / cast((((((seizure_vote#9 + lpd_vote#10) + gpd_vote#11) + lrda_vote#12) + grda_vote#13) + other_vote#14) as double)) AS grda_vote_actual#84, (cast(other_vote#14 as double) / cast((((((seizure_vote#9 + lpd_vote#10) + gpd_vote#11) + lrda_vote#12) + grda_vote#13) + other_vote#14) as double)) AS other_vote_actual#85]\n",
      "Input [15]: [eeg_id#0L, eeg_sub_id#1, eeg_label_offset_seconds#2, spectrogram_id#3, spectrogram_sub_id#4, spectrogram_label_offset_seconds#5, label_id#6L, patient_id#7, expert_consensus#8, seizure_vote#9, lpd_vote#10, gpd_vote#11, lrda_vote#12, grda_vote#13, other_vote#14]\n",
      "\n",
      "(4) Sample\n",
      "Input [22]: [eeg_id#0L, eeg_sub_id#1, eeg_label_offset_seconds#31, spectrogram_id#3, spectrogram_sub_id#4, spectrogram_label_offset_seconds#47, label_id#6L, patient_id#7, expert_consensus#8, seizure_vote#9, lpd_vote#10, gpd_vote#11, lrda_vote#12, grda_vote#13, other_vote#14, label#63, seizure_vote_actual#80, lpd_vote_actual#81, gpd_vote_actual#82, lrda_vote_actual#83, grda_vote_actual#84, other_vote_actual#85]\n",
      "Arguments: 0.0, 0.1, false, 42\n",
      "\n",
      "(5) Sort\n",
      "Input [22]: [eeg_id#0L, eeg_sub_id#1, eeg_label_offset_seconds#31, spectrogram_id#3, spectrogram_sub_id#4, spectrogram_label_offset_seconds#47, label_id#6L, patient_id#7, expert_consensus#8, seizure_vote#9, lpd_vote#10, gpd_vote#11, lrda_vote#12, grda_vote#13, other_vote#14, label#63, seizure_vote_actual#80, lpd_vote_actual#81, gpd_vote_actual#82, lrda_vote_actual#83, grda_vote_actual#84, other_vote_actual#85]\n",
      "Arguments: [eeg_id#0L ASC NULLS FIRST, eeg_sub_id#1 ASC NULLS FIRST, eeg_label_offset_seconds#31 ASC NULLS FIRST, spectrogram_id#3 ASC NULLS FIRST, spectrogram_sub_id#4 ASC NULLS FIRST, spectrogram_label_offset_seconds#47 ASC NULLS FIRST, label_id#6L ASC NULLS FIRST, patient_id#7 ASC NULLS FIRST, expert_consensus#8 ASC NULLS FIRST, seizure_vote#9 ASC NULLS FIRST, lpd_vote#10 ASC NULLS FIRST, gpd_vote#11 ASC NULLS FIRST, lrda_vote#12 ASC NULLS FIRST, grda_vote#13 ASC NULLS FIRST, other_vote#14 ASC NULLS FIRST, label#63 ASC NULLS FIRST, seizure_vote_actual#80 ASC NULLS FIRST, lpd_vote_actual#81 ASC NULLS FIRST, gpd_vote_actual#82 ASC NULLS FIRST, lrda_vote_actual#83 ASC NULLS FIRST, grda_vote_actual#84 ASC NULLS FIRST, other_vote_actual#85 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(6) Sample\n",
      "Input [22]: [eeg_id#0L, eeg_sub_id#1, eeg_label_offset_seconds#31, spectrogram_id#3, spectrogram_sub_id#4, spectrogram_label_offset_seconds#47, label_id#6L, patient_id#7, expert_consensus#8, seizure_vote#9, lpd_vote#10, gpd_vote#11, lrda_vote#12, grda_vote#13, other_vote#14, label#63, seizure_vote_actual#80, lpd_vote_actual#81, gpd_vote_actual#82, lrda_vote_actual#83, grda_vote_actual#84, other_vote_actual#85]\n",
      "Arguments: 0.0, 0.7, false, 42\n",
      "\n",
      "(7) Filter\n",
      "Input [22]: [eeg_id#0L, eeg_sub_id#1, eeg_label_offset_seconds#31, spectrogram_id#3, spectrogram_sub_id#4, spectrogram_label_offset_seconds#47, label_id#6L, patient_id#7, expert_consensus#8, seizure_vote#9, lpd_vote#10, gpd_vote#11, lrda_vote#12, grda_vote#13, other_vote#14, label#63, seizure_vote_actual#80, lpd_vote_actual#81, gpd_vote_actual#82, lrda_vote_actual#83, grda_vote_actual#84, other_vote_actual#85]\n",
      "Condition : (isnotnull(eeg_id#0L) AND isnotnull(spectrogram_id#3))\n",
      "\n",
      "(8) Exchange\n",
      "Input [22]: [eeg_id#0L, eeg_sub_id#1, eeg_label_offset_seconds#31, spectrogram_id#3, spectrogram_sub_id#4, spectrogram_label_offset_seconds#47, label_id#6L, patient_id#7, expert_consensus#8, seizure_vote#9, lpd_vote#10, gpd_vote#11, lrda_vote#12, grda_vote#13, other_vote#14, label#63, seizure_vote_actual#80, lpd_vote_actual#81, gpd_vote_actual#82, lrda_vote_actual#83, grda_vote_actual#84, other_vote_actual#85]\n",
      "Arguments: hashpartitioning(eeg_id#0L, 200), ENSURE_REQUIREMENTS, [plan_id=418]\n",
      "\n",
      "(9) Sort\n",
      "Input [22]: [eeg_id#0L, eeg_sub_id#1, eeg_label_offset_seconds#31, spectrogram_id#3, spectrogram_sub_id#4, spectrogram_label_offset_seconds#47, label_id#6L, patient_id#7, expert_consensus#8, seizure_vote#9, lpd_vote#10, gpd_vote#11, lrda_vote#12, grda_vote#13, other_vote#14, label#63, seizure_vote_actual#80, lpd_vote_actual#81, gpd_vote_actual#82, lrda_vote_actual#83, grda_vote_actual#84, other_vote_actual#85]\n",
      "Arguments: [eeg_id#0L ASC NULLS FIRST], false, 0\n",
      "\n",
      "(10) Scan parquet \n",
      "Output [20]: [Fp1#180, F3#181, C3#182, P3#183, F7#184, T3#185, T5#186, O1#187, Fz#188, Cz#189, Pz#190, Fp2#191, F4#192, C4#193, P4#194, F8#195, T4#196, T6#197, O2#198, EKG#199]\n",
      "Batched: true\n",
      "Location: InMemoryFileIndex [file:/scratch/eecs545w24_class_root/eecs545w24_class/shared_data/hms_data/raw_data/train_eegs/485707667.parquet, ... 1276 entries]\n",
      "ReadSchema: struct<Fp1:float,F3:float,C3:float,P3:float,F7:float,T3:float,T5:float,O1:float,Fz:float,Cz:float,Pz:float,Fp2:float,F4:float,C4:float,P4:float,F8:float,T4:float,T6:float,O2:float,EKG:float>\n",
      "\n",
      "(11) Project\n",
      "Output [21]: [Fp1#180, F3#181, C3#182, P3#183, F7#184, T3#185, T5#186, O1#187, Fz#188, Cz#189, Pz#190, Fp2#191, F4#192, C4#193, P4#194, F8#195, T4#196, T6#197, O2#198, EKG#199, regexp_extract(input_file_name(), (\\d+).parquet, 1) AS eeg_id#220]\n",
      "Input [20]: [Fp1#180, F3#181, C3#182, P3#183, F7#184, T3#185, T5#186, O1#187, Fz#188, Cz#189, Pz#190, Fp2#191, F4#192, C4#193, P4#194, F8#195, T4#196, T6#197, O2#198, EKG#199]\n",
      "\n",
      "(12) ObjectHashAggregate\n",
      "Input [21]: [Fp1#180, F3#181, C3#182, P3#183, F7#184, T3#185, T5#186, O1#187, Fz#188, Cz#189, Pz#190, Fp2#191, F4#192, C4#193, P4#194, F8#195, T4#196, T6#197, O2#198, EKG#199, eeg_id#220]\n",
      "Keys [1]: [eeg_id#220]\n",
      "Functions [20]: [partial_collect_list(Fp1#180, 0, 0), partial_collect_list(F3#181, 0, 0), partial_collect_list(C3#182, 0, 0), partial_collect_list(P3#183, 0, 0), partial_collect_list(F7#184, 0, 0), partial_collect_list(T3#185, 0, 0), partial_collect_list(T5#186, 0, 0), partial_collect_list(O1#187, 0, 0), partial_collect_list(Fz#188, 0, 0), partial_collect_list(Cz#189, 0, 0), partial_collect_list(Pz#190, 0, 0), partial_collect_list(Fp2#191, 0, 0), partial_collect_list(F4#192, 0, 0), partial_collect_list(C4#193, 0, 0), partial_collect_list(P4#194, 0, 0), partial_collect_list(F8#195, 0, 0), partial_collect_list(T4#196, 0, 0), partial_collect_list(T6#197, 0, 0), partial_collect_list(O2#198, 0, 0), partial_collect_list(EKG#199, 0, 0)]\n",
      "Aggregate Attributes [20]: [buf#5108, buf#5109, buf#5110, buf#5111, buf#5112, buf#5113, buf#5114, buf#5115, buf#5116, buf#5117, buf#5118, buf#5119, buf#5120, buf#5121, buf#5122, buf#5123, buf#5124, buf#5125, buf#5126, buf#5127]\n",
      "Results [21]: [eeg_id#220, buf#5128, buf#5129, buf#5130, buf#5131, buf#5132, buf#5133, buf#5134, buf#5135, buf#5136, buf#5137, buf#5138, buf#5139, buf#5140, buf#5141, buf#5142, buf#5143, buf#5144, buf#5145, buf#5146, buf#5147]\n",
      "\n",
      "(13) Exchange\n",
      "Input [21]: [eeg_id#220, buf#5128, buf#5129, buf#5130, buf#5131, buf#5132, buf#5133, buf#5134, buf#5135, buf#5136, buf#5137, buf#5138, buf#5139, buf#5140, buf#5141, buf#5142, buf#5143, buf#5144, buf#5145, buf#5146, buf#5147]\n",
      "Arguments: hashpartitioning(eeg_id#220, 200), ENSURE_REQUIREMENTS, [plan_id=414]\n",
      "\n",
      "(14) ObjectHashAggregate\n",
      "Input [21]: [eeg_id#220, buf#5128, buf#5129, buf#5130, buf#5131, buf#5132, buf#5133, buf#5134, buf#5135, buf#5136, buf#5137, buf#5138, buf#5139, buf#5140, buf#5141, buf#5142, buf#5143, buf#5144, buf#5145, buf#5146, buf#5147]\n",
      "Keys [1]: [eeg_id#220]\n",
      "Functions [20]: [collect_list(Fp1#180, 0, 0), collect_list(F3#181, 0, 0), collect_list(C3#182, 0, 0), collect_list(P3#183, 0, 0), collect_list(F7#184, 0, 0), collect_list(T3#185, 0, 0), collect_list(T5#186, 0, 0), collect_list(O1#187, 0, 0), collect_list(Fz#188, 0, 0), collect_list(Cz#189, 0, 0), collect_list(Pz#190, 0, 0), collect_list(Fp2#191, 0, 0), collect_list(F4#192, 0, 0), collect_list(C4#193, 0, 0), collect_list(P4#194, 0, 0), collect_list(F8#195, 0, 0), collect_list(T4#196, 0, 0), collect_list(T6#197, 0, 0), collect_list(O2#198, 0, 0), collect_list(EKG#199, 0, 0)]\n",
      "Aggregate Attributes [20]: [collect_list(Fp1#180, 0, 0)#264, collect_list(F3#181, 0, 0)#266, collect_list(C3#182, 0, 0)#268, collect_list(P3#183, 0, 0)#270, collect_list(F7#184, 0, 0)#272, collect_list(T3#185, 0, 0)#274, collect_list(T5#186, 0, 0)#276, collect_list(O1#187, 0, 0)#278, collect_list(Fz#188, 0, 0)#280, collect_list(Cz#189, 0, 0)#282, collect_list(Pz#190, 0, 0)#284, collect_list(Fp2#191, 0, 0)#286, collect_list(F4#192, 0, 0)#288, collect_list(C4#193, 0, 0)#290, collect_list(P4#194, 0, 0)#292, collect_list(F8#195, 0, 0)#294, collect_list(T4#196, 0, 0)#296, collect_list(T6#197, 0, 0)#298, collect_list(O2#198, 0, 0)#300, collect_list(EKG#199, 0, 0)#302]\n",
      "Results [21]: [eeg_id#220, collect_list(Fp1#180, 0, 0)#264 AS Fp1#265, collect_list(F3#181, 0, 0)#266 AS F3#267, collect_list(C3#182, 0, 0)#268 AS C3#269, collect_list(P3#183, 0, 0)#270 AS P3#271, collect_list(F7#184, 0, 0)#272 AS F7#273, collect_list(T3#185, 0, 0)#274 AS T3#275, collect_list(T5#186, 0, 0)#276 AS T5#277, collect_list(O1#187, 0, 0)#278 AS O1#279, collect_list(Fz#188, 0, 0)#280 AS Fz#281, collect_list(Cz#189, 0, 0)#282 AS Cz#283, collect_list(Pz#190, 0, 0)#284 AS Pz#285, collect_list(Fp2#191, 0, 0)#286 AS Fp2#287, collect_list(F4#192, 0, 0)#288 AS F4#289, collect_list(C4#193, 0, 0)#290 AS C4#291, collect_list(P4#194, 0, 0)#292 AS P4#293, collect_list(F8#195, 0, 0)#294 AS F8#295, collect_list(T4#196, 0, 0)#296 AS T4#297, collect_list(T6#197, 0, 0)#298 AS T6#299, collect_list(O2#198, 0, 0)#300 AS O2#301, collect_list(EKG#199, 0, 0)#302 AS EKG#303]\n",
      "\n",
      "(15) Exchange\n",
      "Input [21]: [eeg_id#220, Fp1#265, F3#267, C3#269, P3#271, F7#273, T3#275, T5#277, O1#279, Fz#281, Cz#283, Pz#285, Fp2#287, F4#289, C4#291, P4#293, F8#295, T4#297, T6#299, O2#301, EKG#303]\n",
      "Arguments: hashpartitioning(cast(eeg_id#220 as bigint), 200), ENSURE_REQUIREMENTS, [plan_id=419]\n",
      "\n",
      "(16) Sort\n",
      "Input [21]: [eeg_id#220, Fp1#265, F3#267, C3#269, P3#271, F7#273, T3#275, T5#277, O1#279, Fz#281, Cz#283, Pz#285, Fp2#287, F4#289, C4#291, P4#293, F8#295, T4#297, T6#299, O2#301, EKG#303]\n",
      "Arguments: [cast(eeg_id#220 as bigint) ASC NULLS FIRST], false, 0\n",
      "\n",
      "(17) SortMergeJoin\n",
      "Left keys [1]: [eeg_id#0L]\n",
      "Right keys [1]: [cast(eeg_id#220 as bigint)]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(18) Project\n",
      "Output [42]: [eeg_id#0L, eeg_sub_id#1, eeg_label_offset_seconds#31, spectrogram_id#3, spectrogram_sub_id#4, spectrogram_label_offset_seconds#47, label_id#6L, patient_id#7, expert_consensus#8, seizure_vote#9, lpd_vote#10, gpd_vote#11, lrda_vote#12, grda_vote#13, other_vote#14, label#63, seizure_vote_actual#80, lpd_vote_actual#81, gpd_vote_actual#82, lrda_vote_actual#83, grda_vote_actual#84, other_vote_actual#85, Fp1#265, F3#267, C3#269, P3#271, F7#273, T3#275, T5#277, O1#279, Fz#281, Cz#283, Pz#285, Fp2#287, F4#289, C4#291, P4#293, F8#295, T4#297, T6#299, O2#301, EKG#303]\n",
      "Input [43]: [eeg_id#0L, eeg_sub_id#1, eeg_label_offset_seconds#31, spectrogram_id#3, spectrogram_sub_id#4, spectrogram_label_offset_seconds#47, label_id#6L, patient_id#7, expert_consensus#8, seizure_vote#9, lpd_vote#10, gpd_vote#11, lrda_vote#12, grda_vote#13, other_vote#14, label#63, seizure_vote_actual#80, lpd_vote_actual#81, gpd_vote_actual#82, lrda_vote_actual#83, grda_vote_actual#84, other_vote_actual#85, eeg_id#220, Fp1#265, F3#267, C3#269, P3#271, F7#273, T3#275, T5#277, O1#279, Fz#281, Cz#283, Pz#285, Fp2#287, F4#289, C4#291, P4#293, F8#295, T4#297, T6#299, O2#301, EKG#303]\n",
      "\n",
      "(19) BatchEvalPython\n",
      "Input [42]: [eeg_id#0L, eeg_sub_id#1, eeg_label_offset_seconds#31, spectrogram_id#3, spectrogram_sub_id#4, spectrogram_label_offset_seconds#47, label_id#6L, patient_id#7, expert_consensus#8, seizure_vote#9, lpd_vote#10, gpd_vote#11, lrda_vote#12, grda_vote#13, other_vote#14, label#63, seizure_vote_actual#80, lpd_vote_actual#81, gpd_vote_actual#82, lrda_vote_actual#83, grda_vote_actual#84, other_vote_actual#85, Fp1#265, F3#267, C3#269, P3#271, F7#273, T3#275, T5#277, O1#279, Fz#281, Cz#283, Pz#285, Fp2#287, F4#289, C4#291, P4#293, F8#295, T4#297, T6#299, O2#301, EKG#303]\n",
      "Arguments: [<lambda>(stats_summary_udf(filter(slice(Fp1#265, ((200 * eeg_label_offset_seconds#31) + 1), 10000), lambdafunction(((lambda index#450 % 20) = 0), lambda element#449, lambda index#450, false)))#531)#532, <lambda>(stats_summary_udf(filter(slice(F3#267, ((200 * eeg_label_offset_seconds#31) + 1), 10000), lambdafunction(((lambda index#452 % 20) = 0), lambda element#451, lambda index#452, false)))#533)#534, <lambda>(stats_summary_udf(filter(slice(C3#269, ((200 * eeg_label_offset_seconds#31) + 1), 10000), lambdafunction(((lambda index#454 % 20) = 0), lambda element#453, lambda index#454, false)))#535)#536, <lambda>(stats_summary_udf(filter(slice(P3#271, ((200 * eeg_label_offset_seconds#31) + 1), 10000), lambdafunction(((lambda index#456 % 20) = 0), lambda element#455, lambda index#456, false)))#537)#538, <lambda>(stats_summary_udf(filter(slice(F7#273, ((200 * eeg_label_offset_seconds#31) + 1), 10000), lambdafunction(((lambda index#458 % 20) = 0), lambda element#457, lambda index#458, false)))#539)#540, <lambda>(stats_summary_udf(filter(slice(T3#275, ((200 * eeg_label_offset_seconds#31) + 1), 10000), lambdafunction(((lambda index#460 % 20) = 0), lambda element#459, lambda index#460, false)))#541)#542, <lambda>(stats_summary_udf(filter(slice(T5#277, ((200 * eeg_label_offset_seconds#31) + 1), 10000), lambdafunction(((lambda index#462 % 20) = 0), lambda element#461, lambda index#462, false)))#543)#544, <lambda>(stats_summary_udf(filter(slice(O1#279, ((200 * eeg_label_offset_seconds#31) + 1), 10000), lambdafunction(((lambda index#464 % 20) = 0), lambda element#463, lambda index#464, false)))#545)#546, <lambda>(stats_summary_udf(filter(slice(Fz#281, ((200 * eeg_label_offset_seconds#31) + 1), 10000), lambdafunction(((lambda index#466 % 20) = 0), lambda element#465, lambda index#466, false)))#547)#548, <lambda>(stats_summary_udf(filter(slice(Cz#283, ((200 * eeg_label_offset_seconds#31) + 1), 10000), lambdafunction(((lambda index#468 % 20) = 0), lambda element#467, lambda index#468, false)))#549)#550, <lambda>(stats_summary_udf(filter(slice(Pz#285, ((200 * eeg_label_offset_seconds#31) + 1), 10000), lambdafunction(((lambda index#470 % 20) = 0), lambda element#469, lambda index#470, false)))#551)#552, <lambda>(stats_summary_udf(filter(slice(Fp2#287, ((200 * eeg_label_offset_seconds#31) + 1), 10000), lambdafunction(((lambda index#472 % 20) = 0), lambda element#471, lambda index#472, false)))#553)#554, <lambda>(stats_summary_udf(filter(slice(F4#289, ((200 * eeg_label_offset_seconds#31) + 1), 10000), lambdafunction(((lambda index#474 % 20) = 0), lambda element#473, lambda index#474, false)))#555)#556, <lambda>(stats_summary_udf(filter(slice(C4#291, ((200 * eeg_label_offset_seconds#31) + 1), 10000), lambdafunction(((lambda index#476 % 20) = 0), lambda element#475, lambda index#476, false)))#557)#558, <lambda>(stats_summary_udf(filter(slice(P4#293, ((200 * eeg_label_offset_seconds#31) + 1), 10000), lambdafunction(((lambda index#478 % 20) = 0), lambda element#477, lambda index#478, false)))#559)#560, <lambda>(stats_summary_udf(filter(slice(F8#295, ((200 * eeg_label_offset_seconds#31) + 1), 10000), lambdafunction(((lambda index#480 % 20) = 0), lambda element#479, lambda index#480, false)))#561)#562, <lambda>(stats_summary_udf(filter(slice(T4#297, ((200 * eeg_label_offset_seconds#31) + 1), 10000), lambdafunction(((lambda index#482 % 20) = 0), lambda element#481, lambda index#482, false)))#563)#564, <lambda>(stats_summary_udf(filter(slice(T6#299, ((200 * eeg_label_offset_seconds#31) + 1), 10000), lambdafunction(((lambda index#484 % 20) = 0), lambda element#483, lambda index#484, false)))#565)#566, <lambda>(stats_summary_udf(filter(slice(O2#301, ((200 * eeg_label_offset_seconds#31) + 1), 10000), lambdafunction(((lambda index#486 % 20) = 0), lambda element#485, lambda index#486, false)))#567)#568, <lambda>(stats_summary_udf(filter(slice(EKG#303, ((200 * eeg_label_offset_seconds#31) + 1), 10000), lambdafunction(((lambda index#488 % 20) = 0), lambda element#487, lambda index#488, false)))#569)#570], [pythonUDF0#5048, pythonUDF1#5049, pythonUDF2#5050, pythonUDF3#5051, pythonUDF4#5052, pythonUDF5#5053, pythonUDF6#5054, pythonUDF7#5055, pythonUDF8#5056, pythonUDF9#5057, pythonUDF10#5058, pythonUDF11#5059, pythonUDF12#5060, pythonUDF13#5061, pythonUDF14#5062, pythonUDF15#5063, pythonUDF16#5064, pythonUDF17#5065, pythonUDF18#5066, pythonUDF19#5067]\n",
      "\n",
      "(20) Project\n",
      "Output [42]: [eeg_id#0L, eeg_sub_id#1, eeg_label_offset_seconds#31, spectrogram_id#3, spectrogram_sub_id#4, spectrogram_label_offset_seconds#47, label_id#6L, patient_id#7, expert_consensus#8, seizure_vote#9, lpd_vote#10, gpd_vote#11, lrda_vote#12, grda_vote#13, other_vote#14, label#63, seizure_vote_actual#80, lpd_vote_actual#81, gpd_vote_actual#82, lrda_vote_actual#83, grda_vote_actual#84, other_vote_actual#85, pythonUDF0#5048 AS Fp1#571, pythonUDF1#5049 AS F3#572, pythonUDF2#5050 AS C3#573, pythonUDF3#5051 AS P3#574, pythonUDF4#5052 AS F7#575, pythonUDF5#5053 AS T3#576, pythonUDF6#5054 AS T5#577, pythonUDF7#5055 AS O1#578, pythonUDF8#5056 AS Fz#579, pythonUDF9#5057 AS Cz#580, pythonUDF10#5058 AS Pz#581, pythonUDF11#5059 AS Fp2#582, pythonUDF12#5060 AS F4#583, pythonUDF13#5061 AS C4#584, pythonUDF14#5062 AS P4#585, pythonUDF15#5063 AS F8#586, pythonUDF16#5064 AS T4#587, pythonUDF17#5065 AS T6#588, pythonUDF18#5066 AS O2#589, pythonUDF19#5067 AS EKG#590]\n",
      "Input [62]: [eeg_id#0L, eeg_sub_id#1, eeg_label_offset_seconds#31, spectrogram_id#3, spectrogram_sub_id#4, spectrogram_label_offset_seconds#47, label_id#6L, patient_id#7, expert_consensus#8, seizure_vote#9, lpd_vote#10, gpd_vote#11, lrda_vote#12, grda_vote#13, other_vote#14, label#63, seizure_vote_actual#80, lpd_vote_actual#81, gpd_vote_actual#82, lrda_vote_actual#83, grda_vote_actual#84, other_vote_actual#85, Fp1#265, F3#267, C3#269, P3#271, F7#273, T3#275, T5#277, O1#279, Fz#281, Cz#283, Pz#285, Fp2#287, F4#289, C4#291, P4#293, F8#295, T4#297, T6#299, O2#301, EKG#303, pythonUDF0#5048, pythonUDF1#5049, pythonUDF2#5050, pythonUDF3#5051, pythonUDF4#5052, pythonUDF5#5053, pythonUDF6#5054, pythonUDF7#5055, pythonUDF8#5056, pythonUDF9#5057, pythonUDF10#5058, pythonUDF11#5059, pythonUDF12#5060, pythonUDF13#5061, pythonUDF14#5062, pythonUDF15#5063, pythonUDF16#5064, pythonUDF17#5065, pythonUDF18#5066, pythonUDF19#5067]\n",
      "\n",
      "(21) Exchange\n",
      "Input [42]: [eeg_id#0L, eeg_sub_id#1, eeg_label_offset_seconds#31, spectrogram_id#3, spectrogram_sub_id#4, spectrogram_label_offset_seconds#47, label_id#6L, patient_id#7, expert_consensus#8, seizure_vote#9, lpd_vote#10, gpd_vote#11, lrda_vote#12, grda_vote#13, other_vote#14, label#63, seizure_vote_actual#80, lpd_vote_actual#81, gpd_vote_actual#82, lrda_vote_actual#83, grda_vote_actual#84, other_vote_actual#85, Fp1#571, F3#572, C3#573, P3#574, F7#575, T3#576, T5#577, O1#578, Fz#579, Cz#580, Pz#581, Fp2#582, F4#583, C4#584, P4#585, F8#586, T4#587, T6#588, O2#589, EKG#590]\n",
      "Arguments: hashpartitioning(spectrogram_id#3, 200), ENSURE_REQUIREMENTS, [plan_id=430]\n",
      "\n",
      "(22) Sort\n",
      "Input [42]: [eeg_id#0L, eeg_sub_id#1, eeg_label_offset_seconds#31, spectrogram_id#3, spectrogram_sub_id#4, spectrogram_label_offset_seconds#47, label_id#6L, patient_id#7, expert_consensus#8, seizure_vote#9, lpd_vote#10, gpd_vote#11, lrda_vote#12, grda_vote#13, other_vote#14, label#63, seizure_vote_actual#80, lpd_vote_actual#81, gpd_vote_actual#82, lrda_vote_actual#83, grda_vote_actual#84, other_vote_actual#85, Fp1#571, F3#572, C3#573, P3#574, F7#575, T3#576, T5#577, O1#578, Fz#579, Cz#580, Pz#581, Fp2#582, F4#583, C4#584, P4#585, F8#586, T4#587, T6#588, O2#589, EKG#590]\n",
      "Arguments: [spectrogram_id#3 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(23) Scan parquet \n",
      "Output [40]: [LL_0.59#1087, LL_2.54#1097, LL_4.49#1107, LL_6.45#1117, LL_8.4#1127, LL_10.35#1137, LL_12.3#1147, LL_14.26#1157, LL_16.21#1167, LL_18.16#1177, RL_0.59#1187, RL_2.54#1197, RL_4.49#1207, RL_6.45#1217, RL_8.4#1227, RL_10.35#1237, RL_12.3#1247, RL_14.26#1257, RL_16.21#1267, RL_18.16#1277, LP_0.59#1287, LP_2.54#1297, LP_4.49#1307, LP_6.45#1317, LP_8.4#1327, LP_10.35#1337, LP_12.3#1347, LP_14.26#1357, LP_16.21#1367, LP_18.16#1377, RP_0.59#1387, RP_2.54#1397, RP_4.49#1407, RP_6.45#1417, RP_8.4#1427, RP_10.35#1437, RP_12.3#1447, RP_14.26#1457, RP_16.21#1467, RP_18.16#1477]\n",
      "Batched: true\n",
      "Location: InMemoryFileIndex [file:/scratch/eecs545w24_class_root/eecs545w24_class/shared_data/hms_data/raw_data/train_spectrograms/422695038.parquet, ... 1156 entries]\n",
      "ReadSchema: struct<LL_0.59:float,LL_2.54:float,LL_4.49:float,LL_6.45:float,LL_8.4:float,LL_10.35:float,LL_12.3:float,LL_14.26:float,LL_16.21:float,LL_18.16:float,RL_0.59:float,RL_2.54:float,RL_4.49:float,RL_6.45:float,RL_8.4:float,RL_10.35:float,RL_12.3:float,RL_14.26:float,RL_16.21:float,RL_18.16:float,LP_0.59:float,LP_2.54:float,LP_4.49:float,LP_6.45:float,LP_8.4:float,LP_10.35:float,LP_12.3:float,LP_14.26:float,LP_16.21:float,LP_18.16:float,RP_0.59:float,RP_2.54:float,RP_4.49:float,RP_6.45:float,RP_8.4:float,RP_10.35:float,RP_12.3:float,RP_14.26:float,RP_16.21:float,RP_18.16:float>\n",
      "\n",
      "(24) Project\n",
      "Output [41]: [LL_0.59#1087, LL_2.54#1097, LL_4.49#1107, LL_6.45#1117, LL_8.4#1127, LL_10.35#1137, LL_12.3#1147, LL_14.26#1157, LL_16.21#1167, LL_18.16#1177, RL_0.59#1187, RL_2.54#1197, RL_4.49#1207, RL_6.45#1217, RL_8.4#1227, RL_10.35#1237, RL_12.3#1247, RL_14.26#1257, RL_16.21#1267, RL_18.16#1277, LP_0.59#1287, LP_2.54#1297, LP_4.49#1307, LP_6.45#1317, LP_8.4#1327, LP_10.35#1337, LP_12.3#1347, LP_14.26#1357, LP_16.21#1367, LP_18.16#1377, RP_0.59#1387, RP_2.54#1397, RP_4.49#1407, RP_6.45#1417, RP_8.4#1427, RP_10.35#1437, RP_12.3#1447, RP_14.26#1457, RP_16.21#1467, RP_18.16#1477, regexp_extract(input_file_name(), (\\d+).parquet, 1) AS spectrogram_id#1888]\n",
      "Input [40]: [LL_0.59#1087, LL_2.54#1097, LL_4.49#1107, LL_6.45#1117, LL_8.4#1127, LL_10.35#1137, LL_12.3#1147, LL_14.26#1157, LL_16.21#1167, LL_18.16#1177, RL_0.59#1187, RL_2.54#1197, RL_4.49#1207, RL_6.45#1217, RL_8.4#1227, RL_10.35#1237, RL_12.3#1247, RL_14.26#1257, RL_16.21#1267, RL_18.16#1277, LP_0.59#1287, LP_2.54#1297, LP_4.49#1307, LP_6.45#1317, LP_8.4#1327, LP_10.35#1337, LP_12.3#1347, LP_14.26#1357, LP_16.21#1367, LP_18.16#1377, RP_0.59#1387, RP_2.54#1397, RP_4.49#1407, RP_6.45#1417, RP_8.4#1427, RP_10.35#1437, RP_12.3#1447, RP_14.26#1457, RP_16.21#1467, RP_18.16#1477]\n",
      "\n",
      "(25) Project\n",
      "Output [41]: [spectrogram_id#1888, coalesce(nanvl(LL_0.59#1087, null), 0.0) AS LL_0__59#2416, coalesce(nanvl(LL_2.54#1097, null), 0.0) AS LL_2__54#2417, coalesce(nanvl(LL_4.49#1107, null), 0.0) AS LL_4__49#2418, coalesce(nanvl(LL_6.45#1117, null), 0.0) AS LL_6__45#2419, coalesce(nanvl(LL_8.4#1127, null), 0.0) AS LL_8__4#2420, coalesce(nanvl(LL_10.35#1137, null), 0.0) AS LL_10__35#2421, coalesce(nanvl(LL_12.3#1147, null), 0.0) AS LL_12__3#2422, coalesce(nanvl(LL_14.26#1157, null), 0.0) AS LL_14__26#2423, coalesce(nanvl(LL_16.21#1167, null), 0.0) AS LL_16__21#2424, coalesce(nanvl(LL_18.16#1177, null), 0.0) AS LL_18__16#2425, coalesce(nanvl(RL_0.59#1187, null), 0.0) AS RL_0__59#2426, coalesce(nanvl(RL_2.54#1197, null), 0.0) AS RL_2__54#2427, coalesce(nanvl(RL_4.49#1207, null), 0.0) AS RL_4__49#2428, coalesce(nanvl(RL_6.45#1217, null), 0.0) AS RL_6__45#2429, coalesce(nanvl(RL_8.4#1227, null), 0.0) AS RL_8__4#2430, coalesce(nanvl(RL_10.35#1237, null), 0.0) AS RL_10__35#2431, coalesce(nanvl(RL_12.3#1247, null), 0.0) AS RL_12__3#2432, coalesce(nanvl(RL_14.26#1257, null), 0.0) AS RL_14__26#2433, coalesce(nanvl(RL_16.21#1267, null), 0.0) AS RL_16__21#2434, coalesce(nanvl(RL_18.16#1277, null), 0.0) AS RL_18__16#2435, coalesce(nanvl(RP_0.59#1387, null), 0.0) AS RP_0__59#2436, coalesce(nanvl(RP_2.54#1397, null), 0.0) AS RP_2__54#2437, coalesce(nanvl(RP_4.49#1407, null), 0.0) AS RP_4__49#2438, coalesce(nanvl(RP_6.45#1417, null), 0.0) AS RP_6__45#2439, coalesce(nanvl(RP_8.4#1427, null), 0.0) AS RP_8__4#2440, coalesce(nanvl(RP_10.35#1437, null), 0.0) AS RP_10__35#2441, coalesce(nanvl(RP_12.3#1447, null), 0.0) AS RP_12__3#2442, coalesce(nanvl(RP_14.26#1457, null), 0.0) AS RP_14__26#2443, coalesce(nanvl(RP_16.21#1467, null), 0.0) AS RP_16__21#2444, coalesce(nanvl(RP_18.16#1477, null), 0.0) AS RP_18__16#2445, coalesce(nanvl(LP_0.59#1287, null), 0.0) AS LP_0__59#2446, coalesce(nanvl(LP_2.54#1297, null), 0.0) AS LP_2__54#2447, coalesce(nanvl(LP_4.49#1307, null), 0.0) AS LP_4__49#2448, coalesce(nanvl(LP_6.45#1317, null), 0.0) AS LP_6__45#2449, coalesce(nanvl(LP_8.4#1327, null), 0.0) AS LP_8__4#2450, coalesce(nanvl(LP_10.35#1337, null), 0.0) AS LP_10__35#2451, coalesce(nanvl(LP_12.3#1347, null), 0.0) AS LP_12__3#2452, coalesce(nanvl(LP_14.26#1357, null), 0.0) AS LP_14__26#2453, coalesce(nanvl(LP_16.21#1367, null), 0.0) AS LP_16__21#2454, coalesce(nanvl(LP_18.16#1377, null), 0.0) AS LP_18__16#2455]\n",
      "Input [41]: [LL_0.59#1087, LL_2.54#1097, LL_4.49#1107, LL_6.45#1117, LL_8.4#1127, LL_10.35#1137, LL_12.3#1147, LL_14.26#1157, LL_16.21#1167, LL_18.16#1177, RL_0.59#1187, RL_2.54#1197, RL_4.49#1207, RL_6.45#1217, RL_8.4#1227, RL_10.35#1237, RL_12.3#1247, RL_14.26#1257, RL_16.21#1267, RL_18.16#1277, LP_0.59#1287, LP_2.54#1297, LP_4.49#1307, LP_6.45#1317, LP_8.4#1327, LP_10.35#1337, LP_12.3#1347, LP_14.26#1357, LP_16.21#1367, LP_18.16#1377, RP_0.59#1387, RP_2.54#1397, RP_4.49#1407, RP_6.45#1417, RP_8.4#1427, RP_10.35#1437, RP_12.3#1447, RP_14.26#1457, RP_16.21#1467, RP_18.16#1477, spectrogram_id#1888]\n",
      "\n",
      "(26) ObjectHashAggregate\n",
      "Input [41]: [spectrogram_id#1888, LL_0__59#2416, LL_2__54#2417, LL_4__49#2418, LL_6__45#2419, LL_8__4#2420, LL_10__35#2421, LL_12__3#2422, LL_14__26#2423, LL_16__21#2424, LL_18__16#2425, RL_0__59#2426, RL_2__54#2427, RL_4__49#2428, RL_6__45#2429, RL_8__4#2430, RL_10__35#2431, RL_12__3#2432, RL_14__26#2433, RL_16__21#2434, RL_18__16#2435, RP_0__59#2436, RP_2__54#2437, RP_4__49#2438, RP_6__45#2439, RP_8__4#2440, RP_10__35#2441, RP_12__3#2442, RP_14__26#2443, RP_16__21#2444, RP_18__16#2445, LP_0__59#2446, LP_2__54#2447, LP_4__49#2448, LP_6__45#2449, LP_8__4#2450, LP_10__35#2451, LP_12__3#2452, LP_14__26#2453, LP_16__21#2454, LP_18__16#2455]\n",
      "Keys [1]: [spectrogram_id#1888]\n",
      "Functions [40]: [partial_collect_list(LL_0__59#2416, 0, 0), partial_collect_list(LL_2__54#2417, 0, 0), partial_collect_list(LL_4__49#2418, 0, 0), partial_collect_list(LL_6__45#2419, 0, 0), partial_collect_list(LL_8__4#2420, 0, 0), partial_collect_list(LL_10__35#2421, 0, 0), partial_collect_list(LL_12__3#2422, 0, 0), partial_collect_list(LL_14__26#2423, 0, 0), partial_collect_list(LL_16__21#2424, 0, 0), partial_collect_list(LL_18__16#2425, 0, 0), partial_collect_list(RL_0__59#2426, 0, 0), partial_collect_list(RL_2__54#2427, 0, 0), partial_collect_list(RL_4__49#2428, 0, 0), partial_collect_list(RL_6__45#2429, 0, 0), partial_collect_list(RL_8__4#2430, 0, 0), partial_collect_list(RL_10__35#2431, 0, 0), partial_collect_list(RL_12__3#2432, 0, 0), partial_collect_list(RL_14__26#2433, 0, 0), partial_collect_list(RL_16__21#2434, 0, 0), partial_collect_list(RL_18__16#2435, 0, 0), partial_collect_list(RP_0__59#2436, 0, 0), partial_collect_list(RP_2__54#2437, 0, 0), partial_collect_list(RP_4__49#2438, 0, 0), partial_collect_list(RP_6__45#2439, 0, 0), partial_collect_list(RP_8__4#2440, 0, 0), partial_collect_list(RP_10__35#2441, 0, 0), partial_collect_list(RP_12__3#2442, 0, 0), partial_collect_list(RP_14__26#2443, 0, 0), partial_collect_list(RP_16__21#2444, 0, 0), partial_collect_list(RP_18__16#2445, 0, 0), partial_collect_list(LP_0__59#2446, 0, 0), partial_collect_list(LP_2__54#2447, 0, 0), partial_collect_list(LP_4__49#2448, 0, 0), partial_collect_list(LP_6__45#2449, 0, 0), partial_collect_list(LP_8__4#2450, 0, 0), partial_collect_list(LP_10__35#2451, 0, 0), partial_collect_list(LP_12__3#2452, 0, 0), partial_collect_list(LP_14__26#2453, 0, 0), partial_collect_list(LP_16__21#2454, 0, 0), partial_collect_list(LP_18__16#2455, 0, 0)]\n",
      "Aggregate Attributes [40]: [buf#5148, buf#5149, buf#5150, buf#5151, buf#5152, buf#5153, buf#5154, buf#5155, buf#5156, buf#5157, buf#5158, buf#5159, buf#5160, buf#5161, buf#5162, buf#5163, buf#5164, buf#5165, buf#5166, buf#5167, buf#5168, buf#5169, buf#5170, buf#5171, buf#5172, buf#5173, buf#5174, buf#5175, buf#5176, buf#5177, buf#5178, buf#5179, buf#5180, buf#5181, buf#5182, buf#5183, buf#5184, buf#5185, buf#5186, buf#5187]\n",
      "Results [41]: [spectrogram_id#1888, buf#5188, buf#5189, buf#5190, buf#5191, buf#5192, buf#5193, buf#5194, buf#5195, buf#5196, buf#5197, buf#5198, buf#5199, buf#5200, buf#5201, buf#5202, buf#5203, buf#5204, buf#5205, buf#5206, buf#5207, buf#5208, buf#5209, buf#5210, buf#5211, buf#5212, buf#5213, buf#5214, buf#5215, buf#5216, buf#5217, buf#5218, buf#5219, buf#5220, buf#5221, buf#5222, buf#5223, buf#5224, buf#5225, buf#5226, buf#5227]\n",
      "\n",
      "(27) Exchange\n",
      "Input [41]: [spectrogram_id#1888, buf#5188, buf#5189, buf#5190, buf#5191, buf#5192, buf#5193, buf#5194, buf#5195, buf#5196, buf#5197, buf#5198, buf#5199, buf#5200, buf#5201, buf#5202, buf#5203, buf#5204, buf#5205, buf#5206, buf#5207, buf#5208, buf#5209, buf#5210, buf#5211, buf#5212, buf#5213, buf#5214, buf#5215, buf#5216, buf#5217, buf#5218, buf#5219, buf#5220, buf#5221, buf#5222, buf#5223, buf#5224, buf#5225, buf#5226, buf#5227]\n",
      "Arguments: hashpartitioning(spectrogram_id#1888, 200), ENSURE_REQUIREMENTS, [plan_id=426]\n",
      "\n",
      "(28) ObjectHashAggregate\n",
      "Input [41]: [spectrogram_id#1888, buf#5188, buf#5189, buf#5190, buf#5191, buf#5192, buf#5193, buf#5194, buf#5195, buf#5196, buf#5197, buf#5198, buf#5199, buf#5200, buf#5201, buf#5202, buf#5203, buf#5204, buf#5205, buf#5206, buf#5207, buf#5208, buf#5209, buf#5210, buf#5211, buf#5212, buf#5213, buf#5214, buf#5215, buf#5216, buf#5217, buf#5218, buf#5219, buf#5220, buf#5221, buf#5222, buf#5223, buf#5224, buf#5225, buf#5226, buf#5227]\n",
      "Keys [1]: [spectrogram_id#1888]\n",
      "Functions [40]: [collect_list(LL_0__59#2416, 0, 0), collect_list(LL_2__54#2417, 0, 0), collect_list(LL_4__49#2418, 0, 0), collect_list(LL_6__45#2419, 0, 0), collect_list(LL_8__4#2420, 0, 0), collect_list(LL_10__35#2421, 0, 0), collect_list(LL_12__3#2422, 0, 0), collect_list(LL_14__26#2423, 0, 0), collect_list(LL_16__21#2424, 0, 0), collect_list(LL_18__16#2425, 0, 0), collect_list(RL_0__59#2426, 0, 0), collect_list(RL_2__54#2427, 0, 0), collect_list(RL_4__49#2428, 0, 0), collect_list(RL_6__45#2429, 0, 0), collect_list(RL_8__4#2430, 0, 0), collect_list(RL_10__35#2431, 0, 0), collect_list(RL_12__3#2432, 0, 0), collect_list(RL_14__26#2433, 0, 0), collect_list(RL_16__21#2434, 0, 0), collect_list(RL_18__16#2435, 0, 0), collect_list(RP_0__59#2436, 0, 0), collect_list(RP_2__54#2437, 0, 0), collect_list(RP_4__49#2438, 0, 0), collect_list(RP_6__45#2439, 0, 0), collect_list(RP_8__4#2440, 0, 0), collect_list(RP_10__35#2441, 0, 0), collect_list(RP_12__3#2442, 0, 0), collect_list(RP_14__26#2443, 0, 0), collect_list(RP_16__21#2444, 0, 0), collect_list(RP_18__16#2445, 0, 0), collect_list(LP_0__59#2446, 0, 0), collect_list(LP_2__54#2447, 0, 0), collect_list(LP_4__49#2448, 0, 0), collect_list(LP_6__45#2449, 0, 0), collect_list(LP_8__4#2450, 0, 0), collect_list(LP_10__35#2451, 0, 0), collect_list(LP_12__3#2452, 0, 0), collect_list(LP_14__26#2453, 0, 0), collect_list(LP_16__21#2454, 0, 0), collect_list(LP_18__16#2455, 0, 0)]\n",
      "Aggregate Attributes [40]: [collect_list(LL_0__59#2416, 0, 0)#2540, collect_list(LL_2__54#2417, 0, 0)#2542, collect_list(LL_4__49#2418, 0, 0)#2544, collect_list(LL_6__45#2419, 0, 0)#2546, collect_list(LL_8__4#2420, 0, 0)#2548, collect_list(LL_10__35#2421, 0, 0)#2550, collect_list(LL_12__3#2422, 0, 0)#2552, collect_list(LL_14__26#2423, 0, 0)#2554, collect_list(LL_16__21#2424, 0, 0)#2556, collect_list(LL_18__16#2425, 0, 0)#2558, collect_list(RL_0__59#2426, 0, 0)#2560, collect_list(RL_2__54#2427, 0, 0)#2562, collect_list(RL_4__49#2428, 0, 0)#2564, collect_list(RL_6__45#2429, 0, 0)#2566, collect_list(RL_8__4#2430, 0, 0)#2568, collect_list(RL_10__35#2431, 0, 0)#2570, collect_list(RL_12__3#2432, 0, 0)#2572, collect_list(RL_14__26#2433, 0, 0)#2574, collect_list(RL_16__21#2434, 0, 0)#2576, collect_list(RL_18__16#2435, 0, 0)#2578, collect_list(RP_0__59#2436, 0, 0)#2580, collect_list(RP_2__54#2437, 0, 0)#2582, collect_list(RP_4__49#2438, 0, 0)#2584, collect_list(RP_6__45#2439, 0, 0)#2586, collect_list(RP_8__4#2440, 0, 0)#2588, collect_list(RP_10__35#2441, 0, 0)#2590, collect_list(RP_12__3#2442, 0, 0)#2592, collect_list(RP_14__26#2443, 0, 0)#2594, collect_list(RP_16__21#2444, 0, 0)#2596, collect_list(RP_18__16#2445, 0, 0)#2598, collect_list(LP_0__59#2446, 0, 0)#2600, collect_list(LP_2__54#2447, 0, 0)#2602, collect_list(LP_4__49#2448, 0, 0)#2604, collect_list(LP_6__45#2449, 0, 0)#2606, collect_list(LP_8__4#2450, 0, 0)#2608, collect_list(LP_10__35#2451, 0, 0)#2610, collect_list(LP_12__3#2452, 0, 0)#2612, collect_list(LP_14__26#2453, 0, 0)#2614, collect_list(LP_16__21#2454, 0, 0)#2616, collect_list(LP_18__16#2455, 0, 0)#2618]\n",
      "Results [41]: [spectrogram_id#1888, collect_list(LL_0__59#2416, 0, 0)#2540 AS LL_0__59#2541, collect_list(LL_2__54#2417, 0, 0)#2542 AS LL_2__54#2543, collect_list(LL_4__49#2418, 0, 0)#2544 AS LL_4__49#2545, collect_list(LL_6__45#2419, 0, 0)#2546 AS LL_6__45#2547, collect_list(LL_8__4#2420, 0, 0)#2548 AS LL_8__4#2549, collect_list(LL_10__35#2421, 0, 0)#2550 AS LL_10__35#2551, collect_list(LL_12__3#2422, 0, 0)#2552 AS LL_12__3#2553, collect_list(LL_14__26#2423, 0, 0)#2554 AS LL_14__26#2555, collect_list(LL_16__21#2424, 0, 0)#2556 AS LL_16__21#2557, collect_list(LL_18__16#2425, 0, 0)#2558 AS LL_18__16#2559, collect_list(RL_0__59#2426, 0, 0)#2560 AS RL_0__59#2561, collect_list(RL_2__54#2427, 0, 0)#2562 AS RL_2__54#2563, collect_list(RL_4__49#2428, 0, 0)#2564 AS RL_4__49#2565, collect_list(RL_6__45#2429, 0, 0)#2566 AS RL_6__45#2567, collect_list(RL_8__4#2430, 0, 0)#2568 AS RL_8__4#2569, collect_list(RL_10__35#2431, 0, 0)#2570 AS RL_10__35#2571, collect_list(RL_12__3#2432, 0, 0)#2572 AS RL_12__3#2573, collect_list(RL_14__26#2433, 0, 0)#2574 AS RL_14__26#2575, collect_list(RL_16__21#2434, 0, 0)#2576 AS RL_16__21#2577, collect_list(RL_18__16#2435, 0, 0)#2578 AS RL_18__16#2579, collect_list(RP_0__59#2436, 0, 0)#2580 AS RP_0__59#2581, collect_list(RP_2__54#2437, 0, 0)#2582 AS RP_2__54#2583, collect_list(RP_4__49#2438, 0, 0)#2584 AS RP_4__49#2585, collect_list(RP_6__45#2439, 0, 0)#2586 AS RP_6__45#2587, collect_list(RP_8__4#2440, 0, 0)#2588 AS RP_8__4#2589, collect_list(RP_10__35#2441, 0, 0)#2590 AS RP_10__35#2591, collect_list(RP_12__3#2442, 0, 0)#2592 AS RP_12__3#2593, collect_list(RP_14__26#2443, 0, 0)#2594 AS RP_14__26#2595, collect_list(RP_16__21#2444, 0, 0)#2596 AS RP_16__21#2597, collect_list(RP_18__16#2445, 0, 0)#2598 AS RP_18__16#2599, collect_list(LP_0__59#2446, 0, 0)#2600 AS LP_0__59#2601, collect_list(LP_2__54#2447, 0, 0)#2602 AS LP_2__54#2603, collect_list(LP_4__49#2448, 0, 0)#2604 AS LP_4__49#2605, collect_list(LP_6__45#2449, 0, 0)#2606 AS LP_6__45#2607, collect_list(LP_8__4#2450, 0, 0)#2608 AS LP_8__4#2609, collect_list(LP_10__35#2451, 0, 0)#2610 AS LP_10__35#2611, collect_list(LP_12__3#2452, 0, 0)#2612 AS LP_12__3#2613, collect_list(LP_14__26#2453, 0, 0)#2614 AS LP_14__26#2615, collect_list(LP_16__21#2454, 0, 0)#2616 AS LP_16__21#2617, collect_list(LP_18__16#2455, 0, 0)#2618 AS LP_18__16#2619]\n",
      "\n",
      "(29) Exchange\n",
      "Input [41]: [spectrogram_id#1888, LL_0__59#2541, LL_2__54#2543, LL_4__49#2545, LL_6__45#2547, LL_8__4#2549, LL_10__35#2551, LL_12__3#2553, LL_14__26#2555, LL_16__21#2557, LL_18__16#2559, RL_0__59#2561, RL_2__54#2563, RL_4__49#2565, RL_6__45#2567, RL_8__4#2569, RL_10__35#2571, RL_12__3#2573, RL_14__26#2575, RL_16__21#2577, RL_18__16#2579, RP_0__59#2581, RP_2__54#2583, RP_4__49#2585, RP_6__45#2587, RP_8__4#2589, RP_10__35#2591, RP_12__3#2593, RP_14__26#2595, RP_16__21#2597, RP_18__16#2599, LP_0__59#2601, LP_2__54#2603, LP_4__49#2605, LP_6__45#2607, LP_8__4#2609, LP_10__35#2611, LP_12__3#2613, LP_14__26#2615, LP_16__21#2617, LP_18__16#2619]\n",
      "Arguments: hashpartitioning(cast(spectrogram_id#1888 as int), 200), ENSURE_REQUIREMENTS, [plan_id=431]\n",
      "\n",
      "(30) Sort\n",
      "Input [41]: [spectrogram_id#1888, LL_0__59#2541, LL_2__54#2543, LL_4__49#2545, LL_6__45#2547, LL_8__4#2549, LL_10__35#2551, LL_12__3#2553, LL_14__26#2555, LL_16__21#2557, LL_18__16#2559, RL_0__59#2561, RL_2__54#2563, RL_4__49#2565, RL_6__45#2567, RL_8__4#2569, RL_10__35#2571, RL_12__3#2573, RL_14__26#2575, RL_16__21#2577, RL_18__16#2579, RP_0__59#2581, RP_2__54#2583, RP_4__49#2585, RP_6__45#2587, RP_8__4#2589, RP_10__35#2591, RP_12__3#2593, RP_14__26#2595, RP_16__21#2597, RP_18__16#2599, LP_0__59#2601, LP_2__54#2603, LP_4__49#2605, LP_6__45#2607, LP_8__4#2609, LP_10__35#2611, LP_12__3#2613, LP_14__26#2615, LP_16__21#2617, LP_18__16#2619]\n",
      "Arguments: [cast(spectrogram_id#1888 as int) ASC NULLS FIRST], false, 0\n",
      "\n",
      "(31) SortMergeJoin\n",
      "Left keys [1]: [spectrogram_id#3]\n",
      "Right keys [1]: [cast(spectrogram_id#1888 as int)]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(32) Project\n",
      "Output [82]: [eeg_id#0L, eeg_sub_id#1, eeg_label_offset_seconds#31, spectrogram_id#3, spectrogram_sub_id#4, spectrogram_label_offset_seconds#47, label_id#6L, patient_id#7, expert_consensus#8, seizure_vote#9, lpd_vote#10, gpd_vote#11, lrda_vote#12, grda_vote#13, other_vote#14, label#63, seizure_vote_actual#80, lpd_vote_actual#81, gpd_vote_actual#82, lrda_vote_actual#83, grda_vote_actual#84, other_vote_actual#85, Fp1#571, F3#572, C3#573, P3#574, F7#575, T3#576, T5#577, O1#578, Fz#579, Cz#580, Pz#581, Fp2#582, F4#583, C4#584, P4#585, F8#586, T4#587, T6#588, O2#589, EKG#590, LL_0__59#2541, LL_2__54#2543, LL_4__49#2545, LL_6__45#2547, LL_8__4#2549, LL_10__35#2551, LL_12__3#2553, LL_14__26#2555, LL_16__21#2557, LL_18__16#2559, RL_0__59#2561, RL_2__54#2563, RL_4__49#2565, RL_6__45#2567, RL_8__4#2569, RL_10__35#2571, RL_12__3#2573, RL_14__26#2575, RL_16__21#2577, RL_18__16#2579, RP_0__59#2581, RP_2__54#2583, RP_4__49#2585, RP_6__45#2587, RP_8__4#2589, RP_10__35#2591, RP_12__3#2593, RP_14__26#2595, RP_16__21#2597, RP_18__16#2599, LP_0__59#2601, LP_2__54#2603, LP_4__49#2605, LP_6__45#2607, LP_8__4#2609, LP_10__35#2611, LP_12__3#2613, LP_14__26#2615, LP_16__21#2617, LP_18__16#2619]\n",
      "Input [83]: [eeg_id#0L, eeg_sub_id#1, eeg_label_offset_seconds#31, spectrogram_id#3, spectrogram_sub_id#4, spectrogram_label_offset_seconds#47, label_id#6L, patient_id#7, expert_consensus#8, seizure_vote#9, lpd_vote#10, gpd_vote#11, lrda_vote#12, grda_vote#13, other_vote#14, label#63, seizure_vote_actual#80, lpd_vote_actual#81, gpd_vote_actual#82, lrda_vote_actual#83, grda_vote_actual#84, other_vote_actual#85, Fp1#571, F3#572, C3#573, P3#574, F7#575, T3#576, T5#577, O1#578, Fz#579, Cz#580, Pz#581, Fp2#582, F4#583, C4#584, P4#585, F8#586, T4#587, T6#588, O2#589, EKG#590, spectrogram_id#1888, LL_0__59#2541, LL_2__54#2543, LL_4__49#2545, LL_6__45#2547, LL_8__4#2549, LL_10__35#2551, LL_12__3#2553, LL_14__26#2555, LL_16__21#2557, LL_18__16#2559, RL_0__59#2561, RL_2__54#2563, RL_4__49#2565, RL_6__45#2567, RL_8__4#2569, RL_10__35#2571, RL_12__3#2573, RL_14__26#2575, RL_16__21#2577, RL_18__16#2579, RP_0__59#2581, RP_2__54#2583, RP_4__49#2585, RP_6__45#2587, RP_8__4#2589, RP_10__35#2591, RP_12__3#2593, RP_14__26#2595, RP_16__21#2597, RP_18__16#2599, LP_0__59#2601, LP_2__54#2603, LP_4__49#2605, LP_6__45#2607, LP_8__4#2609, LP_10__35#2611, LP_12__3#2613, LP_14__26#2615, LP_16__21#2617, LP_18__16#2619]\n",
      "\n",
      "(33) BatchEvalPython\n",
      "Input [82]: [eeg_id#0L, eeg_sub_id#1, eeg_label_offset_seconds#31, spectrogram_id#3, spectrogram_sub_id#4, spectrogram_label_offset_seconds#47, label_id#6L, patient_id#7, expert_consensus#8, seizure_vote#9, lpd_vote#10, gpd_vote#11, lrda_vote#12, grda_vote#13, other_vote#14, label#63, seizure_vote_actual#80, lpd_vote_actual#81, gpd_vote_actual#82, lrda_vote_actual#83, grda_vote_actual#84, other_vote_actual#85, Fp1#571, F3#572, C3#573, P3#574, F7#575, T3#576, T5#577, O1#578, Fz#579, Cz#580, Pz#581, Fp2#582, F4#583, C4#584, P4#585, F8#586, T4#587, T6#588, O2#589, EKG#590, LL_0__59#2541, LL_2__54#2543, LL_4__49#2545, LL_6__45#2547, LL_8__4#2549, LL_10__35#2551, LL_12__3#2553, LL_14__26#2555, LL_16__21#2557, LL_18__16#2559, RL_0__59#2561, RL_2__54#2563, RL_4__49#2565, RL_6__45#2567, RL_8__4#2569, RL_10__35#2571, RL_12__3#2573, RL_14__26#2575, RL_16__21#2577, RL_18__16#2579, RP_0__59#2581, RP_2__54#2583, RP_4__49#2585, RP_6__45#2587, RP_8__4#2589, RP_10__35#2591, RP_12__3#2593, RP_14__26#2595, RP_16__21#2597, RP_18__16#2599, LP_0__59#2601, LP_2__54#2603, LP_4__49#2605, LP_6__45#2607, LP_8__4#2609, LP_10__35#2611, LP_12__3#2613, LP_14__26#2615, LP_16__21#2617, LP_18__16#2619]\n",
      "Arguments: [<lambda>(stats_summary_udf(slice(LL_0__59#2541, (spectrogram_label_offset_seconds#47 + 1), 600))#2865)#2866, <lambda>(stats_summary_udf(slice(LL_2__54#2543, (spectrogram_label_offset_seconds#47 + 1), 600))#2867)#2868, <lambda>(stats_summary_udf(slice(LL_4__49#2545, (spectrogram_label_offset_seconds#47 + 1), 600))#2869)#2870, <lambda>(stats_summary_udf(slice(LL_6__45#2547, (spectrogram_label_offset_seconds#47 + 1), 600))#2871)#2872, <lambda>(stats_summary_udf(slice(LL_8__4#2549, (spectrogram_label_offset_seconds#47 + 1), 600))#2873)#2874, <lambda>(stats_summary_udf(slice(LL_10__35#2551, (spectrogram_label_offset_seconds#47 + 1), 600))#2875)#2876, <lambda>(stats_summary_udf(slice(LL_12__3#2553, (spectrogram_label_offset_seconds#47 + 1), 600))#2877)#2878, <lambda>(stats_summary_udf(slice(LL_14__26#2555, (spectrogram_label_offset_seconds#47 + 1), 600))#2879)#2880, <lambda>(stats_summary_udf(slice(LL_16__21#2557, (spectrogram_label_offset_seconds#47 + 1), 600))#2881)#2882, <lambda>(stats_summary_udf(slice(LL_18__16#2559, (spectrogram_label_offset_seconds#47 + 1), 600))#2883)#2884, <lambda>(stats_summary_udf(slice(RL_0__59#2561, (spectrogram_label_offset_seconds#47 + 1), 600))#2885)#2886, <lambda>(stats_summary_udf(slice(RL_2__54#2563, (spectrogram_label_offset_seconds#47 + 1), 600))#2887)#2888, <lambda>(stats_summary_udf(slice(RL_4__49#2565, (spectrogram_label_offset_seconds#47 + 1), 600))#2889)#2890, <lambda>(stats_summary_udf(slice(RL_6__45#2567, (spectrogram_label_offset_seconds#47 + 1), 600))#2891)#2892, <lambda>(stats_summary_udf(slice(RL_8__4#2569, (spectrogram_label_offset_seconds#47 + 1), 600))#2893)#2894, <lambda>(stats_summary_udf(slice(RL_10__35#2571, (spectrogram_label_offset_seconds#47 + 1), 600))#2895)#2896, <lambda>(stats_summary_udf(slice(RL_12__3#2573, (spectrogram_label_offset_seconds#47 + 1), 600))#2897)#2898, <lambda>(stats_summary_udf(slice(RL_14__26#2575, (spectrogram_label_offset_seconds#47 + 1), 600))#2899)#2900, <lambda>(stats_summary_udf(slice(RL_16__21#2577, (spectrogram_label_offset_seconds#47 + 1), 600))#2901)#2902, <lambda>(stats_summary_udf(slice(RL_18__16#2579, (spectrogram_label_offset_seconds#47 + 1), 600))#2903)#2904, <lambda>(stats_summary_udf(slice(RP_0__59#2581, (spectrogram_label_offset_seconds#47 + 1), 600))#2905)#2906, <lambda>(stats_summary_udf(slice(RP_2__54#2583, (spectrogram_label_offset_seconds#47 + 1), 600))#2907)#2908, <lambda>(stats_summary_udf(slice(RP_4__49#2585, (spectrogram_label_offset_seconds#47 + 1), 600))#2909)#2910, <lambda>(stats_summary_udf(slice(RP_6__45#2587, (spectrogram_label_offset_seconds#47 + 1), 600))#2911)#2912, ... 16 more fields], [pythonUDF0#5068, pythonUDF1#5069, pythonUDF2#5070, pythonUDF3#5071, pythonUDF4#5072, pythonUDF5#5073, pythonUDF6#5074, pythonUDF7#5075, pythonUDF8#5076, pythonUDF9#5077, pythonUDF10#5078, pythonUDF11#5079, pythonUDF12#5080, pythonUDF13#5081, pythonUDF14#5082, pythonUDF15#5083, pythonUDF16#5084, pythonUDF17#5085, pythonUDF18#5086, pythonUDF19#5087, pythonUDF20#5088, pythonUDF21#5089, pythonUDF22#5090, pythonUDF23#5091, ... 16 more fields]\n",
      "\n",
      "(34) Project\n",
      "Output [82]: [spectrogram_id#3, eeg_id#0L, eeg_sub_id#1, eeg_label_offset_seconds#31, spectrogram_sub_id#4, spectrogram_label_offset_seconds#47, label_id#6L, patient_id#7, expert_consensus#8, seizure_vote#9, lpd_vote#10, gpd_vote#11, lrda_vote#12, grda_vote#13, other_vote#14, label#63, seizure_vote_actual#80, lpd_vote_actual#81, gpd_vote_actual#82, lrda_vote_actual#83, grda_vote_actual#84, other_vote_actual#85, Fp1#571, F3#572, C3#573, P3#574, F7#575, T3#576, T5#577, O1#578, Fz#579, Cz#580, Pz#581, Fp2#582, F4#583, C4#584, P4#585, F8#586, T4#587, T6#588, O2#589, EKG#590, pythonUDF0#5068 AS LL_0__59#2945, pythonUDF1#5069 AS LL_2__54#2946, pythonUDF2#5070 AS LL_4__49#2947, pythonUDF3#5071 AS LL_6__45#2948, pythonUDF4#5072 AS LL_8__4#2949, pythonUDF5#5073 AS LL_10__35#2950, pythonUDF6#5074 AS LL_12__3#2951, pythonUDF7#5075 AS LL_14__26#2952, pythonUDF8#5076 AS LL_16__21#2953, pythonUDF9#5077 AS LL_18__16#2954, pythonUDF10#5078 AS RL_0__59#2955, pythonUDF11#5079 AS RL_2__54#2956, pythonUDF12#5080 AS RL_4__49#2957, pythonUDF13#5081 AS RL_6__45#2958, pythonUDF14#5082 AS RL_8__4#2959, pythonUDF15#5083 AS RL_10__35#2960, pythonUDF16#5084 AS RL_12__3#2961, pythonUDF17#5085 AS RL_14__26#2962, pythonUDF18#5086 AS RL_16__21#2963, pythonUDF19#5087 AS RL_18__16#2964, pythonUDF20#5088 AS RP_0__59#2965, pythonUDF21#5089 AS RP_2__54#2966, pythonUDF22#5090 AS RP_4__49#2967, pythonUDF23#5091 AS RP_6__45#2968, pythonUDF24#5092 AS RP_8__4#2969, pythonUDF25#5093 AS RP_10__35#2970, pythonUDF26#5094 AS RP_12__3#2971, pythonUDF27#5095 AS RP_14__26#2972, pythonUDF28#5096 AS RP_16__21#2973, pythonUDF29#5097 AS RP_18__16#2974, pythonUDF30#5098 AS LP_0__59#2975, pythonUDF31#5099 AS LP_2__54#2976, pythonUDF32#5100 AS LP_4__49#2977, pythonUDF33#5101 AS LP_6__45#2978, pythonUDF34#5102 AS LP_8__4#2979, pythonUDF35#5103 AS LP_10__35#2980, pythonUDF36#5104 AS LP_12__3#2981, pythonUDF37#5105 AS LP_14__26#2982, pythonUDF38#5106 AS LP_16__21#2983, pythonUDF39#5107 AS LP_18__16#2984]\n",
      "Input [122]: [eeg_id#0L, eeg_sub_id#1, eeg_label_offset_seconds#31, spectrogram_id#3, spectrogram_sub_id#4, spectrogram_label_offset_seconds#47, label_id#6L, patient_id#7, expert_consensus#8, seizure_vote#9, lpd_vote#10, gpd_vote#11, lrda_vote#12, grda_vote#13, other_vote#14, label#63, seizure_vote_actual#80, lpd_vote_actual#81, gpd_vote_actual#82, lrda_vote_actual#83, grda_vote_actual#84, other_vote_actual#85, Fp1#571, F3#572, C3#573, P3#574, F7#575, T3#576, T5#577, O1#578, Fz#579, Cz#580, Pz#581, Fp2#582, F4#583, C4#584, P4#585, F8#586, T4#587, T6#588, O2#589, EKG#590, LL_0__59#2541, LL_2__54#2543, LL_4__49#2545, LL_6__45#2547, LL_8__4#2549, LL_10__35#2551, LL_12__3#2553, LL_14__26#2555, LL_16__21#2557, LL_18__16#2559, RL_0__59#2561, RL_2__54#2563, RL_4__49#2565, RL_6__45#2567, RL_8__4#2569, RL_10__35#2571, RL_12__3#2573, RL_14__26#2575, RL_16__21#2577, RL_18__16#2579, RP_0__59#2581, RP_2__54#2583, RP_4__49#2585, RP_6__45#2587, RP_8__4#2589, RP_10__35#2591, RP_12__3#2593, RP_14__26#2595, RP_16__21#2597, RP_18__16#2599, LP_0__59#2601, LP_2__54#2603, LP_4__49#2605, LP_6__45#2607, LP_8__4#2609, LP_10__35#2611, LP_12__3#2613, LP_14__26#2615, LP_16__21#2617, LP_18__16#2619, pythonUDF0#5068, pythonUDF1#5069, pythonUDF2#5070, pythonUDF3#5071, pythonUDF4#5072, pythonUDF5#5073, pythonUDF6#5074, pythonUDF7#5075, pythonUDF8#5076, pythonUDF9#5077, pythonUDF10#5078, pythonUDF11#5079, pythonUDF12#5080, pythonUDF13#5081, pythonUDF14#5082, pythonUDF15#5083, pythonUDF16#5084, pythonUDF17#5085, pythonUDF18#5086, pythonUDF19#5087, pythonUDF20#5088, pythonUDF21#5089, pythonUDF22#5090, pythonUDF23#5091, pythonUDF24#5092, pythonUDF25#5093, pythonUDF26#5094, pythonUDF27#5095, pythonUDF28#5096, pythonUDF29#5097, pythonUDF30#5098, pythonUDF31#5099, pythonUDF32#5100, pythonUDF33#5101, pythonUDF34#5102, pythonUDF35#5103, pythonUDF36#5104, pythonUDF37#5105, pythonUDF38#5106, pythonUDF39#5107]\n",
      "\n",
      "(35) AdaptiveSparkPlan\n",
      "Output [82]: [spectrogram_id#3, eeg_id#0L, eeg_sub_id#1, eeg_label_offset_seconds#31, spectrogram_sub_id#4, spectrogram_label_offset_seconds#47, label_id#6L, patient_id#7, expert_consensus#8, seizure_vote#9, lpd_vote#10, gpd_vote#11, lrda_vote#12, grda_vote#13, other_vote#14, label#63, seizure_vote_actual#80, lpd_vote_actual#81, gpd_vote_actual#82, lrda_vote_actual#83, grda_vote_actual#84, other_vote_actual#85, Fp1#571, F3#572, C3#573, P3#574, F7#575, T3#576, T5#577, O1#578, Fz#579, Cz#580, Pz#581, Fp2#582, F4#583, C4#584, P4#585, F8#586, T4#587, T6#588, O2#589, EKG#590, LL_0__59#2945, LL_2__54#2946, LL_4__49#2947, LL_6__45#2948, LL_8__4#2949, LL_10__35#2950, LL_12__3#2951, LL_14__26#2952, LL_16__21#2953, LL_18__16#2954, RL_0__59#2955, RL_2__54#2956, RL_4__49#2957, RL_6__45#2958, RL_8__4#2959, RL_10__35#2960, RL_12__3#2961, RL_14__26#2962, RL_16__21#2963, RL_18__16#2964, RP_0__59#2965, RP_2__54#2966, RP_4__49#2967, RP_6__45#2968, RP_8__4#2969, RP_10__35#2970, RP_12__3#2971, RP_14__26#2972, RP_16__21#2973, RP_18__16#2974, LP_0__59#2975, LP_2__54#2976, LP_4__49#2977, LP_6__45#2978, LP_8__4#2979, LP_10__35#2980, LP_12__3#2981, LP_14__26#2982, LP_16__21#2983, LP_18__16#2984]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/28 09:37:26 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "df_train_spectrograms.explain(\"formatted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6216a147",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b993a68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, StandardScaler\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.types import ArrayType, DoubleType\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ee7947",
   "metadata": {},
   "source": [
    "### Model the brain problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3329346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------                         (13 + 23) / 36]\n",
      "Exception occurred during processing of request from ('127.0.0.1', 55330)\n",
      "Traceback (most recent call last):\n",
      "  File \"/sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/sw/pkgs/arc/python3.10-anaconda/2023.03/lib/python3.10/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/sohamdas/.local/lib/python3.10/site-packages/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/sohamdas/.local/lib/python3.10/site-packages/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "  File \"/home/sohamdas/.local/lib/python3.10/site-packages/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/sohamdas/.local/lib/python3.10/site-packages/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sohamdas/.local/lib/python3.10/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sohamdas/.local/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/sohamdas/.local/lib/python3.10/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sohamdas/.local/lib/python3.10/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sohamdas/.local/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/sohamdas/.local/lib/python3.10/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o1969.fit",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 50\u001b[0m\n\u001b[1;32m     35\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline(\n\u001b[1;32m     36\u001b[0m     stages\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     37\u001b[0m         label_indexer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m     ]\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Fit the pipeline to the DataFrame\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train_spectrograms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/ml/base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[1;32m    210\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/ml/pipeline.py:134\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    132\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m stage\u001b[38;5;241m.\u001b[39mtransform(dataset)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# must be an Estimator\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mstage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m     transformers\u001b[38;5;241m.\u001b[39mappend(model)\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m indexOfLastEstimator:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/ml/base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[1;32m    210\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/ml/wrapper.py:381\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: DataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JM:\n\u001b[0;32m--> 381\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copyValues(model)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/ml/wrapper.py:378\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/protocol.py:334\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m                 \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    336\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name))\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m answer[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o1969.fit"
     ]
    }
   ],
   "source": [
    "# Convert string labels to numeric using StringIndexer\n",
    "label_indexer = StringIndexer(inputCol=\"label\", outputCol=\"indexed_label\")\n",
    "\n",
    "inputCols = eeg_columns_data + spectrogram_columns_data_dot\n",
    "# VectorAssembler for the discrete value and vectorized arrays\n",
    "vector_assembler = VectorAssembler(\n",
    "    inputCols=inputCols,\n",
    "    outputCol=\"feature_vector\",\n",
    ")\n",
    "\n",
    "# Normalize features using StandardScaler\n",
    "standard_scaler = StandardScaler(\n",
    "    inputCol=\"feature_vector\",\n",
    "    outputCol=\"normalized_features\",\n",
    "    withMean=True,\n",
    "    withStd=True,\n",
    ")\n",
    "\n",
    "# RandomForestClassifier\n",
    "random_forest_classifier = RandomForestClassifier(\n",
    "    featuresCol=\"feature_vector\",\n",
    "    labelCol=\"indexed_label\",\n",
    "    numTrees=16,#255\n",
    "    maxDepth=8,#30\n",
    "    maxBins=16,#32\n",
    "    bootstrap=True,\n",
    "    minInstancesPerNode=1,\n",
    "    minInfoGain=0.0,\n",
    "    subsamplingRate=1.0,\n",
    "    featureSubsetStrategy=\"auto\",\n",
    "    seed=experiment_params.get(\"seed\", 42),\n",
    ")\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(\n",
    "    stages=[\n",
    "        label_indexer,\n",
    "        # my_custom_transformer,\n",
    "        vector_assembler,\n",
    "        standard_scaler,\n",
    "        # dt_classifier,\n",
    "        # logistic_regression,\n",
    "        # gbt_classifier,\n",
    "        random_forest_classifier,\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Fit the pipeline to the DataFrame\n",
    "model = pipeline.fit(df_train_spectrograms)  # df_train_eegs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3314aef",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac493e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"eval\" in FLAGS:\n",
    "\n",
    "    predictions = model.transform(df_eval_spectrograms)\n",
    "\n",
    "    # Evaluate the model using MulticlassClassificationEvaluator:\n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"indexed_label\", predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    "    )\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8742ea26",
   "metadata": {},
   "source": [
    "## Predict & Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bf1746",
   "metadata": {},
   "source": [
    "### Load Test & EEGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaf6ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = (\n",
    "    spark.read.csv(os.path.join(root, \"test.csv\"), header=True, schema=test_schema)\n",
    "    # cast offest to integer\n",
    "    # .withColumn(\n",
    "    #     \"eeg_label_offset_seconds\",\n",
    "    #     col(\"eeg_label_offset_seconds\").cast(\"integer\"),\n",
    "    # )\n",
    "    # label\n",
    "    # .withColumn(\"label\", col(\"expert_consensus\"))\n",
    "    # percent of votes for each label for model evaluation,necesary on 'eval' flag\n",
    "    # .withColumns(\n",
    "    #     {\n",
    "    #         f\"{column}_actual\": expr(f\"{column} / {sum_of_votes_expr}\")\n",
    "    #         for column in votes_columns\n",
    "    #     },\n",
    "    # )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3de6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eegs_files_paths = get_parquet_files(\n",
    "    df_test.select(col(\"eeg_id\").alias(\"id\")), folder=\"test_eegs\", root=root\n",
    ")\n",
    "test_spectro_files_paths = get_parquet_files(\n",
    "    df_test.select(col(\"spectrogram_id\").alias(\"id\")),\n",
    "    folder=\"test_spectrograms\",\n",
    "    root=root,\n",
    ")\n",
    "\n",
    "df_test_eegs = load_eegs(df_test, test_eegs_files_paths, eeg_schema, eeg_columns_data)\n",
    "df_test_spectrograms = load_spectrograms(\n",
    "    df_test_eegs,\n",
    "    test_spectro_files_paths,\n",
    "    schema=spectrogram_schema,\n",
    "    cols_to_array=spectrogram_columns_data_dot,\n",
    ")\n",
    "print(f\"Test eegs paths: {test_eegs_files_paths[:3]} ... \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3cb9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print(\"sample fraction =\",sample_frac)\n",
    "print((end-start)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b658df",
   "metadata": {},
   "source": [
    "### Predict & Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1ab690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = model.transform(df_test_spectrograms)\n",
    "\n",
    "# Extract individual probability values into separate columns\n",
    "labels = [\n",
    "    x.lower() for x in model.stages[0].labels\n",
    "]  # Get labels from the StringIndexer\n",
    "\n",
    "exprs = [\n",
    "    vector_to_array(\"probability\")[i].alias(f\"{labels[i]}_vote\")\n",
    "    for i in range(len(labels))\n",
    "]\n",
    "\n",
    "# Show the predictions, including probabilities for each class\n",
    "predictions.select(\n",
    "    \"eeg_id\",\n",
    "    *exprs,\n",
    ").toPandas().to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1298e1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
