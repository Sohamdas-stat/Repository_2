{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e48a6383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4d9daaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of train EEG files 17300\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Data Preprocessing\n",
    "project_path = '/Users/sohamdas/Desktop/EECS 545/Project'\n",
    "data_path = project_path + '/data'\n",
    "train_eeg_path = data_path + '/train_eegs'\n",
    "eeg_file_list = os.listdir(train_eeg_path)\n",
    "print('Total no. of train EEG files',len(eeg_file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc0fbf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the whole dataset\n",
    "#record_times = []\n",
    "#for i in range(len(eeg_file_list)):\n",
    "#    filename = eeg_file_list[i]\n",
    "#    df = pd.read_parquet(train_eeg_path + '/' + filename)\n",
    "#    record_times.append(df.shape[0])\n",
    "#print(min(record_times), max(record_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39d4310c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just a subset of 20 samples\n",
    "short_file_list = eeg_file_list[:20]\n",
    "\n",
    "record_times = []\n",
    "for i in range(len(short_file_list)):\n",
    "    filename = short_file_list[i]\n",
    "    df = pd.read_parquet(train_eeg_path + '/' + filename)\n",
    "    record_times.append(df.shape[0])\n",
    "\n",
    "min_time = min(record_times)\n",
    "n_graphs = df.shape[1]\n",
    "n_samples = len(short_file_list)\n",
    "n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb4a9af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 10000, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-processing\n",
    "# making the X_train in a particular shape\n",
    "X_train = np.empty((0, min_time, n_graphs), int)\n",
    "for i in range(n_samples):\n",
    "    filename = short_file_list[i]\n",
    "    df = pd.read_parquet(train_eeg_path + '/' + filename)\n",
    "    df_balanced = df[:min_time].to_numpy()\n",
    "    X_train = np.append(X_train, np.array([df_balanced]), axis=0)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    df_normalized = scaler.fit_transform(df)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f6abfe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>eeg_sub_id</th>\n",
       "      <th>eeg_label_offset_seconds</th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>spectrogram_sub_id</th>\n",
       "      <th>spectrogram_label_offset_seconds</th>\n",
       "      <th>label_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>expert_consensus</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127492639</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3887563113</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1142670488</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2718991173</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3080632009</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eeg_id  eeg_sub_id  eeg_label_offset_seconds  spectrogram_id  \\\n",
       "0  1628180742           0                       0.0          353733   \n",
       "1  1628180742           1                       6.0          353733   \n",
       "2  1628180742           2                       8.0          353733   \n",
       "3  1628180742           3                      18.0          353733   \n",
       "4  1628180742           4                      24.0          353733   \n",
       "\n",
       "   spectrogram_sub_id  spectrogram_label_offset_seconds    label_id  \\\n",
       "0                   0                               0.0   127492639   \n",
       "1                   1                               6.0  3887563113   \n",
       "2                   2                               8.0  1142670488   \n",
       "3                   3                              18.0  2718991173   \n",
       "4                   4                              24.0  3080632009   \n",
       "\n",
       "   patient_id expert_consensus  seizure_vote  lpd_vote  gpd_vote  lrda_vote  \\\n",
       "0       42516          Seizure             3         0         0          0   \n",
       "1       42516          Seizure             3         0         0          0   \n",
       "2       42516          Seizure             3         0         0          0   \n",
       "3       42516          Seizure             3         0         0          0   \n",
       "4       42516          Seizure             3         0         0          0   \n",
       "\n",
       "   grda_vote  other_vote  \n",
       "0          0           0  \n",
       "1          0           0  \n",
       "2          0           0  \n",
       "3          0           0  \n",
       "4          0           0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-processing\n",
    "# making the Y_train in a particular shape\n",
    "train_data = pd.read_csv(data_path + '/' + 'train.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae92a40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17089\n",
      "17300\n"
     ]
    }
   ],
   "source": [
    "unique_eeg_id = np.unique(train_data['eeg_id'])\n",
    "common_eeg_id = []\n",
    "for i in range(len(unique_eeg_id)):\n",
    "    ID = unique_eeg_id[i]\n",
    "    if str(ID) + '.parquet' in eeg_file_list:\n",
    "        common_eeg_id.append(i)\n",
    "print(len(common_eeg_id))\n",
    "print(len(eeg_file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b09a393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_eeg_id = np.unique(train_data['eeg_id'])\n",
    "var_of_interest = ['eeg_id','seizure_vote,''lpd_vote','gpd_vote','lrda_vote','grda_vote','other_vote']\n",
    "vote_vector = ['seizure_vote','lpd_vote','gpd_vote','lrda_vote','grda_vote','other_vote']\n",
    "n_disease = len(vote_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f54f04d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.empty((0, n_disease), int)\n",
    "n_samples = 20  #len(unique_eeg_id)\n",
    "for i in range(n_samples):\n",
    "    ID = unique_eeg_id[i]\n",
    "    if str(ID) + '.parquet' in eeg_file_list:\n",
    "        row_loc = train_data.index[train_data['eeg_id'] == ID][0]\n",
    "        vote_count = train_data.loc[row_loc,vote_vector]\n",
    "        if np.sum(np.isnan(vote_count.astype(float)), axis=0) > 0:\n",
    "            raise ValueError(\"NaN value encountered\")\n",
    "        vote_share = vote_count / sum(vote_count)\n",
    "        Y_train = np.append(Y_train, np.array([vote_share]),axis=0)\n",
    "#print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f838c7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "NaN value encountered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     df_balanced \u001b[38;5;241m=\u001b[39m df[:min_time]\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39misnan(df_balanced\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)), axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:    \n\u001b[0;32m----> 7\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN value encountered\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m X_reshaped \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Initialize and apply MinMaxScaler for reshaped dataset\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: NaN value encountered"
     ]
    }
   ],
   "source": [
    "X = np.empty((0, min_time, n_graphs), float)\n",
    "for i in range(n_samples):\n",
    "    filename = str(unique_eeg_id[i]) + '.parquet'\n",
    "    df = pd.read_parquet(train_eeg_path + '/' + filename)\n",
    "    df_balanced = df[:min_time].to_numpy()\n",
    "    if np.sum(np.isnan(df_balanced.astype(float)), axis=(0,1)) > 0:    \n",
    "        raise ValueError(\"NaN value encountered\")\n",
    "X_reshaped = X.reshape(-1, df.shape[-1])\n",
    "\n",
    "# Initialize and apply MinMaxScaler for reshaped dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_scaled = scaler.fit_transform(X_reshaped)\n",
    "\n",
    "# Reshape back to 3D (n_samples, n_time_steps, n_features)\n",
    "X_scaled_3d = X_scaled.reshape(X.shape)\n",
    "X = X_scaled_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6987b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "X = X.astype('float32')\n",
    "Y = Y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2bfee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00e8c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a14b570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Building the LSTM Model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ef42fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Training the Model\n",
    "model.fit(X_train, y_train, epochs=2, validation_split=0.2)\n",
    "\n",
    "# Step 4: Making Predictions\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973ed39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d0b0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0a4004",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model.predict(X_train))\n",
    "#print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb94fe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_data = []\n",
    "target_votes = [] # Assuming this is how you store expert votes\n",
    "target_probabilities = []\n",
    "\n",
    "# Function to load data and convert votes to probabilities\n",
    "def load_data_and_votes(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    # Assuming the DataFrame df has columns 'EEG_data' for EEG signals and 'Disease1', ... 'Disease6' for votes\n",
    "    \n",
    "    # Preprocess EEG data here (e.g., normalization, truncation/padding)\n",
    "    # Placeholder for actual EEG data preprocessing\n",
    "    \n",
    "    # Convert votes to probabilities\n",
    "    vote_columns = ['Disease1', 'Disease2', 'Disease3', 'Disease4', 'Disease5', 'Disease6']\n",
    "    votes = df[vote_columns].sum(axis=0)  # Sum votes for each disease\n",
    "    total_votes = votes.sum()  # Total votes across all diseases\n",
    "    probabilities = votes / total_votes  # Convert to probabilities\n",
    "    \n",
    "    return processed_eeg_data, probabilities  # Placeholder for actual EEG data and probabilities\n",
    "\n",
    "# Assuming a file path\n",
    "file_path = '/path/to/your/data_eeg/patient_file.parquet'\n",
    "processed_eeg_data, target_probabilities = load_data_and_votes(file_path)\n",
    "\n",
    "# Continue with data splitting, model definition, training, and prediction as described earlier\n",
    "\n",
    "for file in file_list:\n",
    "    # Load data\n",
    "    df = pd.read_parquet(os.path.join(data_folder, file))\n",
    "    # Preprocess (truncate/pad, normalize)\n",
    "    # Assuming df has columns for data and maybe a separate file or column for votes\n",
    "    # Normalize data\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(df.values) # Assuming df.values is the EEG data\n",
    "    all_data.append(scaled_data)\n",
    "    # Load votes and convert to probabilities\n",
    "    # This part needs more information about how votes are stored\n",
    "\n",
    "# Uniform time series length\n",
    "# This is a placeholder function to make all data sequences have the same length\n",
    "def uniform_length(data, sequence_length=1000):\n",
    "    return np.array([np.pad(d, (0, max(0, sequence_length - len(d))), 'constant', constant_values=0)[:sequence_length] for d in data])\n",
    "\n",
    "all_data_uniform = uniform_length(all_data)\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_uniform, target_votes, test_size=0.2)\n",
    "\n",
    "# Step 2: Building the LSTM Model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 3: Training the Model\n",
    "model.fit(X_train, y_train, epochs=10, validation_split=0.1)\n",
    "\n",
    "# Step 4: Making Predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Further developments are discussed in the text above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d252b7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.empty((0, min_time, n_graphs), float)\n",
    "for i in range(n_samples):\n",
    "    filename = str(unique_eeg_id[i]) + '.parquet'\n",
    "    df = pd.read_parquet(train_eeg_path + '/' + filename)\n",
    "    df_balanced = df[:min_time].to_numpy()\n",
    "    if np.sum(np.isnan(df_balanced.astype(float)), axis=(0,1)) > 0:    \n",
    "        raise ValueError(\"NaN value encountered\")\n",
    "    X_train = np.append(X_train, np.array([df_balanced]), axis=0)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    df_normalized = scaler.fit_transform(df)\n",
    "np.sum(np.isnan(X_train),axis=(1,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
