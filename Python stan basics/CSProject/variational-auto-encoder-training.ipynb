{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "428c75ff",
   "metadata": {
    "papermill": {
     "duration": 0.009308,
     "end_time": "2024-03-13T22:24:47.628275",
     "exception": false,
     "start_time": "2024-03-13T22:24:47.618967",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Features+Head Ensemble Starter [LB 0.34] for HMS Brain Comp\n",
    "This is Features+Head is a combination and ensemble Starter notebook for Kaggle's HMS brain comp. We can train 4 different models using:\n",
    "- Kaggle's spectrograms (CV 0.6123 – LB 0.41)\n",
    "- Chris's EEG spectrograms(modified version) (CV 0.6288 – LB 0.39)\n",
    "- Both Kaggle and EEG spectrograms (CV 0.5768 – LB 0.37)\n",
    "- Chris's [WaveNet][4] (CV 0.6992 - LB 0.41)\n",
    "\n",
    "**The Ensemble achieves LB 0.34** \n",
    "\n",
    "Great discussion [here][5] by @KOLOO that led to the latest score!\n",
    "\n",
    "Features+Head Starter uses Chris Deotte's Kaggle dataset [here][1]. Also Uses Chris's EEG spectrograms [here][3] (modified version) \n",
    "\n",
    "### Train and Infer Tips\n",
    "\n",
    "This notebook can be used both to train and submit (infer) to Kaggle LB. When training, you can set variable `submission = False` , you can also set `TEST_MODE = TRUE` to upload 500 samples queckly instead of the whole dataset for testing. \n",
    "\n",
    "To train a specific model type, you should set `DATA_TYPE = 'both|eeg|kaggle|raw'`, `kaggle` to train on Kaggle's spectrograms, `eeg` to train on EEG's spectrograms, `both` to train on Kaggle's and EEG's spectrograms, `raw` to train on EEG's signal with WaveNet,\n",
    "\n",
    "For submission after training models, you should save them in the LOAD_MODELS_FROM dataset, then run this notebook with `submission = True`.\n",
    "\n",
    "Once we have all the models saved to LOAD_MODELS_FROM and ready ensemble, we should set `submission = True` and `ENSEMBLE = True` and set the models versions that we prior specified, as well as their `LBs` for weighted ensemble.\n",
    "\n",
    "This notebook is made as generic as possible to expand and try different experiments.\n",
    "\n",
    "What you could do:\n",
    "- Change EfficientNetB(0-7) with `LOAD_BACKBONE_FROM`\n",
    "- Data augmentation by setting DataGenerator's parameter to `augment = True`\n",
    "- Different image configurations as input.\n",
    "- WaveNet model tuning.\n",
    "\n",
    "\n",
    "This notebook is a direct descendent of Chris's notebook [here][2]\n",
    "\n",
    "[1]: https://www.kaggle.com/datasets/cdeotte/brain-spectrograms\n",
    "[2]: https://www.kaggle.com/code/cdeotte/efficientnetb2-starter-lb-0-57\n",
    "[3]: https://www.kaggle.com/datasets/nartaa/eeg-spectrograms\n",
    "[4]: https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/468684\n",
    "[5]: https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/477461"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fd97f2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:24:47.647874Z",
     "iopub.status.busy": "2024-03-13T22:24:47.647136Z",
     "iopub.status.idle": "2024-03-13T22:25:02.580693Z",
     "shell.execute_reply": "2024-03-13T22:25:02.579700Z"
    },
    "papermill": {
     "duration": 14.945772,
     "end_time": "2024-03-13T22:25:02.582900",
     "exception": false,
     "start_time": "2024-03-13T22:24:47.637128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 12:13:56.508133: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-28 12:13:59.939073: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-28 12:14:05.134847: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 0 GPU\n"
     ]
    }
   ],
   "source": [
    "import os, random\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "import tensorflow.keras.backend as K\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "VER = 45\n",
    "DATA_TYPE = 'both' # both|eeg|kaggle|raw\n",
    "TEST_MODE = False\n",
    "submission = False\n",
    "\n",
    "\n",
    "np.random.seed(21)\n",
    "random.seed(21)\n",
    "tf.random.set_seed(21)\n",
    "\n",
    "# USE SINGLE GPU, MULTIPLE GPUS \n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "# WE USE MIXED PRECISION\n",
    "tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n",
    "if len(gpus)>1:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    print(f'Using {len(gpus)} GPUs')\n",
    "else:\n",
    "    strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
    "    print(f'Using {len(gpus)} GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c13ede3",
   "metadata": {
    "papermill": {
     "duration": 0.008744,
     "end_time": "2024-03-13T22:25:02.600941",
     "exception": false,
     "start_time": "2024-03-13T22:25:02.592197",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load and create Non-Overlapping Eeg Id Train Data\n",
    "The competition data description says that test data does not have multiple crops from the same `eeg_id`. Therefore we will train and validate using only 1 crop per `eeg_id`. There is a discussion about this [here][1].\n",
    "[1]: https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/467021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9addb929",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:25:02.619974Z",
     "iopub.status.busy": "2024-03-13T22:25:02.619443Z",
     "iopub.status.idle": "2024-03-13T22:25:06.696472Z",
     "shell.execute_reply": "2024-03-13T22:25:06.695096Z"
    },
    "papermill": {
     "duration": 4.089386,
     "end_time": "2024-03-13T22:25:06.698968",
     "exception": false,
     "start_time": "2024-03-13T22:25:02.609582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   eeg_id    spec_id  offset  patient_id target  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  other_vote        kl\n",
      "0  568657  789577333     0.0       20654  Other           0.0       0.0      0.25        0.0   0.166667    0.583333  4.584192\n"
     ]
    }
   ],
   "source": [
    "TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
    "FEATS2 = ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']\n",
    "FEAT2IDX = {x:y for x,y in zip(FEATS2,range(len(FEATS2)))}\n",
    "\n",
    "def eeg_from_parquet(parquet_path):\n",
    "\n",
    "    eeg = pd.read_parquet(parquet_path, columns=FEATS2)\n",
    "    rows = len(eeg)\n",
    "    offset = (rows-10_000)//2\n",
    "    eeg = eeg.iloc[offset:offset+10_000]\n",
    "    data = np.zeros((10_000,len(FEATS2)))\n",
    "    for j,col in enumerate(FEATS2):\n",
    "        \n",
    "        # FILL NAN\n",
    "        x = eeg[col].values.astype('float32')\n",
    "        m = np.nanmean(x)\n",
    "        if np.isnan(x).mean()<1: x = np.nan_to_num(x,nan=m)\n",
    "        else: x[:] = 0\n",
    "        \n",
    "        data[:,j] = x\n",
    "\n",
    "    return data\n",
    "\n",
    "def add_kl(data):\n",
    "    import torch\n",
    "    labels = data[TARGETS].values + 1e-5\n",
    "\n",
    "    # compute kl-loss with uniform distribution by pytorch\n",
    "    data['kl'] = torch.nn.functional.kl_div(\n",
    "        torch.log(torch.tensor(labels)),\n",
    "        torch.tensor([1 / 6] * 6),\n",
    "        reduction='none'\n",
    "    ).sum(dim=1).numpy()\n",
    "    return data\n",
    "\n",
    "def reset_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "if not submission:\n",
    "    train = pd.read_csv('/scratch/eecs545w24_class_root/eecs545w24_class/shared_data/hms_data/raw_data/train.csv')\n",
    "    TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
    "    META = ['spectrogram_id','spectrogram_label_offset_seconds','patient_id','expert_consensus']\n",
    "    train = train.groupby('eeg_id')[META+TARGETS\n",
    "                           ].agg({**{m:'first' for m in META},**{t:'sum' for t in TARGETS}}).reset_index() \n",
    "    train[TARGETS] = train[TARGETS]/train[TARGETS].values.sum(axis=1,keepdims=True)\n",
    "    train.columns = ['eeg_id','spec_id','offset','patient_id','target'] + TARGETS\n",
    "    train = add_kl(train)\n",
    "    print(train.head(1).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cb3509",
   "metadata": {
    "papermill": {
     "duration": 0.008639,
     "end_time": "2024-03-13T22:25:06.716688",
     "exception": false,
     "start_time": "2024-03-13T22:25:06.708049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Read Train Spectrograms and EEGs\n",
    "\n",
    "We can read 3 file from Chris's [Kaggle dataset here][1] which contains all the 11k spectrograms. From Chris's modified EEG spectrogram [here][2]. From Chris's EEG signals [here][3]\n",
    "\n",
    "[1]: https://www.kaggle.com/datasets/cdeotte/brain-spectrograms\n",
    "[2]: https://www.kaggle.com/datasets/nartaa/eeg-spectrograms\n",
    "[3]: https://www.kaggle.com/datasets/cdeotte/brain-eegs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f86ff9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:25:06.735809Z",
     "iopub.status.busy": "2024-03-13T22:25:06.735160Z",
     "iopub.status.idle": "2024-03-13T22:27:23.783487Z",
     "shell.execute_reply": "2024-03-13T22:27:23.782598Z"
    },
    "papermill": {
     "duration": 137.069325,
     "end_time": "2024-03-13T22:27:23.794734",
     "exception": false,
     "start_time": "2024-03-13T22:25:06.725409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if not submission:\n",
    "    # FOR TESTING SET TEST_MODE TO TRUE\n",
    "    if TEST_MODE:\n",
    "        train = train.sample(500,random_state=42).reset_index(drop=True)\n",
    "        spectrograms = {}\n",
    "        for i,e in enumerate(train.spec_id.values):\n",
    "            if i%100==0: print(i,', ',end='')\n",
    "            x = pd.read_parquet(f'/kaggle/input/hms-harmful-brain-activity-classification/train_spectrograms/{e}.parquet')\n",
    "            spectrograms[e] = x.values\n",
    "        all_eegs = {}\n",
    "        for i,e in enumerate(train.eeg_id.values):\n",
    "            if i%100==0: print(i,', ',end='')\n",
    "            x = np.load(f'/kaggle/input/eeg-spectrograms/EEG_Spectrograms/{e}.npy')\n",
    "            all_eegs[e] = x\n",
    "        all_raw_eegs = {}\n",
    "        for i,e in enumerate(train.eeg_id.values):\n",
    "            if i%100==0: print(i,', ',end='')\n",
    "            x = eeg_from_parquet(f'/kaggle/input/hms-harmful-brain-activity-classification/train_eegs/{e}.parquet')              \n",
    "            all_raw_eegs[e] = x\n",
    "    else:\n",
    "        spectrograms = None\n",
    "        all_eegs = None\n",
    "        all_raw_eegs = None\n",
    "        if DATA_TYPE=='both' or DATA_TYPE=='kaggle':\n",
    "            spectrograms = np.load('/scratch/eecs545w24_class_root/eecs545w24_class/shared_data/HMSEnsemble/brain-spectrograms/specs.npy',allow_pickle=True).item()\n",
    "        if DATA_TYPE=='both' or DATA_TYPE=='eeg':\n",
    "            all_eegs = np.load('/scratch/eecs545w24_class_root/eecs545w24_class/shared_data/HMSEnsemble/eeg-spectrograms/eeg_specs.npy',allow_pickle=True).item()\n",
    "        if DATA_TYPE=='raw':\n",
    "            all_raw_eegs = np.load('/kaggle/input/brain-eegs/eegs.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5771c709",
   "metadata": {
    "papermill": {
     "duration": 0.008571,
     "end_time": "2024-03-13T22:27:23.812325",
     "exception": false,
     "start_time": "2024-03-13T22:27:23.803754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DATA GENERATOR\n",
    "This data generator outputs 512x512x3, the spectrogram and eeg images are concatenated all togother in a single image. For using data augmention you can set `augment = True` when creating the train data generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782e52fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:27:23.831813Z",
     "iopub.status.busy": "2024-03-13T22:27:23.831437Z",
     "iopub.status.idle": "2024-03-13T22:27:26.207855Z",
     "shell.execute_reply": "2024-03-13T22:27:26.206948Z"
    },
    "papermill": {
     "duration": 2.389464,
     "end_time": "2024-03-13T22:27:26.210442",
     "exception": false,
     "start_time": "2024-03-13T22:27:23.820978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "class DataGenerator():\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, data, specs=None, eeg_specs=None, raw_eegs=None, augment=False, mode='train', data_type=DATA_TYPE): \n",
    "        self.data = data\n",
    "        self.augment = augment\n",
    "        self.mode = mode\n",
    "        self.data_type = data_type\n",
    "        self.specs = specs\n",
    "        self.eeg_specs = eeg_specs\n",
    "        self.raw_eegs = raw_eegs\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.data_generation(index)\n",
    "        if self.augment: X = self.augmentation(X)\n",
    "        return X, y\n",
    "    \n",
    "    def __call__(self):\n",
    "        for i in range(self.__len__()):\n",
    "            yield self.__getitem__(i)\n",
    "            \n",
    "            if i == self.__len__()-1:\n",
    "                self.on_epoch_end()\n",
    "                \n",
    "    def on_epoch_end(self):\n",
    "        if self.mode=='train': \n",
    "            self.data = self.data.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    def data_generation(self, index):\n",
    "        if self.data_type == 'both':\n",
    "            X,y = self.generate_all_specs(index)\n",
    "        elif self.data_type == 'eeg' or self.data_type == 'kaggle':\n",
    "            X,y = self.generate_specs(index)\n",
    "        elif self.data_type == 'raw':\n",
    "            X,y = self.generate_raw(index)\n",
    "\n",
    "        return X,y\n",
    "    \n",
    "    def generate_all_specs(self, index):\n",
    "        X = np.zeros((512,512,3),dtype='float32')\n",
    "        y = np.zeros((6,),dtype='float32')\n",
    "        \n",
    "        row = self.data.iloc[index]\n",
    "        if self.mode=='test': \n",
    "            offset = 0\n",
    "        else:\n",
    "            offset = int(row.offset/2)\n",
    "            \n",
    "        eeg = self.eeg_specs[row.eeg_id]\n",
    "        spec = self.specs[row.spec_id]\n",
    "        \n",
    "        imgs = [spec[offset:offset+300,k*100:(k+1)*100].T for k in [0,2,1,3]] # to match kaggle with eeg\n",
    "        img = np.stack(imgs,axis=-1)\n",
    "        # LOG TRANSFORM SPECTROGRAM\n",
    "        img = np.clip(img,np.exp(-4),np.exp(8))\n",
    "        img = np.log(img)\n",
    "            \n",
    "        # STANDARDIZE PER IMAGE\n",
    "        img = np.nan_to_num(img, nan=0.0)    \n",
    "            \n",
    "        mn = img.flatten().min()\n",
    "        mx = img.flatten().max()\n",
    "        ep = 1e-5\n",
    "        img = 255 * (img - mn) / (mx - mn + ep)\n",
    "        \n",
    "        X[0_0+56:100+56,:256,0] = img[:,22:-22,0] # LL_k\n",
    "        X[100+56:200+56,:256,0] = img[:,22:-22,2] # RL_k\n",
    "        X[0_0+56:100+56,:256,1] = img[:,22:-22,1] # LP_k\n",
    "        X[100+56:200+56,:256,1] = img[:,22:-22,3] # RP_k\n",
    "        X[0_0+56:100+56,:256,2] = img[:,22:-22,2] # RL_k\n",
    "        X[100+56:200+56,:256,2] = img[:,22:-22,1] # LP_k\n",
    "        \n",
    "        X[0_0+56:100+56,256:,0] = img[:,22:-22,0] # LL_k\n",
    "        X[100+56:200+56,256:,0] = img[:,22:-22,2] # RL_k\n",
    "        X[0_0+56:100+56,256:,1] = img[:,22:-22,1] # LP_k\n",
    "        X[100+56:200+56,256:,1] = img[:,22:-22,3] # RP_K\n",
    "        \n",
    "        # EEG\n",
    "        img = eeg\n",
    "        mn = img.flatten().min()\n",
    "        mx = img.flatten().max()\n",
    "        ep = 1e-5\n",
    "        img = 255 * (img - mn) / (mx - mn + ep)\n",
    "        X[200+56:300+56,:256,0] = img[:,22:-22,0] # LL_e\n",
    "        X[300+56:400+56,:256,0] = img[:,22:-22,2] # RL_e\n",
    "        X[200+56:300+56,:256,1] = img[:,22:-22,1] # LP_e\n",
    "        X[300+56:400+56,:256,1] = img[:,22:-22,3] # RP_e\n",
    "        X[200+56:300+56,:256,2] = img[:,22:-22,2] # RL_e\n",
    "        X[300+56:400+56,:256,2] = img[:,22:-22,1] # LP_e\n",
    "        \n",
    "        X[200+56:300+56,256:,0] = img[:,22:-22,0] # LL_e\n",
    "        X[300+56:400+56,256:,0] = img[:,22:-22,2] # RL_e\n",
    "        X[200+56:300+56,256:,1] = img[:,22:-22,1] # LP_e\n",
    "        X[300+56:400+56,256:,1] = img[:,22:-22,3] # RP_e\n",
    "\n",
    "        if self.mode!='test':\n",
    "            y[:] = row[TARGETS]\n",
    "        \n",
    "        return X,y\n",
    "    \n",
    "    def generate_specs(self, index):\n",
    "        X = np.zeros((512,512,3),dtype='float32')\n",
    "        y = np.zeros((6,),dtype='float32')\n",
    "        \n",
    "        row = self.data.iloc[index]\n",
    "        if self.mode=='test': \n",
    "            offset = 0\n",
    "        else:\n",
    "            offset = int(row.offset/2)\n",
    "            \n",
    "        if self.data_type == 'eeg':\n",
    "            img = self.eeg_specs[row.eeg_id]\n",
    "        elif self.data_type == 'kaggle':\n",
    "            spec = self.specs[row.spec_id]\n",
    "            imgs = [spec[offset:offset+300,k*100:(k+1)*100].T for k in [0,2,1,3]] # to match kaggle with eeg\n",
    "            img = np.stack(imgs,axis=-1)\n",
    "            # LOG TRANSFORM SPECTROGRAM\n",
    "            img = np.clip(img,np.exp(-4),np.exp(8))\n",
    "            img = np.log(img)\n",
    "            \n",
    "            # STANDARDIZE PER IMAGE\n",
    "            img = np.nan_to_num(img, nan=0.0)    \n",
    "            \n",
    "        mn = img.flatten().min()\n",
    "        mx = img.flatten().max()\n",
    "        ep = 1e-5\n",
    "        img = 255 * (img - mn) / (mx - mn + ep)\n",
    "        \n",
    "        X[0_0+56:100+56,:256,0] = img[:,22:-22,0]\n",
    "        X[100+56:200+56,:256,0] = img[:,22:-22,2]\n",
    "        X[0_0+56:100+56,:256,1] = img[:,22:-22,1]\n",
    "        X[100+56:200+56,:256,1] = img[:,22:-22,3]\n",
    "        X[0_0+56:100+56,:256,2] = img[:,22:-22,2]\n",
    "        X[100+56:200+56,:256,2] = img[:,22:-22,1]\n",
    "        \n",
    "        X[0_0+56:100+56,256:,0] = img[:,22:-22,0]\n",
    "        X[100+56:200+56,256:,0] = img[:,22:-22,1]\n",
    "        X[0_0+56:100+56,256:,1] = img[:,22:-22,2]\n",
    "        X[100+56:200+56,256:,1] = img[:,22:-22,3]\n",
    "        \n",
    "        X[200+56:300+56,:256,0] = img[:,22:-22,0]\n",
    "        X[300+56:400+56,:256,0] = img[:,22:-22,1]\n",
    "        X[200+56:300+56,:256,1] = img[:,22:-22,2]\n",
    "        X[300+56:400+56,:256,1] = img[:,22:-22,3]\n",
    "        X[200+56:300+56,:256,2] = img[:,22:-22,3]\n",
    "        X[300+56:400+56,:256,2] = img[:,22:-22,2]\n",
    "        \n",
    "        X[200+56:300+56,256:,0] = img[:,22:-22,0]\n",
    "        X[300+56:400+56,256:,0] = img[:,22:-22,2]\n",
    "        X[200+56:300+56,256:,1] = img[:,22:-22,1]\n",
    "        X[300+56:400+56,256:,1] = img[:,22:-22,3]\n",
    "        \n",
    "        if self.mode!='test':\n",
    "            y[:] = row[TARGETS]\n",
    "        \n",
    "        return X,y\n",
    "    \n",
    "    def generate_raw(self,index):\n",
    "        X = np.zeros((10_000,8),dtype='float32')\n",
    "        y = np.zeros((6,),dtype='float32')\n",
    "        \n",
    "        row = self.data.iloc[index]\n",
    "        eeg = self.raw_eegs[row.eeg_id]\n",
    "            \n",
    "        # FEATURE ENGINEER\n",
    "        X[:,0] = eeg[:,FEAT2IDX['Fp1']] - eeg[:,FEAT2IDX['T3']]\n",
    "        X[:,1] = eeg[:,FEAT2IDX['T3']] - eeg[:,FEAT2IDX['O1']]\n",
    "            \n",
    "        X[:,2] = eeg[:,FEAT2IDX['Fp1']] - eeg[:,FEAT2IDX['C3']]\n",
    "        X[:,3] = eeg[:,FEAT2IDX['C3']] - eeg[:,FEAT2IDX['O1']]\n",
    "            \n",
    "        X[:,4] = eeg[:,FEAT2IDX['Fp2']] - eeg[:,FEAT2IDX['C4']]\n",
    "        X[:,5] = eeg[:,FEAT2IDX['C4']] - eeg[:,FEAT2IDX['O2']]\n",
    "            \n",
    "        X[:,6] = eeg[:,FEAT2IDX['Fp2']] - eeg[:,FEAT2IDX['T4']]\n",
    "        X[:,7] = eeg[:,FEAT2IDX['T4']] - eeg[:,FEAT2IDX['O2']]\n",
    "            \n",
    "        # STANDARDIZE\n",
    "        X = np.clip(X,-1024,1024)\n",
    "        X = np.nan_to_num(X, nan=0) / 32.0\n",
    "            \n",
    "        # BUTTER LOW-PASS FILTER\n",
    "        X = self.butter_lowpass_filter(X)\n",
    "        # Downsample\n",
    "        X = X[::5,:]\n",
    "        \n",
    "        if self.mode!='test':\n",
    "            y[:] = row[TARGETS]\n",
    "                \n",
    "        return X,y\n",
    "        \n",
    "    def butter_lowpass_filter(self, data, cutoff_freq=20, sampling_rate=200, order=4):\n",
    "        nyquist = 0.5 * sampling_rate\n",
    "        normal_cutoff = cutoff_freq / nyquist\n",
    "        b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "        filtered_data = lfilter(b, a, data, axis=0)\n",
    "        return filtered_data\n",
    "    \n",
    "    def resize(self, img,size):\n",
    "        composition = albu.Compose([\n",
    "                albu.Resize(size[0],size[1])\n",
    "            ])\n",
    "        return composition(image=img)['image']\n",
    "            \n",
    "    def augmentation(self, img):\n",
    "        composition = albu.Compose([\n",
    "                albu.HorizontalFlip(p=0.4)\n",
    "            ])\n",
    "        return composition(image=img)['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdd2505",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:27:26.232712Z",
     "iopub.status.busy": "2024-03-13T22:27:26.231654Z",
     "iopub.status.idle": "2024-03-13T22:27:26.237293Z",
     "shell.execute_reply": "2024-03-13T22:27:26.236307Z"
    },
    "papermill": {
     "duration": 0.018645,
     "end_time": "2024-03-13T22:27:26.239302",
     "exception": false,
     "start_time": "2024-03-13T22:27:26.220657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VAEDataGenerator(DataGenerator):\n",
    "    def __getitem__(self,index):\n",
    "        x,y=super().__getitem__(index)\n",
    "        return (x)/256,(x)/256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078e6fba",
   "metadata": {
    "papermill": {
     "duration": 0.008825,
     "end_time": "2024-03-13T22:27:26.257391",
     "exception": false,
     "start_time": "2024-03-13T22:27:26.248566",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DISPLAY DATA GENERATOR\n",
    "Below we display example data generator spectrogram images and raw EEG signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67bfad3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:27:26.276860Z",
     "iopub.status.busy": "2024-03-13T22:27:26.276518Z",
     "iopub.status.idle": "2024-03-13T22:27:27.152471Z",
     "shell.execute_reply": "2024-03-13T22:27:27.151484Z"
    },
    "papermill": {
     "duration": 0.888734,
     "end_time": "2024-03-13T22:27:27.154995",
     "exception": false,
     "start_time": "2024-03-13T22:27:26.266261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not submission and DATA_TYPE!='raw':\n",
    "    gen = DataGenerator(train, augment=False, specs=spectrograms, eeg_specs=all_eegs, data_type=DATA_TYPE)\n",
    "    for x,y in gen:\n",
    "        break\n",
    "    plt.imshow(x[:,:,0])\n",
    "    plt.title(f'Target = {y.round(1)}',size=12)\n",
    "    plt.yticks([])\n",
    "    plt.ylabel('Frequencies (Hz)',size=12)\n",
    "    plt.xlabel('Time (sec)',size=12)\n",
    "    plt.show()\n",
    "    plt.imshow(x[:,:,1])\n",
    "    plt.title(f'Target = {y.round(1)}',size=12)\n",
    "    plt.yticks([])\n",
    "    plt.ylabel('Frequencies (Hz)',size=12)\n",
    "    plt.xlabel('Time (sec)',size=12)\n",
    "    plt.show()\n",
    "    plt.imshow(x[:,:,2])\n",
    "    plt.title(f'Target = {y.round(1)}',size=12)\n",
    "    plt.yticks([])\n",
    "    plt.ylabel('Frequencies (Hz)',size=12)\n",
    "    plt.xlabel('Time (sec)',size=12)\n",
    "    plt.show()\n",
    "    \n",
    "if not submission and DATA_TYPE=='raw':\n",
    "    gen = DataGenerator(train, raw_eegs=all_raw_eegs, data_type=DATA_TYPE)\n",
    "    for x,y in gen:\n",
    "        plt.figure(figsize=(20,4))\n",
    "        offset = 0\n",
    "        for j in range(x.shape[-1]):\n",
    "            if j!=0: offset -= x[:,j].min()\n",
    "            plt.plot(range(2_000),x[:,j]+offset,label=f'feature {j+1}')\n",
    "            offset += x[:,j].max()\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f88cbf1",
   "metadata": {
    "papermill": {
     "duration": 0.014055,
     "end_time": "2024-03-13T22:27:27.183784",
     "exception": false,
     "start_time": "2024-03-13T22:27:27.169729",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3e08a71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:27:27.212863Z",
     "iopub.status.busy": "2024-03-13T22:27:27.212054Z",
     "iopub.status.idle": "2024-03-13T22:27:27.218497Z",
     "shell.execute_reply": "2024-03-13T22:27:27.217495Z"
    },
    "papermill": {
     "duration": 0.023019,
     "end_time": "2024-03-13T22:27:27.220567",
     "exception": false,
     "start_time": "2024-03-13T22:27:27.197548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def halved_glorot_uniform(shape, dtype=None):\\n    initializer = tf.keras.initializers.GlorotUniform()\\n    weights = initializer(shape, dtype)\\n    return weights / 2.0\\ntf.keras.layers.Dense.Conv2D = halved_glorot_uniform'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def halved_glorot_uniform(shape, dtype=None):\n",
    "    initializer = tf.keras.initializers.GlorotUniform()\n",
    "    weights = initializer(shape, dtype)\n",
    "    return weights / 2.0\n",
    "tf.keras.layers.Dense.Conv2D = halved_glorot_uniform\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c794950e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:27:27.250834Z",
     "iopub.status.busy": "2024-03-13T22:27:27.250565Z",
     "iopub.status.idle": "2024-03-13T22:27:27.267200Z",
     "shell.execute_reply": "2024-03-13T22:27:27.266277Z"
    },
    "papermill": {
     "duration": 0.034402,
     "end_time": "2024-03-13T22:27:27.269227",
     "exception": false,
     "start_time": "2024-03-13T22:27:27.234825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class ResNetBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, in_channels, kernel_size, modify=False, bn=True):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.modify = modify\n",
    "        if modify == 'downsample':\n",
    "            self.conv1 = tf.keras.layers.Conv2D(in_channels*2, kernel_size, strides=2, padding='same', use_bias=False, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(0.005))\n",
    "            self.conv2 = tf.keras.layers.Conv2D(in_channels*2, kernel_size, padding='same', use_bias=False, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(0.005))\n",
    "            if bn:\n",
    "                self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "                self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "            else:\n",
    "                self.bn1 = tf.keras.layers.Layer()\n",
    "                self.bn2 = tf.keras.layers.Layer()\n",
    "        elif modify == 'upsample':\n",
    "            self.conv1 = tf.keras.layers.Conv2DTranspose(in_channels//2, kernel_size, strides=2, padding='same', output_padding=1, use_bias=False, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(0.005))\n",
    "            self.conv2 = tf.keras.layers.Conv2D(in_channels//2, kernel_size, padding='same', use_bias=False, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(0.005))\n",
    "            self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "            self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        else:\n",
    "            self.conv1 = tf.keras.layers.Conv2D(in_channels, kernel_size, padding='same', activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(0.005))\n",
    "            self.conv2 = tf.keras.layers.Conv2D(in_channels, kernel_size, padding='same', activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(0.005))\n",
    "            self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "            self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.act = tf.keras.layers.ReLU()\n",
    "        if modify == 'downsample':\n",
    "            self.proj = tf.keras.layers.Conv2D(in_channels*2, kernel_size, strides=2, padding='same', activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(0.005))\n",
    "        if modify == 'upsample':\n",
    "            self.proj = tf.keras.layers.Conv2DTranspose(in_channels//2, kernel_size, strides=2, padding='same', output_padding=1, activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(0.005))\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.act(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.modify:\n",
    "            x = self.proj(x)\n",
    "        out = x + out\n",
    "        out = self.act(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f273776a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:27:27.297481Z",
     "iopub.status.busy": "2024-03-13T22:27:27.296889Z",
     "iopub.status.idle": "2024-03-13T22:27:27.305857Z",
     "shell.execute_reply": "2024-03-13T22:27:27.305162Z"
    },
    "papermill": {
     "duration": 0.025321,
     "end_time": "2024-03-13T22:27:27.307839",
     "exception": false,
     "start_time": "2024-03-13T22:27:27.282518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(train, train_size=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dff3eda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:27:27.335282Z",
     "iopub.status.busy": "2024-03-13T22:27:27.335011Z",
     "iopub.status.idle": "2024-03-13T22:27:27.441842Z",
     "shell.execute_reply": "2024-03-13T22:27:27.441062Z"
    },
    "papermill": {
     "duration": 0.12305,
     "end_time": "2024-03-13T22:27:27.444236",
     "exception": false,
     "start_time": "2024-03-13T22:27:27.321186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = VAEDataGenerator(train, augment=False, specs=spectrograms, eeg_specs=all_eegs, raw_eegs=all_raw_eegs)\n",
    "x_train = tf.data.Dataset.from_generator(generator=x_train, \n",
    "                                               output_signature=(tf.TensorSpec(shape=(512,512,3), dtype=tf.float32),\n",
    "                                                                 tf.TensorSpec(shape=(512,512,3), dtype=tf.float32))).batch(16).prefetch(tf.data.AUTOTUNE)\n",
    "x_test = VAEDataGenerator(test, augment=False, specs=spectrograms, eeg_specs=all_eegs, raw_eegs=all_raw_eegs)\n",
    "x_test= tf.data.Dataset.from_generator(generator=x_test, \n",
    "                                               output_signature=(tf.TensorSpec(shape=(512,512,3), dtype=tf.float32),\n",
    "                                                                 tf.TensorSpec(shape=(512,512,3), dtype=tf.float32))).batch(16).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a35ad46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:27:27.473128Z",
     "iopub.status.busy": "2024-03-13T22:27:27.472843Z",
     "iopub.status.idle": "2024-03-13T22:27:27.778538Z",
     "shell.execute_reply": "2024-03-13T22:27:27.776812Z"
    },
    "papermill": {
     "duration": 0.322362,
     "end_time": "2024-03-13T22:27:27.780970",
     "exception": false,
     "start_time": "2024-03-13T22:27:27.458608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 10:24:24.052828: W tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:2303] No (suitable) GPUs detected, skipping auto_mixed_precision graph optimizer\n",
      "2024-03-28 10:24:24.848866: W tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:2303] No (suitable) GPUs detected, skipping auto_mixed_precision graph optimizer\n",
      "2024-03-28 10:24:25.125586: W tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:2303] No (suitable) GPUs detected, skipping auto_mixed_precision graph optimizer\n",
      "2024-03-28 10:24:25.472042: W tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:2303] No (suitable) GPUs detected, skipping auto_mixed_precision graph optimizer\n"
     ]
    }
   ],
   "source": [
    "for x,y in x_train:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    print(np.max(x))\n",
    "    print(np.min(x))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd152a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:27:27.812741Z",
     "iopub.status.busy": "2024-03-13T22:27:27.812418Z",
     "iopub.status.idle": "2024-03-13T22:27:27.816686Z",
     "shell.execute_reply": "2024-03-13T22:27:27.815831Z"
    },
    "papermill": {
     "duration": 0.023031,
     "end_time": "2024-03-13T22:27:27.818732",
     "exception": false,
     "start_time": "2024-03-13T22:27:27.795701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "latent_space_dim = 512*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d1bda0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:27:27.848186Z",
     "iopub.status.busy": "2024-03-13T22:27:27.847909Z",
     "iopub.status.idle": "2024-03-13T22:27:28.549885Z",
     "shell.execute_reply": "2024-03-13T22:27:28.549071Z"
    },
    "papermill": {
     "duration": 0.719566,
     "end_time": "2024-03-13T22:27:28.552222",
     "exception": false,
     "start_time": "2024-03-13T22:27:27.832656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(512,512,3))\n",
    "conv = tf.keras.layers.Conv2D(3, 7, 1, padding='same')(inputs)\n",
    "eres1 = ResNetBlock(16, 3, modify='downsample')(conv)\n",
    "eres2 = ResNetBlock(32, 3, modify='downsample')(eres1)\n",
    "eres3 = ResNetBlock(64, 3, modify='downsample')(eres2)\n",
    "eres4 = ResNetBlock(128, 3, modify='downsample')(eres3)\n",
    "eres5 = ResNetBlock(256, 3, modify='downsample')(eres4)\n",
    "eres6 = ResNetBlock(512, 3, modify='downsample')(eres5)\n",
    "\n",
    "shape_before_flatten = tensorflow.keras.backend.int_shape(eres6)[1:]\n",
    "encoder_flatten = tensorflow.keras.layers.Flatten()(eres6)\n",
    "\n",
    "z_mean_l  = tensorflow.keras.layers.Dense(units=latent_space_dim, name=\"encoder_mu\")\n",
    "z_mean = z_mean_l(encoder_flatten) \n",
    "z_log_var_l  = tensorflow.keras.layers.Dense(units=latent_space_dim, name=\"encoder_log_variance\", kernel_initializer='zeros', kernel_regularizer=tf.keras.regularizers.l2(3))\n",
    "z_log_var = z_log_var_l(encoder_flatten)\n",
    "\n",
    "#encoder_mu_log_variance_model = tensorflow.keras.models.Model(enc_input_layer, (encoder_mu, encoder_log_variance), name=\"encoder_mu_log_variance_model\")\n",
    "\n",
    "@tf.function\n",
    "def sampling(args):\n",
    "    z_mean_, z_log_var_ = args\n",
    "    #tf.print(z_mean_)\n",
    "    #tf.print(z_log_var_)\n",
    "    #tf.print(tf.reduce_max(z_log_var_))\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean_)[0], latent_space_dim))\n",
    "    #tf.print(epsilon)\n",
    "    result = z_mean_ + K.exp(z_log_var_ / 2) * epsilon\n",
    "    #tf.print(result)\n",
    "    return tf.debugging.check_numerics(result, \"NaN detected in sampling\")\n",
    "\n",
    "# Reparameterization trick\n",
    "z = tf.keras.layers.Lambda(sampling)([z_mean, z_log_var])\n",
    "\n",
    "encoder = tf.keras.Model(inputs, [z_mean, z_log_var, z], name='encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6061ce5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:27:28.581596Z",
     "iopub.status.busy": "2024-03-13T22:27:28.581262Z",
     "iopub.status.idle": "2024-03-13T22:27:29.017404Z",
     "shell.execute_reply": "2024-03-13T22:27:29.016216Z"
    },
    "papermill": {
     "duration": 0.453674,
     "end_time": "2024-03-13T22:27:29.019992",
     "exception": false,
     "start_time": "2024-03-13T22:27:28.566318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dec_input_layer = tf.keras.layers.Input(shape=(latent_space_dim))\n",
    "decoder_dense_layer1 = tensorflow.keras.layers.Dense(units=np.prod(shape_before_flatten), name=\"decoder_dense_1\")(dec_input_layer)\n",
    "decoder_reshape = tensorflow.keras.layers.Reshape(target_shape=shape_before_flatten)(decoder_dense_layer1)\n",
    "dres1 = ResNetBlock(1024, 3, modify='upsample')(decoder_reshape)\n",
    "dres2 = ResNetBlock(512, 3, modify='upsample')(dres1)\n",
    "dres3 = ResNetBlock(256, 3, modify='upsample')(dres2)\n",
    "dres4 = ResNetBlock(128, 3, modify='upsample')(dres3)\n",
    "dres5 = ResNetBlock(64, 3, modify='upsample')(dres4)\n",
    "dres6 = ResNetBlock(32, 3, modify='upsample')(dres5)\n",
    "dconv = tf.keras.layers.Conv2D(3, 3, 1, padding='same', activation = tf.nn.sigmoid)(dres6)\n",
    "\n",
    "decoder = tf.keras.models.Model(dec_input_layer, dconv, name=\"decoder_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1d0df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:27:29.052191Z",
     "iopub.status.busy": "2024-03-13T22:27:29.051634Z",
     "iopub.status.idle": "2024-03-13T22:27:29.425520Z",
     "shell.execute_reply": "2024-03-13T22:27:29.424734Z"
    },
    "papermill": {
     "duration": 0.392197,
     "end_time": "2024-03-13T22:27:29.427775",
     "exception": false,
     "start_time": "2024-03-13T22:27:29.035578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#VAE:\n",
    "\n",
    "#vae_input = tf.keras.layers.Input(shape=(512, 512, 3), name=\"VAE_input\")\n",
    "vae_encoder_output = encoder(inputs)\n",
    "outputs = decoder(vae_encoder_output[2])\n",
    "vae = tf.keras.models.Model(inputs, outputs, name=\"VAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0863d16b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:27:29.456172Z",
     "iopub.status.busy": "2024-03-13T22:27:29.455643Z",
     "iopub.status.idle": "2024-03-13T22:27:29.502110Z",
     "shell.execute_reply": "2024-03-13T22:27:29.501260Z"
    },
    "papermill": {
     "duration": 0.068558,
     "end_time": "2024-03-13T22:27:29.509945",
     "exception": false,
     "start_time": "2024-03-13T22:27:29.441387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca200ddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:27:29.589607Z",
     "iopub.status.busy": "2024-03-13T22:27:29.589233Z",
     "iopub.status.idle": "2024-03-13T22:27:29.630404Z",
     "shell.execute_reply": "2024-03-13T22:27:29.629621Z"
    },
    "papermill": {
     "duration": 0.065758,
     "end_time": "2024-03-13T22:27:29.636968",
     "exception": false,
     "start_time": "2024-03-13T22:27:29.571210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ac91b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:27:29.676639Z",
     "iopub.status.busy": "2024-03-13T22:27:29.676363Z",
     "iopub.status.idle": "2024-03-13T22:27:29.706455Z",
     "shell.execute_reply": "2024-03-13T22:27:29.705571Z"
    },
    "papermill": {
     "duration": 0.052143,
     "end_time": "2024-03-13T22:27:29.708469",
     "exception": false,
     "start_time": "2024-03-13T22:27:29.656326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889a01ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:27:29.750927Z",
     "iopub.status.busy": "2024-03-13T22:27:29.750655Z",
     "iopub.status.idle": "2024-03-13T22:27:29.872010Z",
     "shell.execute_reply": "2024-03-13T22:27:29.871337Z"
    },
    "papermill": {
     "duration": 0.145049,
     "end_time": "2024-03-13T22:27:29.873923",
     "exception": false,
     "start_time": "2024-03-13T22:27:29.728874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import mse\n",
    "reconstruction_loss = mse(K.flatten(inputs), K.flatten(outputs))\n",
    "reconstruction_loss *= 512*512*3\n",
    "kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=1)\n",
    "B = 1\n",
    "vae_loss = K.mean(B * reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.add_metric(kl_loss, name=\"kl_loss\")\n",
    "vae.add_metric(reconstruction_loss, name=\"reconstruction_loss\")\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam(lr=10e-6, global_clipnorm=10e-6, clipvalue=10e-6, weight_decay=1))\n",
    "\n",
    "#vae.fit(x_train, epochs=500, batch_size=batch_size, validation_data=(x_test, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90fd9b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:27:29.917968Z",
     "iopub.status.busy": "2024-03-13T22:27:29.917648Z",
     "iopub.status.idle": "2024-03-13T22:27:30.183612Z",
     "shell.execute_reply": "2024-03-13T22:27:30.182689Z"
    },
    "papermill": {
     "duration": 0.289568,
     "end_time": "2024-03-13T22:27:30.185639",
     "exception": false,
     "start_time": "2024-03-13T22:27:29.896071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.array([next(iter(x_train))[0][0].numpy()]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7a9ce3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:27:30.228743Z",
     "iopub.status.busy": "2024-03-13T22:27:30.228440Z",
     "iopub.status.idle": "2024-03-14T00:01:01.439262Z",
     "shell.execute_reply": "2024-03-14T00:01:01.438408Z"
    },
    "papermill": {
     "duration": 5611.234539,
     "end_time": "2024-03-14T00:01:01.441366",
     "exception": false,
     "start_time": "2024-03-13T22:27:30.206827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "def plot_callback(epoch, logs):\n",
    "    x = np.array([next(iter(x_train))[0][0].numpy()])\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # Plot x\n",
    "    axes[0].imshow(x[0][:,:,0])\n",
    "    axes[0].set_yticks([])\n",
    "    axes[0].set_ylabel('Frequencies (Hz)', size=12)\n",
    "    axes[0].set_xlabel('Time (sec)', size=12)\n",
    "    # Plot out\n",
    "    out = vae.predict(x)\n",
    "    axes[1].imshow(out[0][:,:,0])\n",
    "    axes[1].set_yticks([])\n",
    "    axes[1].set_ylabel('Frequencies (Hz)', size=12)\n",
    "    axes[1].set_xlabel('Time (sec)', size=12)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "class PrintValidationLoss(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_loss = logs.get('val_loss')\n",
    "        val_kl_loss = logs.get('val_kl_loss')\n",
    "        val_reconstruction_loss = logs.get(\"val_reconstruction_loss\")\n",
    "        print(f'Validation Loss: {val_loss} - kl_loss: {val_kl_loss} - reconstruction_loss: {val_reconstruction_loss}')\n",
    "# Define the LambdaCallback\n",
    "plot_callback_lambda = LambdaCallback(on_epoch_end=plot_callback)\n",
    "#m_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath='/kaggle/working', save_weights_only = True, period=5)\n",
    "\n",
    "# Fit the model\n",
    "History = vae.fit(x_train, epochs=10, batch_size=64, callbacks=[plot_callback_lambda,PrintValidationLoss()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d6a72e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T00:01:03.004825Z",
     "iopub.status.busy": "2024-03-14T00:01:03.004429Z",
     "iopub.status.idle": "2024-03-14T00:01:22.024422Z",
     "shell.execute_reply": "2024-03-14T00:01:22.023484Z"
    },
    "papermill": {
     "duration": 19.810689,
     "end_time": "2024-03-14T00:01:22.028233",
     "exception": false,
     "start_time": "2024-03-14T00:01:02.217544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vae.save_weights('final_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7962dc2",
   "metadata": {
    "papermill": {
     "duration": 0.792414,
     "end_time": "2024-03-14T00:01:23.656978",
     "exception": false,
     "start_time": "2024-03-14T00:01:22.864564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eeb454",
   "metadata": {
    "papermill": {
     "duration": 0.762113,
     "end_time": "2024-03-14T00:01:25.173885",
     "exception": false,
     "start_time": "2024-03-14T00:01:24.411772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf31280",
   "metadata": {
    "papermill": {
     "duration": 0.7633,
     "end_time": "2024-03-14T00:01:26.754973",
     "exception": false,
     "start_time": "2024-03-14T00:01:25.991673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0ceef3",
   "metadata": {
    "papermill": {
     "duration": 0.760608,
     "end_time": "2024-03-14T00:01:28.275409",
     "exception": false,
     "start_time": "2024-03-14T00:01:27.514801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20158d96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7469972,
     "sourceId": 59093,
     "sourceType": "competition"
    },
    {
     "datasetId": 4297782,
     "sourceId": 7392775,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4317718,
     "sourceId": 7465251,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4407194,
     "sourceId": 7570342,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4382744,
     "sourceId": 7752462,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4417235,
     "sourceId": 7818976,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5809.712952,
   "end_time": "2024-03-14T00:01:33.668455",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-13T22:24:43.955503",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
